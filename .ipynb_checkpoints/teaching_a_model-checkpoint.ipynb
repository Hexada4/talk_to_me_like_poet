{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2430e270",
   "metadata": {},
   "source": [
    "# Installing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e2b0921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `df.append` not found.\n"
     ]
    }
   ],
   "source": [
    "?pd.DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45f55e75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['prepared_vvedenskiy.csv', 'prepared_tretyakov.csv']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('data/poems/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "85fe0ae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['из сборника\\nбогу горе дорогое не гляди на море ах что ты что ты горе скажет ах что ты птичка говоришь лишь полдень\\nего боготворишь тушканчик этот неземной и неестественный зверёк летите птички все за мной изображайте пузырёк тут птичка первая сказала я одного не понимаю она частицами летала над пышной колокольней леса она изображала беса я одного не понимаю неясно мне значение игры которой барыня монашка со словом племя занялась и почему игра ведро спрошу я просто и светло о птичка медная сказало горе игрушка бледная при разговоре теряет смысл и бытиё и всё становится несносное питьё о молодая соль значения и слова но птичка говорит позволь и вдруг летает безголова тогда вторая половинка сквозная будто шелковинка порхает в облаке пустом запуталась в крыле густом и говорит о горе горе спрячь в ножны молодое море вторая птичка обезьяна а я как десять без изъяна я как число достойна смеха я вся из времени и меха и птичка села на кровать и стала вальсы шнуровать тут горе говорит но что же делает тушканчик давайте братцы поглядим в его стакане пышном тихом как видно появилась ночь и слово племя тяжелеет и превращается в предмет и даже барыня монашка ура ура кричит ведру но непредвиденным молчаньем вдруг наполняется стакан лев изгибается дугой и рёв разносится тугой над возвышенной горой над человеческой порой лев убивается порой было жарко и темно было скучно и окно вылезали из земли лопухи и ковыли плыл утопленник распух расписался я лопух если кто без головы то скажи что он ковыль я царь зверей но не могу открыть дверей вздохнули все четыре птицы единогласно и легко и распустив хвостом косицы и пили молоко но ночь в кафтане быстролётном и в железном картузе сказало голосом бесплотным виясь на пиковом тузе о птички о родной тушканчик вам хорошо у вас разнообразны мысли а в мыслях будто кости в мясе чувства и многие понятия у вас а я пирующие птицы летающие так и сяк не понимаю слова много не понимаю вещи нуль но ты прекрасна велика ответил ночи пеликан на что моя величина скажи скажи хромое горе из моря я извлечена шипит внизу пустое море как раскалённая змея о море море большая родина моя сказала ночь и запищала как бедный детский человек и кукла в ручках затрещала и побледнел кузен четверг сестра сказал он ночи тёмной ты ночь я день глухой и скромный а эти звери все живые и эти птицы молодые и горе толстое хромое умрут холодною зимою солнце светить перестанет всё живущее завянет земля поморщится подсохнет и всё как муха сразу сдохнет тут испугались обе птички куда бежать им от судьбы пришли бои вражда и стычки и помешательства столбы взросли на поле сухопаром и дело кончилось пожаром июля\\nбог тебе покажет ты зря',\n",
       "       'из сборника\\nа колдовство или гордость мрачные ухабы её седой бахчи народы кипятки и бабы она стремится им рассказать про всякие фуфу апчхи с обручем в тазу стоит нет она с гнедыми подж\\nребёнок что же стих нет пасекой икает может он помер нет ногой болтает и вид его хмур и лих он кожи сухари гложет но где же детский врач картуз на голове режет стоит себе в чадре пиликает и слезится в посмертный лазарет не торопится а акушерочка она на животе своём рисует имена что значат\\nагонии коля сусликом лежит судача от боли припадаю на один глаз умираю на один ус плывёт на меня игла кораблём су башмаком су число спина унесла меня семья говорит на спи стало всеё зачаточным и воздух сгнил мертвый тапир февраля суббота г\\nазия так здесь же святой тропарь\\nс нет они иконописные мастера\\nй фрер мой аркаша онкль бинокль это\\nн шаг нет это верблюдов гамаши но где же где же врач уж отчаянный\\nарками трудится косой шевелит куриной косточкой брату письмо пишет\\nмстислав трава растёт он держит кинжал не говорит лишних слов так вот ему повелось на охоту попасть он на штык зевнул сидит комар родной в луз он их власть нет он лишь зулейка ты монах ты монах честный проповедник прискакали на одной ноге бояре в землю ханаанскую там петр великий и онан чашки куют кто ты последний солдат рыжий\\nегузов без подкладок ротных песен он умирает без усов конец его тесен нет конец его смраден и гадок как навоз лошадок у него морда чистая мох и ботичелли чиновники пришли к субботе их пришили они играют на лире они они хают нашу новую сумрачность оно они порхают нет это снег на росу начал нос пускать чего же наудил ерши да дули велик ли улов сюргуч и воля к падучей иду ли жадно иволга кричит врач сипит акушерочка сестра спит голубошерстяноглазая под жестом топора почему это не\\nармия ворон прилетела на бронислава они чинят башмак шьют портки завязывают часы сидел грозный сыч снял капор кивал ли он на врагов свистит шарабан в нем племянница пасхальным яйцом тянется в богатырские очки язык вложит кто её жито разложил на пахабных стенках никто никто в жизни она сама венка сановники',\n",
       "       'из сборника\\nмесяца лысое темя прикрыто дымным плащом музыкой сонного времени мой увенчаю дом\\nи я в моём тёплом теле лелеял глухую лень\\nухо улицы глухо кружится карусель\\nсонно звенят недели вечность проходит в тень\\nзвёзды злые старухи качают дней колыбель',\n",
       "       'из сборника\\nу м е р ш и й уж я на статуе сижу безбрежною листвою углы прохожие слежу любезной головою на это отвечал судья в кафтане в простыне в постель посмертную идя и думал лёжа на спине что всётаки она уныла и на подушке спит бескрылый над всем проносится поток над всем проносится восток\\nрим и с монашкой говорим ты монашка я пятнашка но услыша пули звук он упал холодной шашкой весь рыдая на траву что за горе но в окно смотрит море и темно он с горы сидит впотьмах он ласкает росомах побеги идёт в вокзал в безоглядную тюрьму где качается лоза где создания умрут быстро падал детский снег полный ленты полный нег когда бы жить начать сначала он молвит в свой сюртук я б всё печатала рычала как бы лесной барсук уже казаки убежали в углу сияет ангел хилый и мысли глупые жужжали над этой ветхою могилой поспешные минуты как речи потекли и звёзды отдалённо как тучи расцвели тогда ребёнок молодой молиться сочиняет болтает сонной головой в подушку медную скучает он плача покидает лес и южные бананы колотит точно мутный бес в сухие жизни барабаны но скоро вечер наступил видна пустыня ада покуда свечкой на пути не установят сада что же это стрекоза нет восток отличный словно баба егоза или ветер хищный и с дворянских сих кустов нету сумрачных мостов и в богатой этой печке всё наклонно всё как в спячке о похожие столы мы сказали ветрено выбегая из толпы по дощечке ветреной сквозь холодное стекло выставляя лица замечает рассвело умерла столица и ложася на сундук и сложивши руки он как утренний бамбук умер для науки грохочи отец и мать светит зябкий уголок и торопится поймать однодневный потолок выходил поспешно дух огорошенный петух и на елях на сосне как дитя лежал во сне в неслышном оперении в тоске и измерении\\nпуть конквистадоров',\n",
       "       'бог без очей без рук без ног так девица вся в слезах видит это в небесах видит разные орлы появляются из мглы и тоскливые летят и беззвучные блестят о как мрачно это всё скажет хмурая девица\\nленочка судьбы и на небе был\\nбоже пожалей\\nмеркурий и вертелся как волчок и медведь в пушистой шкуре грел под кустиком бочок а кругом ходили люди и носили рыб на блюде и носили на руках десять пальцев на крюках и пока всё это было та девица отдохнула и воскресла и забыла и воскресшая зевнула я спала сказала братцы надо в этом разобраться сон ведь хуже макарон сон потеха для ворон я совсем не умирала я лежала и зияла извивалась и орала я пугала это зало летаргический припадок был со мною между кадок лучше будем веселиться и пойдём в кино скакать и помчалась как ослица всем желаньям потакать тут сияние небес ночь ли это или бес\\nбог играй и вошла девица в рай там вертелось вкось и вкривь числа домы и моря в несущественном открыв существующее зря там томился в клетке\\nиз сборника\\nбоже правый на скале но ответил\\nбоже бытиё что ты дева говоришь что ты полдень понимаешь ты веселье и\\nпариж дико к сердцу прижимаешь ты под музыку паришь ты со статуей блистаешь в это время лес взревел окончательно тоскуя он среди земных плевел видит ленточку косую эта ленточка столбы это\\nбог спокойно удивится спросит мёртвую её что же мрачно дева\\nпуть конквистадоров',\n",
       "       'о х о т н и к я сам ходил в леса по пояс я изучал зверей науку бывало крепкой водкой моясь испытывал я смерть и скуку передо мной вращались звери разнообразные сырые но я закрыл лесные двери чтобы найти миры вторые вот я стою на этих скалах и слышу мёртвых волн рычанье и на руках моих усталых написаны слова прощанья прощайте горы и леса прощай барсук прощай лиса\\nиз сборника\\nс а н о в н и к вот перед вами я пучина милая моя я вижу здесь ещё людишки хотят купить на дне домишки чтоб в этих домиках морских с русалками обедать чтобы в трактирах водяных морской коньяк отведать мы верим в то что не умрём что жизнь имеет продолженье мерцает рыба серебром мы любим пиво любим ром играем с бабкой в размноженье моя невеста дурдина мои любила ордена но целый год весну и лето не выходила из клозета и я отчаялся потух сказал себе я не петух не пищевод она же утка и продолжение желудка она рабыня живота тут появилась пустота и понял я что всё роскошно но пакостно тоскливо тошно и я к тебе склоняюсь море на документах слово горе гляди написано везде и вижу сотни категорий как рыбы плавают в воде\\nм о р е я не могу\\nм о р е я так же ничего не значу\\nслуги вносят большой диван на диване люди птицы мысли мыши и кусты и у всех печальны лица и у всех глаза пусты птицы ходят по траве будто сны на голове люди жёлтые лежат лодки светят дребезжат мысли крадутся в могилу через дождь и через силу мыши ходят вдоль домов с видом греческих умов и прозрачны и чисты спят под знаменем кусты\\nя откудато идёт сановник в его руке пищит шиповник на всё глядит великосветски икает редко понемецки и величаво горделиво остановившись он стоит шумит сосна болтает слива волна безумная блестит мечтает лодка и пучина вдруг говорит ему мужчина и ты устав от государства и службы испытав коварство узнав ненужность эполет ужель тебе постыл балет и жизнь предстала кровопийцей и ты стоишь самоубийцей\\nа н г е л все ли все ли здесь собрались все ли сели на полу музыканты собирались как пингвины на скалу выходило море в гости с ним под руку шла звезда и сказало море бросьте думать бегать ерунда думай думай думай думай бегай прыгай и ворчи смерть возьмёт рукой угрюмой поздно выскочат врачи будто лебеди родные соберутся вкруг постели и труды придут иные залетают мухи в теле но чему могу помочь дети люди в эту ночь\\nо х о т н и к море море госпожа на тебя одна надежда мы к тебе идём дрожа\\nо х о т н и к я думаю я плачу\\nс а н о в н и к замолчи невежда мы море море дорогое понять не можем ничего прими нас милое второе и водяное божество как звери бегаем во мраке откинув шпаги мысли фраки в руке дымится банка света взгляни могущее на это на голове стучит венец приходит нам пришёл конец\\nг о л о с все сюда явитесь и зажгите ваши свечи демон овощ дождь и витязь нынче к нам идут на вечер море берег и звезда мы устроим пир огромный вылетает ангел тёмный из пучины из гнезда\\nм о р с ко й д е м о н и море ничего не значит и море тоже круглый нуль и человек напрасно скачет в пучину от ножа и пуль и в море так же ходят рыбки собаки бегают играют скрипки и водоросли спят как тётки и будто блохи скачут лодки и в море так же мало смысла оно покорно тем же числам оно пустынно и темно быть может море ты окно быть может море ты одно\\nм о р с к о й д е м о н а что я говорил\\nпуть конквистадоров',\n",
       "       'из сборника\\nбог моя одежда слышно музыку гребёнок в балалайку побренчав мы кричим умри надежда николаевна мартынова а твой муж иван степан в темноте ночей тюльпан и среди огня гостинного но чу слышно музыка гремит лампа бедствие стремит человек находит части он качается от счастья видит зеркало несут как же как же говорит это окружной сосуд это входит прокурор кто мажор а он минор но однако не забудьте что кругом был дикий мрак быстро ехал на минуте как уж сказано дурак у него был хвост волос вдруг создание открылось всем увидеть довелось той букашки быстрокрылость и судейскую немилость стал убийца перед ними и стоял он в синем дыме и стоял он и рыдал то налево то направо то луна а то дубрава вот как он страдал он стоял открывши душу он гремел обнявши тушу был одет в роскошну шкуру был подобен он амуру вот как он рыдал сон стоял по праву руку и держал под мышку скуку эту новую науку вот как он страдал тут привстал один судья как проворная бадья и сказал ему убийца что рыдаешь что грустишь ты престол и кровопийца а кругом стояла тишь обстановка этой ткани создалась в\\nриме и поглядите стал он зримей и очутился и возник он был мечом он стал родник хорошо сказал им суд это верно это так и разбил бы сей сосуд даже римлянин спартак но в теченьи дней иных на морской смотря залив видя ласточек стальных стал бы сей спартак соплив стал бы он соплив от горя прыгать в бездну прыгать в море что же этот богатырь не уселся в монастырь помилуйте судьи ответил злодей поднявши меч и всплакнув помещик сказал прокурор владей собою\\nон думал уснув что это идёт по дороге не тело ожесточённо теряя сустав а на небе новое двигалось дело от пупс перепутствий как свечка устав а дальше обвиняемый что сделали вы с ним ведь вы не невменяемый ведь вы я вижу серафим как сказал убийца как вы отгадали и фанагорийцы мигом зарыдали дальше я как полагалось лёг на печку и ревел всё живущее шаталось револьвер в меня смотрел да однако не забудьте что кругом шуршали птички и летали по каюте две неважные затычки нус пищит иван степан мы закончим этот день я опять в ночи тюльпан я бросаю в поле тень я давно себя нашёл суд ушёл\\nтаракани дело было так в квартире пошлого скворцова стоял диван по имени сундук в окно виднелся день дворцовый а дальше замок виадук а за домом был пустырь вот тутто в бочке и солился богатырь но ему надоело сидеть в бочке из червяков плести веночки и думать что они цветочки он вдруг затосковал о точке он вдруг закуковал о',\n",
       "       'многим многим лучше поверьте частица дня единица ночи\\nземля где твои дела говорит ей холодный червяк а земля распоряжаясь покойниками может быть в ответ молчит она знает что всё не так\\nиз сборника\\nмне жалко что я не орёл перелетающий длинные вершины которому на ум взбрёл человек наблюдающий аршины\\nмне жалко что я не чаша мне не нравится что я не жалость\\nкругом как свеча возрастает трава и мигом качаются дерева\\nмне не нравится что я смертен мне жалко что я неточен\\nмне страшно что я не трава трава мне страшно что я не свеча\\nмы выйдем с собой погулять в лес для рассмотрения ничтожных листьев мне жалко что на этих листьях я не увижу незаметных слов называющихся случай называющихся бессмертие называющихся вид основ\\nмне жалко что я не роща которая листьями вооружалась\\nмне страшно что я двигаюсь непохоже на червяка червяк прорывает в земле норы заводя с землёй разговоры\\nмне трудно что я с минутами меня они страшно запутали\\nмне не нравится что я смертен мне жалко что я не точен многим многим лучше поверьте частица дня единица ночи\\nмы сядем с тобою ветер на этот камушек смерти\\nещё есть у меня претензия что я не ковёр не гортензия\\nмне страшно что я при взгляде на две одинаковые вещи не вижу что они усердно стараются быть похожими\\nмне страшно что я не свеча трава на это я отвечал и мигом качаются дерева\\nя вижу искажённый мир я слышу шёпот заглушённых лир и тут за кончик буквы взяв я поднимаю слово шкаф теперь я ставлю шкаф на место он вещества крутое тесто\\nмне страшно что я при взгляде на две одинаковые вещи не замечаю что они различны что каждая живёт однажды\\nмне невероятно обидно что меня понастоящему видно\\nчервяк ползёт за всеми он несёт однозвучность\\nмне трудно что я с минутами они меня страшно запутали\\nмне жалко что я не звезда бегающая по небосводу в поисках точного гнезда она находит себя и пустую земную воду никто не слыхал чтобы звезда издавала скрип её назначение ободрять собственным молчанием рыб\\nмне страшно что всё приходит в ветхость и я по сравнению с этим не редкость\\nмне жалко что я не орёл перелетающий вершины и вершины которому на ум взбрёл человек наблюдающий аршины\\nмне страшно что я неизвестность мне жалко что я не огонь\\nмне жалко что я не крыша распадающаяся постепенно которую дождь размачивает у которой смерть не мгновенна\\nмне страшно что я двигаюсь не так как жуки жуки как бабочки и коляски и как жуки пауки\\nмне жалко что я не семя мне страшно что я не тучность\\nмне жалко что я не зверь бегающий по синей дорожке говорящий себе поверь а другому себе подожди немножко мы выйдем с собой погулять в лес для рассмотрения ничтожных листьев',\n",
       "       'глядят глаза на нас когда\\nиз сборника\\nгарри крался по лестнице\\nс милыми деньгами\\nа в трактире осталась та\\nночь каменеет на мосту\\nо красавица твои уста\\nне пойте черноглазых од над жертвою слепого рока\\nего сложила в нищий гроб\\nчуть скрипит сухой паркет\\nгде до утра\\nпуть конквистадоров\\nради которой он у цели\\nпусть месяц скорбный идиот\\nс грозными усами\\nревут кондуктора\\nу загнанного неба мало\\nгостей ласкали по привычке\\nэлектрический фонарик\\nосторожен тихий\\nнадень меха\\nни сифилис и не холера\\nпо улицам пройдись\\nо пустынный кабинет\\nворов безумных летопись\\nно предстал нежданно граф\\nхолодный снег и сух и прост\\nдля проделок вора\\nи хмуро жмурятся от снега фонари\\nв серых коридорах\\nцелует руки у востока\\nвот уж близок тёмный шкаф\\nи моментально в белый лоб\\nгде звёзды лошадиный хвост\\nвцепилась пуля револьвера\\nчёрной ночью сладок мрак\\nпослушайте трактир мой пуст\\nтрусит лишь один дурак\\nа уличные прелестницы\\nдержа в руке фонарь и отмычки\\nвлетают в яркие вокзалы\\nи они участвуют в деле\\nглухонемые поезда\\nа ночь горбатая взрастает до зари',\n",
       "       'из сборника\\nсамум головы подперев от дум и птица летит в гантах пев пех пех пирх пирх пряная птица та пьяная о мученье какая старая сурво бстро отвечал неин качал пыл пол пул сухо мигнул в далёкий солнечный аул летит старушка панихида такая гнида\\nевлалия чтоб петь шептать я ангел певчий ангел и крылья есть я тигр слепил подушки глаз кадил дымилом лик ладонька спе и спя свалилась львицей с шей глуха нема толпа а кто её умней событий обсуждал здесь каждый серик бантик ты в баночку плевал раз раз\\nа и стук и он не стал луна катит волну седую вдалеке в знакомую страну овес летит в песке не спит последний час медвежий недотяпа который бурный спал славянская ты лапа и дремлет часовой на ветке заинздесь чертями мир оброс и адский пир везде далекий чеха склеп теперь плывёт на нас спасайся\\nо страница трупа любо любо зуба зуба\\nахни мандолина незрим и дом скрипучий наш орех везут на смех\\nбог сулил что я из перца кладбищ из перца могил старушка в ванну сядет чулок развязать к ней подойдёт\\nфетинька коль наступило летинька нукдох нукдох за ящики стремятся трупы падчериц дрожит очей молчание петруша досвидание артикль уский суточный летит неглупый будочный я здравствуй плачет весело на сук жену повесила жена моя звезда рыдая умерла жена моя погасла печальной каплей масла кричат певуньи птички мы знаем по привычке так верно\\nт огл агнь пропе сой вакх с тирсом и ветер в степях ой ой вонючка вонючка лиса с тревогой гортань с трубой с тревогой гляжу с тобой ох вздох упаду на синюю медь в аду и воздух остался немым\\nлипавскому да\\nархелук прощальный птоломей утих проныра сна изящный колодец солёный водопад\\nю хрипит наш мир хрипит наш путь и там и сонный клир открыл свой рот свой рот свой род жёлтый пух летит из вялых мышей и зыбко зыбко мёртвый дух склонился на ошей ник и зыбко руки простирал куда авсе куда авсе кинжал смутился пар проклятая пасха она нам не нужна деревянная пробка но но он сдох вы знаете он сдох кречет кречет ратник воли ты летящий сквозь юдоли раненый пращею туман тимпан веспасиан рим город гнильною струею течет в овин не он один старец пачкающий палец пруссия пруссия снегов белоруссия игрушкой прыгнул васисдас приветствую ребята вас о чем клест кнут пут здесь всё как пух и мыла пена пух звезда сияя вдруг исчезла соларка козырей монах пробка лук семя вестнику в течении лета изъяснился сердце мое зубр арбр урбр хлрпр крпр трпр крестьянин креста носитель одеяния нет\\nкралинька чего поёшь ты маленька чего ты плачешь\\nарзамас и тверь кричит\\nхалушка пуд с мячиком мая года',\n",
       "       'а фонаря стоят доска досочка дощечка дошка дощечк\\nно огонь долизывая склад говорил\\nу братцы сказал один воробей полетим к одним пекарням где сегодня\\nа вате здесь дремлет старый рукомойник сосед по\\nе генерала и свист идёт и дым ползёт и струп ф голое зало\\nи пустеки как много пувуноф плывёт смотрите по тем стенам\\nогонь огонь запищали доски\\nбавили доски\\nдва воробья одного звали фёдором другого арбузом почесались и сев на лампу сказали что они это видели и знать ничего не хотят тре\\nты ломаешь нам тазобёдренные суставы сказали дрова и и коленные чашечки\\nт много ситнаго чем тут клевать собственную\\nе темнеет что вы пристаёте ко мне с вашими нелепыми предложениями гнусными как пятикопеечная марка клеенная под ситцевыми занавесками сеенная на звонках в\\nа ей щипцы накладывали\\nр здесь пеших не подточит\\nе полетел и наевшись досыта вернулся и стал смеяться над своими товарищами\\nа есть слишком долгая тюремная подпись\\nяная волна при\\nы животная царица\\nы емечки и е ай и яички и а ыыы ко запры лента лента лентатя\\nветер ветер закричали жалобно дрова\\nй нос как много свистков как много неуклюжих\\nсемечки емей ей е\\nь в карнафейку\\nи каста каста каста каста\\nа на ней сладко спит\\nупсы в карнафейку есть хитрые дома и шинкари забуженные в старах лесах потому что для них кистень с надписью\\nа твоя корзинка полна песочными сугробами полна широких сковородок хвостами полнели нелли по\\nх я на вытянутых вам руках несу вам плод мохнатой стрекоз\\nа лебеда что ты поперхнулась плохо что ты оттататакнулась три воробья сидели на ветке и клевали\\nиз сборника\\nт большая кушетка\\nогонь начал лизаться и причмокивать и морщась торопливо обхватывать дровяной склад\\nшида дикий голос\\nа полна вареников веселько взамахнулось по водке по воде речной кусты шелестелят супруг с супруго\\nи она замужем\\nа дошка дашка доска досченчик досочек\\nе летит насекомое\\nне могус не хочус у меня жена\\nа восах оеных',\n",
       "       'из сборника\\nя с завистью гляжу на зверя ни мыслям ни делам не веря умов произошла потеря бороться нет причины\\nвот воин плавая навагой наполнен важною отвагой с морской волнующейся влагой вступает в бой неравный\\nони испытывают бремя пускай бренчит пустое стремя сходить с ума не надо\\nгде лес глядит в полей просторы в ночей неслышные уборы а мы глядим в окно без шторы на свет звезды бездушной в пустом сомненье сердце прячем а в ночь не спим томимся плачем мы ничего почти не значим мы жизни ждем послушной\\nнам восхищенье неизвестно нам туго пасмурно и тесно мы друга предаем бесчестно и\\nосматривая гор вершины их бесконечные аршины вином налитые кувшины весь мир как снег прекрасный я видел горные потоки я видел бури взор жестокий и ветер мирный и высокий и смерти час напрасный\\nмы все воспримем как паденье и день и тень и сновиденье и даже музыки гуденье не избежит пучины\\nбеспечную забыли трезвость воспели смерть воспели мерзость воспоминанье мним как дерзость за то мы и палимы\\nвозница хилый и сварливый в последний час зари сонливой гони гони возок ленивый лети без промедленья\\nне плещут лебеди крылами над пиршественными столами совместно с медными орлами в рог не трубят победный\\nпусть мчится в путь ручей хрустальный пусть рысью конь спешит зеркальный вдыхая воздух музыкальный вдыхаешь ты и тленье\\nлетят божественные птицы их развеваются косицы халаты их блестят как спицы в полете нет пощады\\nцветок несчастья мы взрастили мы нас самим себе простили нам тем кто как зола остыли милей орла гвоздика\\nтак сочинилась мной элегия о том как ехал на телеге я\\nисчезнувшее вдохновенье теперь приходит на мгновенье на смерть на смерть держи равненье певец и всадник бедный\\nбог нам не владыка\\nв морском прибое беспокойном в песке пустынном и нестройном и в женском теле непристойном отрады не нашли мы\\nвот конь в могучие ладони кладет огонь лихой погони и пляшут сумрачные кони в руке травы державной\\nони отсчитывают время',\n",
       "       'из сборника',\n",
       "       'из сборника\\nбог смени же гнев на милость так на войне рубила шашка солдаты и рыжих и седых как поразительная сабля колола толстых и худых сбирались в кучу командиры шипели вот она резня текли желудочные жиры всю зелень быстро упраздня ну хорошо ревёт чеченец ну ладно плакает младенец а там хихикает испанец и чирикает воробей ты не робей ты знай что ты покойник и всё равно что рукомойник так говорил больному врач держа ручные кисти над водой во фраке чёрном будто грач не в позументах с бородой и с продолжительной тоской вот он какой увы стоял в зверинце стул увы увы там был аул там собиралися казаки и собиралися кусаки и грациозный разговор вели с утра до этих пор был слышен шум тяжёлых шпор увы увы он был мертвец ты не носи ему овец ты не ходи к нему с посудой и не зови его\\nкак же так мая\\nорфеи синицы тёщи и мартышки играют в тусклые картишки но этого ничего не было ему всё это показалось оно воды великой не пило всё быстро в мире развязалось стекло стоявшее доселе в связи с железною дорогой теперь кивает еле еле и стало долгой недотрогой корова бывшая женою четвероногого быка теперь качает сединою под белым сводом кабака и видит как полкан залез в большой стакан звезда казавшаяся ране одною точкою в грязи теперь сверкает на овце на котелке на торговце и всё вообще переменилось о\\nиудой где стул где поле где аул он поплясал и он уснул и снова увидал аул\\nсемирамиду и говорил я бледен беден я будто крыса тощ и вреден во мне остались пустяки четыре печени да костяки но врач ему сказал граждане я думаю что вы не правы и ваше злое ожидание плевок в зелёные дубравы плевок в зелёные растенья добавлю в мира сотворенье вот вам моё стихотворенье ну что зелёные зелёные какие ж могут быть растенья и тучи бегают солёные и куры спят как сновиденья ну что вы мне твердите право про паука и честь и травы вы покажите мне стакан в котором бегает полкан который лает гав гав гав скажу пред смертью не солгав я болен болен как дитя на мне платочков триста штук давай лечебного питья по предписанию наук так молвил больной усмехаясь на север и запад чихаясь но доктор как тихая сабля скрутился в углу как доска и только казённая шашка спокойно сказала тоска мне слышать врачебные речи воды постепенный язык пять лет продолжается вечер болит бессловесный кадык и ухо сверлит понемногу и нос начинает болеть в ноге наблюдаю миногу в затылке колючки и плеть ну прямо иголки иголки клещи муравьеды и пчёлки вот что странно он стал похожим на барана он стал валяться на кровати воображать что он на вате что всюду ходят грёзы феи и',\n",
       "       'из сборника\\nпетром он шепчет я русская баня окончил свое созданье я скупо лег и поблек вот бред речной помолился и будто скотина скучали здесь времени стало два года и дятел на дерево сел он был как ночная природа и бегал вол и цвел и будто время брел но не был он орел\\nбогом костыли мы сядем в злую банку мы поплывём к ветвям на няньку иностранку совпал прелестный свет она упала птицей как мокрый ураган ударилась косицей о каменный курган приходит кладбищенский внук как некий железный каблук и всё рассыпается в прах и всё рассыпается в трах пред нами пучина пред нами причина где корень где аист вещей потом появился отец хотел он законы рожать и химии тусклый птенец начал над ними жужжать тогда приходит ягненок съедаемый без пеленок и проваренный осетром за что не зовут\\nпуть конквистадоров',\n",
       "       'из сборника\\nкронштадт гордой дудкой мчатся волны мел играет мёртвой стенкой в даль кидает как водичку спит пунцовая соломка на спине сверкает три полк английский ерусланский шепчет важное ура торг ведёт монах с василием где часовня жабой русою улыбается густой каймой на штыки на третье рождество дым и пень котёл и паучок скоро сядет на холму воробышек голубой как утка пиротехничек ты сова копилка птица глупая тень диван татары лунь павлин уж летят степные галки уж горячей пеной по небу в шесть мечей сверкают башни и блестят латинским маслом волосами щит лазурный вмиг покрылся как гусёныш кипите кости в жиже бурной варенье чёрное в стаканах уста тяжёлого медведя горели свечкою в берлоге они открылись и сказали на гуслях смерть играет в рясе она пропахшему подружка чу сухорукие костры свиная тихая колхида горели мясом\\nрысь женилась\\nпуть конквистадоров',\n",
       "       'из сборника\\nмы немного в один миг охватываем оком\\nнам прохожий говорит скорбь вас не охватила\\nно увидев тело музыки вы не заплакали навзрыд\\nнас кругом росли цветы звёзды люди и дома\\nбудем думать в ясный день сев на камень и на пень\\nбога это всё исчезающая дорога\\nи только один звук ощущает наш нищий слух\\nмы сказали да это очевидно всё это нам очень обидно\\nнам непонятное приятно необъяснимое нам друг мы видим лес шагающий обратно стоит вчера сегодняшнего дня вокруг\\nмы сказали да это очевидно часа назад нам не видно\\nи я полетел как дятел воображая что я лечу\\nнас кругом трепещут птицы и ходят синие девицы\\nбог и спроси лису что лиса от утра до вечера далеко от слова разумеется до слова цветок большое ли расстояние пробежит поток\\nно где же где же нас кругом теперь отсутствующий гром\\nмы сидели в этот миг мы смотрели всё на них\\nс гор высоких и крутых быстро падала вода\\nи печальную часть наук постигает наш дух\\nответит лиса на вопросы\\nзвезда меняется в объеме стареет мир стареет лось\\nмы подумали нам очень одиноко\\nда музыки волшебное светило погасшее имело жалкий вид\\nлисицы и жуки в лесу понятия на небе высоком подойди\\nбог рыба и небо исчез тот кусок навсегда очевидно с нашего света\\nпрохожий ты брось неумное уныние гляди кругом гуляют девы синие как ангелы собаки бегают умно чего ж тебе неинтересно и темно\\nи ощущение покоя всех гладило своей рукою\\nв морей солёном водоёме нам както побывать пришлось где волны издавали скрип мы наблюдали гордых рыб рыбы плавали как масло по поверхности воды мы поняли жизнь всюду гасла от рыб до\\nты или я или он мы прошли волосок мы и не успели посмотреть минуту эту а смотрите\\nи тут мы полетели\\nночь царственная начиналась мы плакали навек\\nнас кругом сияет день под нами камень под нами пень\\nмы созерцаем часть реки мы скажем камню вопреки где ты ночь отсутствуешь в этот день в этот час искусство что ты чувствуешь находясь без нас государство где ты пребываешь\\nпрохожий подумал он спятил он богоподобен сычу\\nбога и звезды',\n",
       "       'нарисует страсть и горе\\nиз сборника\\nгде темнеет глаз кружок\\nона танцует полупьяная\\nшикарный вечер догорал\\nкто в свирель кафешантанную\\nбыл бой зрачков в неё влюблённых\\nскрипач и плач трубы\\nпуть конквистадоров\\nнежнейших ног обтянутых в трико\\nи извиваясь телом голубым\\nна краснеющем диване\\nон придёт ревнивый\\nпролив слезу\\nгде сладострастно дремлют франты\\nпьянеет музыка печальных скрипок\\nмы вечера плетём как банты\\nна лице своём усталом\\nв ресторанах злых и сонных\\nк ней танцующей в тумане\\nзимним вечером поёт\\nв глазах давно опустошённых\\nиз соврем романса\\nплатье тонкое распорет\\nкружась над чёрною ногой\\nмерцанье ламп надменно и легко\\nноябрьдекабрь\\nаргентинское танго\\nа он попрежнему гуляет вечерами\\nзабавноресторанная\\nуж не подняться с пышных кресел\\nв ночных шикарных ресторанах\\nно лживых песен танец весел\\nлежит под красным светом фонаря\\nвлюблённых в тихое танго\\nсверкал недопитый бокал\\nв ночную синюю косу\\nи с ним свинцовая заря\\nоб убийстве в ресторане\\nи подают сверкающий напиток\\nон пронзит её кинжалом\\nтанцовщица с умершими руками\\nа на эстраде утомлённой',\n",
       "       'из сборника\\nзимний день на\\nпод глазами синева\\nах зачем же тихо стонет\\nпепел сердца моего\\nотворика отвори\\nна четвёртом этаже\\nя любила вас не зная\\nразболелась от потери\\nвсё по комнатам гуляю\\nно ждала вас до зари\\nзакружилась голова\\nодиноко в неглиже\\nрвётся ночью ветер в окна\\nпусть мои закрыты двери\\nвы сдуваете с ладоней\\nя задумалась глубоко',\n",
       "       'из сборника\\nщепина в гробу лежала как спина и из тропической земли слоны цветочков принесли цветочек тюль цветочек сон цветок июль цветок фасон апреля\\nстолыпин дети все кричат в испуге молодом а няньки хитрые ворчат гоморра и содом священник вышел на погост и мумией завыл вращая деревянный хвост он человеком был княгиня\\nдрожала мать крутя фуражкой над бедной дочкою своей а дочка скрючившись барашком кричала будто соловей мне больно мама я одна а в животе моём\\nбоже говорит он правый во имя\\nпуть конквистадоров\\nдвина её животик был как холм высок и очень туп ко лбу её прилип хохол она сказала скоро труп меня заменит здесь и труп холодный и большой уж не попросит есть затем что он сплошной икнула тихо\\nотец и мать\\nмать и дочь\\nзаболоцкому я выхожу из кабака там мёртвый труп везут пока то труп жены моей родной вон там за гробовой стеной я горько плачу страшно злюсь о гроб главою колочусь и вынимаю потроха чтоб показать что в них уха в слезах свидетели идут и благодетели поют змеёю песенка несётся собачка на углу трясётся стоит слепой городовой над позлащённой мостовой и подслащённая толпа лениво ходит у столба выходит рыжий генерал глядит в очках на потроха когда я скажет умирал во мне была одна труха одно колечко два сморчка извозчик поглядел с торчка и усмехнувшись произнёс возьмём покойницу за нос давайте выколем ей лоб и по щекам её хлоп хлоп махнув хлыстом сказал кобыла андреевна меня любила восходит светлый комиссар как яблок над людьми как мирновременный корсар имея вид семи а я стою и наблюдаю тяжко страшно голодаю берёт покойника за грудки кричит забудьте эти шутки когда здесь девушка лежит во всех рыданье дребезжит а вы хохочите лентяй однако ктото был слюнтяй священник вышел на помост и почесавши сзади хвост сказал ребята вы с ума сошли она давно сама скончалась пошли ребята вон пошли а песня к небу быстро мчалась о\\nщепина в своём вертепе и легко и славно жила княгиня\\nвышла пена и стала твёрдой как полено монашка всхлипнула немного и ускакала как минога я погружаюсь в благодушную дремоту скрываю непослушную зевоту я подавляю наступившую икоту покуда все не вышли петухи поесть немного может быть ухи в ней много косточек янтарных жирных сочных мы не забудем благодарны пуховиков песочных где посреди больших земель лежит красивая мамзель тут кончил драться генерал с извозчиком нахальным извозчик руки потирал извозчик был пасхальным буржуй во\\nфранцию бежал как злое решето француз французку ублажал в своём большом шато вдова поехала к себе на кладбище опять комуто вновь не по себе а ктото хочет спать и вдруг покойница как снег с телеги на земь бух но тут раздался общий смех и затрещал петух и время стало как словарь нелепо толковать и поскакала голова на толстую кровать\\nдержавы тут начал драться генерал с извозчиком больным извозчик плакал и играл и слал привет родным зашёл на дерево буржуй оттуда посмотрел при виде разных белый струй он молча вдруг сгорел и только вьётся здесь дымок да не спеша растёт домок я выхожу из кабака там мёртвый труп везут пока интересуюсь я спросить кто приказал нам долго жить кто именно лежит в коробке подобно гвоздику иль кнопке и слышу голос с небеси мона монашенку спроси монашка ясная скажите кто здесь бесчувственный лежит кто это больше уж не житель уж больше не поляк не жид и не голландец не испанец и не худой американец вздохнула бедная монашка без лести вам скажу канашка сей мёртвый труп была она княгиня\\nтарас её рождали сорок тысяч раз она жила она любила моду она любила тучные цветы вот както скушав много мёду она легла на край тахты и говорит скорей мамаша скорей придите мне помочь в моём желудке простокваша мне плохо плохо\\nбоже прими создание\\nтвоё пусть без костей без мышц без кожи оно как прежде заживёт о\\nбоже говорит он\\nниколавна она лицо имела как виденье имела в жизни не одно рожденье',\n",
       "       'было дело под\\nиз сборника\\nфедором было б веселей тут все войско моё зарыдает навзрыд закричит заговорит вот несчастный какой с той поры и здесь трактир год\\nполтавой голенький сидит\\nмазепа говорит был бы\\nполтавой нет не дело а медаль мы дрались тогда со шведкой чуть что вправо мы налево тсс видим побежала юбку синюю порвала я кричу остановись чуть что вправо мы налево за сосною под\\nпуть конквистадоров',\n",
       "       'я прохожу по улице\\nиз сборника\\nвздыхаю пред огнём\\nчто ж делать больше нечего\\nи плачу долгим вечером\\nя в лавке продовольственной\\nмой друг мой верный друг\\nвсё помню с удовольствием\\nмоё подымет платье\\nиграет на корнетеапистоне\\nна голубом балконе\\nиз длинных синих рук\\nв очередях стою\\nи думаю о нём\\nвесёлый ветерок\\nстановишься распутницей\\nв юбке до колен\\nтак много перемен\\nпоследнее люблю\\nиграя на закате\\nв краснеющий рожок',\n",
       "       'бог ответил хорошо\\nиз сборника\\nконь степной бежит устало пена каплет с конских губ\\nон был нестрашный\\nон обратною рукою показал мне над рекою рыба бегала во мгле отражаясь как в стекле\\nболь мою пронзила кость\\nя решил я согрешил значит\\nчеловек стал бес и покуда будто чудо через час исчез\\nбог меня лишил воли тела и ума\\nне помню твердо было все черно и гордо\\nвечер был на расстояньи от меня на много верст\\nнет я все увидел сразу поднял дня немую вазу я сказал смешную фразу чудо любит пятки греть\\nя сидел и я пошел как растение на стол как понятье неживое как пушинка или жук на собранье мировое насекомых и наук гор и леса скал и беса птиц и ночи слов и дня\\nчеловек из человека наклоняется ко мне на меня глядит как эхо он с медалью на спине\\nя услышал конский топот и не понял этот шепот я решил что это опыт превращения предмета из железа в слово в ропот в сон в несчастье в каплю света\\nгость ночной тебя не стало вдруг исчез ты на бегу\\nко мне вернулся день вчерашний\\nповернулся боком конь и я взглянул в его ладонь\\nв кипятке была зима в ручейке была тюрьма был в цветке болезней сбор был в жуке ненужный спор\\nгость я рад я счастлив очень я увидел край коня\\nконь был гладок без загадок прост и ясен как ручей\\nни в чем я не увидел смысла\\nя услышал дверь и шкап сказали ясно конский храп\\nконь бил гривой торопливой говорил я съел бы щей\\nя забыл существованье слов зверей воды и звезд\\nя забыл существованье я созерцал вновь расстоянье\\nсвет возник слова возникли мир поник орлы притихли\\nдверь открылась входит гость\\nты может быть отсутствуешь\\nя собранья председатель я на сборище пришел',\n",
       "       'из сборника\\nя понимаю я мысль из тела вынимаю кладу на стол сию змею её ровесницу мою я бегаю пустой по\\nя вижу лес я долго спал\\nя буду я тут и я там малютку и будду комуто отдам индийские черти речка течёт два часа смерти а\\nгосподи то больше то лакомка то только дольше вообще я был как сумасшедший за мной виднелся только рай и каждый голубь лев прошедший кричал скачи и помирай куда умрёшь\\nвсемогущий через райские кущи сквозь пустые вершины сквозь моря и машины\\nб е г у щ и й в о л к смешно о чём тут разговор я мимо шёл\\nя залез я подошёл в тоске дыша какая скука не меня под потолком сидит душа как тетерев себя маня\\nф а к т однако ужасен таинственный факт где это горы и где тот антракт что знаем мы дети о\\nпетроград шли кумиры и виднелись ордена на них блестят а пришли оцепенели стали песней не летят\\nв о п р о с мы где\\nб о г подымаясь садитесь вы нынче мои гости\\nо т в е т мы кости к о н е ц апреля\\nи что сожрёшь\\nбог наступил хмуро и тщательно всех потопил\\nв о п р о с это поле люди поле боевое еду на верблюде еду я и вою вою боги о звезде где убогие\\nк у м и р ы мы есть мы мы из тьмы вы есть вы где же львы мы рабы сидим и плачем и в гробы грозою скачем и открытые как печь верно значим лечь иль жечь\\nф а к т ты сидишь в беседке мира звёздам и планетам брат по дороге два кумира шли из\\nт е о р и я я сегодня скончался ты скончался вчера кто из нас причащался\\nд у ш а иди сюда я иди ко мне я тяжело без тебя как самому без себя скажи мне я который час скажи мне я кто я из нас\\nя вижу двор покойник поле\\nбоге и сне где горы эти\\nф а к т и в это день меня манил магнит малюток и могил я утром встал я сел на ленту цвела листва я поклонился монументу и тихо вышел за дрова был сон приятным шло число я вижу ночь идёт обратно я вижу люди понесло моря монеты и могилу мычанье лебедя и силу я вижу всё и говорю и ничего не говорю я всё узнал\\nбоге дети люди друзья мы с тобою на небе это ты это я\\nо т в е т на той сосне в конце отвечало торчание скал вот смерти начало а я вас искал да очевидно скажу не крестясь что ночь грушевидна вскричал воротясь с того постороннего света и мигом увидев всё это я был там\\nф а к т значительной не знал эпохи конец и смерть родные блохи осталось что лежать и зреть и на себя в кулак смотреть осталось что сидеть и гнить из смерти чудом вырвать нить которые мёртвые которые нет идите четвёртые в тот кабинет здесь окончательно\\nо т в е т три пера\\nпольше крича то\\nо т в е т везде\\nв о п р о с что мы знаем о',\n",
       "       'из сборника\\nпуть конквистадоров\\nлежит на жёрдочке\\nласкает звёздочки\\nтемнее тамошних туземцев\\nсижу на тумбе я\\nмои глаза в\\nк скучной скуке\\nа солнце мёртвое\\nтарарабумбия\\nрука простёртая\\nпростерты руки\\nа в руках белое полотенце\\nу неё узкая талия',\n",
       "       'из сборника\\nпуть конквистадоров\\nбога умолить а дождик льёт и льёт и стенку это радует тогда францусские чины выходят из столовой давайте братцы начинать молвил пениеголовый и вышиб дверь плечом на мелочь все садятся и тыкнувшись ногой в штыки сижу кудрявый хвост горжусь о чем же плачешь ты их девушка была брюхата пятнашкой бреются они и шепчет душкой оближусь и в револьвер стреляет и вся страна теперь богата но выходил из чрева сын и ручкой бил в своё решето тогда щекотал часы и молча гаркнул на здоровье стали прочие вестись кого они желали снять печонка лопнула смеются и всетаки теснятся гремя двоюродным рыдают тогда привстанет царь немецкий дотоль гуляющий под веткой поднявши нож великосветский его обратно вложит ваткой но будет это время печь температурка и клистирь францусская царица стала петь обводит всё двояким взглядом голландцы дремлют молодцы вялый памятник влекомый летал двоякий насекомый очки сгустились затрещали ладошками уж повращали пора и спать ложиться и все опять садятся\\nь пушечна тяжба зачем же вам бежать молочных молний осязуем гром пустяком трясёт пускаючи слезу и мужиком горюет вот это непременно но в ту же осень провожает горсточку их было восемьдесят нет с петром кружит волгу ласточку лилейный патрон сосет лебяжью косточку на мутной тропинке встречает ясных ангелов и молча спит болото садятся на приступку порхая семеро вдвоём и видят финкель окрест лежит орлом о чем ты кормишь плотно садятся на весы он качается он качается пред галантною толпою в которой публика часы и все мечтали перед этими людьми она на почки падает никто ничего не сознаёт стремится\\nт и думаю что нету их васильев так вот и затих среда октября\\nмы взошли на\\nбоже этот тихий мост где сиянье любим православных мест и озираем озираем кругом идущий забор залаяла собачка в кафтане и чехле её все бабкою зовут и жизненным бочком ну чтобы ей дряхлеть снимает жирны сапоги ёлки жёлтые растут расцветают и расцветают все смеются погиб вот уж лет бросают шапки тут здесь повара сидят в седле им музыка играла и увлечённо все болтали вольно францусскому коту не наш ли это лагерь цыгане гоготали а фрачница легла патронами сидят им словно кум кричит макар а он ей говорит и в можжевелевый карман обратный бой кладёт меж тем на снег садится куда же тут бежать но русские стреляют фролов егор свисток альфред кровать листают',\n",
       "       'из сборника\\nи сверкает как костёр в пылком небе метеор\\nняню демон вопросил няня сколько в мире сил\\nзвери лазали за мной я казался им герой а приснился им горой\\nи построили фонтан и шкатулку и шантан во шантане веселились во фонтане дети мылись\\nмолча ели мы кисель лёжа на кувшине льда\\nмы рогатые бараны\\nсмерть меня поколебала я на землю упаду под землёй гулять пойду\\nняньки бегали с ведёрком по окружности земной\\nбоже мы развешаны\\nвсё проходит без следа\\nбоже мы помешаны мы на дереве висим в дудку голоса свистим шашкой машем вправо влево как сундук и королева\\nна обоях человек а на блюдечке четверг\\nзвери плача ты висел\\nбросьте звери дребедень настаёт последний день новый кончился шильон мир ложится утомлён мир ложится почивать\\nвсё казалось им тетёркой\\nсатурна бесшабашно вольно бурно существует квакает так что кольца крякают\\nкак жуир спешит тапир на земли последний пир\\nпоявились кровопийцы под названием убийцы с ними нож и пистолет жили двести триста лет\\nона взлетела со стола как соловей и пастила теперь живёт в кольце\\nсила первая светло и за ней идёт тепло а за ней идёт движенье и животных размноженье\\nотчего спросил верблюд\\nон кончает все дела\\nмы во льду видали страны\\nя лягушку родила\\nя не ем тяжёлых блюд\\nотвечала няня две обе силы в голове\\nчеловек сидит на ветке и воркует как сова а верблюд стоит в беседке и волнуется трава\\nно верблюд сказал дурак ведь не в этом сходство тел в речке тихо плавал рак от воды он пропотел но однако потный рак не похож на плотный фрак пропотевший после бала\\nбог собрался ночевать\\nчеловек сказал верблюду ты напомнил мне',\n",
       "       'петра дряхлым шагам внимая заря поёт до утра\\nиз сборника\\nземля ещё дышит красными шестами мятежей\\nшаги прозвучат ещё тише по дорогам соседних аллей\\nа каменные солдаты мечтающие о хлебе проваливаются в квадраты просверленные на небе\\nбезкосые китайцы ждут звёздной руки\\nна набережной болтаются дома у самой реки\\nвнимания не обращая ни на\\nвеликого ни на',\n",
       "       'из сборника\\nбога исцели трещотками брели музеи ему давали скипидар горчишники с тремасом и он как бы поэт\\nпиндар давился пышным квасом улыбались ночи расам бабкою на сундуке с незабудкою в руке что за ночи просто ночь не улыбки бестолочь он тогда опять заснул и в париж прилетел но проснулся на столе между прочих блюд и дел и доставши воротник отвинтил бумажку чтоб монах стоявший вник и прочёл ромашку а в бумажке написал это деньги я сказал июня\\nбоже мой уха я видел день течёт затейливо во сне носилась чепуха и всё кругом насмешливо пред смертью улыбалось вежливо доставши бабушкин цилиндр и кофту бумазейну молил я\\nсоню она платку благодаря дала мне сон богатыря и я лежал немой как соня и я глядел в окно смешное и в трёх шагах гулял один иеромонах я думаю вот добрый вечер кафтан пустой кому перечить лишь полки пальмами висят да в уголках бобы свистят они себе ломают шляпу они стучат в больные лапы медведи волки тигры звери еноты бабушки и двери наставница скажу я тихо обои потеревши лихо обедают псалмы пошведски а в окнах разные челны благовонный воздух светский станет родственник волны тогда ко мне бегут сажают на скрипке песням ужасают а он смеюсь а он боюсь мамаша с ним колечком бьюсь прошли два года как листва да в уголках бобы свистят тогда одевшись кораблём он рассуждает королём и неподвижный яблок ест на седалище прежних мест как скворец мы поём нивы хижины всё поймём а если зря лежишь в горячке как бы коран как бы коран блюдите детство на карачках так в кипятке шипит кора я поднял свой голос сонный он сказал это всё сионы иерусалимы хижины франции где циклопы и померанцы я хотел вступить с ней в брак но пришлось поехать в барак в боку завёлся червяк оказалось он был мертвяк на шляпе выросло перо друзья вон поезд выбегает на перрон осыпан снежною судьбой заняться хочет молотьбой поля прелестные кругом наставница читала каблуком и поднимая ввысь глаза ей с неба падала лоза она уже читалась вся лишь полки пальмами висят я спал как',\n",
       "       'из сборника\\nфранц весёлый возгласил дайте\\nфранца появляется из ранца человеческий ровесник и психолог божества объявляет нам кудесник вмиг начало торжества звёзды праздные толпятся люди скучные дымятся мысли бегают отдельно всё печально и бесцельно\\nобера ракету лошадиных дайте сил я поеду по вселенной на прекрасной этой конке я земли военнопленный со звездой устрою гонки с потолка взгляну на мох я синица я между тем из острой ночи из пучины злого сна появляется веночек и ветвистая коса ты сердитая змея смерть бездетная моя здрасте скажет\\nфранц сохранял протуберанц от начала до конца не спускался он с крыльца мерял звёзды звал цветы думал он что я есть ты вечно время измеряя вечно песни повторяя он и умер и погиб как двустволка и полип он пугаясь видел юбку фантазируя во сне и садясь в большую шлюпку плыл к задумчивой сосне где жуков ходили роты совершали повороты показав богам усы говорили мы часы боги выли невпопад и валились в водопад там в развесистой траве созидался муравей и светляк недобрый царь зажигал большой фонарь молча молнии сверкали звери фыркали в тоске и медлительно рычали волны лёжа на песке где же где всё это было где вращалась эта местность солнце скажет я забыло опускаясь в неизвестность только видно нам у\\nфранц в тоске в каждом вашем волоске больше мысли чем в горшке больше сна чем в порошке вы достаньте вашу шашку и разрежьте мне рубашку а потом разрежьте кожу и меня приклейте к ложу всё равно жива наука я хрипя проговорю и себе на смену внука в виде лампы сотворю будет внук стоять сиять сочинения писать смерть сказала ты цветок и сбежала на восток одинок остался\\nфранц созерцать протуберанц мерить звёзды звать цветы составляя я и ты лёжа в полной тишине на небесной высоте или\\nбоже что за торжество прямо смерти рождество по заливам ходят куры в зале прыгают амуры а железный паровоз созерцает весь навоз\\nфранц проснулся сон зловещий для чего здесь эти вещи тут как пальма стал слуга сзади вечности луга невысокий как тростник спит на стуле воротник керосиновая ветвь озаряет полумрак ты кудесник мне ответь сон ли это я дурак но однако где кудесник где психолог божества он во сне считает песни осыпаясь как листва он сюда придти не может где реальный мир стоит он спокойно тени множит и на небе не блестит дайте турки мне карету',\n",
       "       'е геометры он знает вы все театралы\\nперсии не все\\nа какая звон\\nплесневая струйка ползёт в ней царствует бенз\\nй татарин у тебя хорошие усы\\nв а вам вам\\nнас немного карликов мы глухие жолобы а седло у нас будапешт туркестан суламифь конь есть од\\nа шопышин а мост поперечен крыло поломали стало как в бочке стало сельдь была голова круглой хвост был длинный глаза два гривенника агарусный\\nструйка тиртиртир ляски это не отверстие мячик гриб в углу а над грибом одна звёздочка и страшно высоко как пустошь написано было\\nвспыхнул керосин и потух полосы ночные пошли и выглянув изза лампы пуп и застыл\\nнет не театралы мы мы все нищие духом мы все мошенники голенькие и из другой земли и у нас чолы есть потому в пробках\\nзка в самом тёмном зеркале рожа мухомориная стала на пятки железные лапки бьёт барабан верблюжьим мясом\\nиз зеркальных кустарников бутоны мед и столбы летели из широких штор а улыбка их была не понятна пустынник дверцу отворил её войти он пригласил светила тусклая звезда и лампочку жестяную зажёг стояло колесо большое и деревянная большая дверь закрыла дождь и ночь и стала как пустое о толстая шершавая скамейка твой платок стоит тёплый стены были в голых брёвнах твоя тёплая нога она босая как богиня горячая как утюг прелая потная башня падать начнёт с мохом здесь не будет ни одного странника не будет ни одного комода они из пены как венера и зачем им быть а твоя стеклянная копилка всё равно на слом пошла вот сидел и щупала пальцы щупал пальцы керосин ревел где орлы тяжёлые ворота необозримые ночные пряжки всё только мельницы да снова мельницы из кусочков бархата и кожи холод лёг на почтовый ящик и глаза отчаянные страстные как кожа уток\\nк моя добрая старушка ны славная обкуренная трубка\\nгнедые смутные вокзалы коней пустынных позабудешь зачем с тропинки не уходишь когда дороги побегут тяжёлых песен плавный жар шумят просторы чёрной ночи летят сухие сны костылик от чёрных листьев потемнели и рукомойники и паства певцы пустыни отчего замолкли испорчен плащ печальна ночь у печки у печки что ж не у широких рощ не у широких рощ глаза твои желты и дои твой бос но не на сердце скал не на огромных скал певец пузатый прячет флейту спокойствие вождя температур\\nи прекрасный ты столяр\\nленинградскому отделению\\nн в узком плать\\nисидоры кусы не все леса но\\nи отчего нестругана доска оттого что сгнила\\nи три угла четыре колокольни три боба нестругана доска стало сердце\\nф ты отчего ржавая отчего на простынях отчего при лампочке\\nиз сборника\\nвы были родом из\\nу пасмурных больших колыбелей ноготками\\nь что иным детям безрассудно то вам\\nн ны моя ны моя маленькая грязная ны моя нечистоплотная ны моя милая хорошая ны\\nв ленинградское отделение\\nя и фаддей старенькая наша дедушка\\nвсероссийского союза поэтов стихов александравведенского\\nи большие звёзды и одни большие лица как коричневая пакля выкрашенные потому в цвет все деревья в кушаках\\nк стонет тесная нищенка',\n",
       "       'два конца два кольца\\nиз сборника\\nлюди в белых балахонах\\nматерия хрюкнула\\nа из зеркал на них\\nстрекозы над прудом а солнце жарит',\n",
       "       'из сборника\\nверть колес осей гармонизация аккорда\\nдуговой фонарь лунит у стены\\nтраурны на телегах ломовые возчики\\nброшу в оси вопросы и росчерки\\nпробрильянтят воду златорваной бахромой\\nа с той стороны созвездья двоюродных фабрик\\nи плачут котлы пламенем поблескивая\\nтам спички в пачки доски потрескивают\\nпод грозовыми облаками\\nа оттуда не пускает железный болт\\nремни мнутся на лясканье колес\\nздесь каждый фонарь изумительно жёлт\\nи сплевывая в воду закачаются домой\\nа вечером выйдут закопченные на берег\\nна мне кепка и сальные штаны\\nя пришел из клеточек и созвездий города\\nплотными каплями нефтяных слез\\nстихотворения',\n",
       "       'из сборника\\nаэролит протрясся\\nмолчание верблюда\\nна серебре степного блюда\\nв копытах гул булыжных гирь\\nа то придет погонщик\\nгорбы с курганами обнимутся уснут\\nмхом обволок клокастый войлок\\nпуды усталого мяса\\nпод грозовыми облаками\\nвращать чигирь\\nплевком колючим плюнет кнут\\nна зареве зари верблюжий выгиб тоньше\\nпо колеям небесного сосуда\\nна ироничном рте болтается увязка\\nверблюд беги\\nсвежо степное ветряное пойло\\nна шали зарева закатного кургана\\nверблюд пойдет на утро вязко\\nстихотворения',\n",
       "       'из сборника\\nвесну к декабрям седым и недобрым\\nсвоих берегов на океанский голос\\nстанового хребта\\nскользит и не ляскнет и крутит и сеет\\nхомутом облаков перетертый загривок\\nпо шлифу русла синеет намасленный\\nзеленые сани поставив на полоз\\nенисей сквозь драные ребра\\nклюкой восхода лукнутая криво\\nворгулят беспамятно на речушном наречии\\nтут туг приводный ремень\\nоблака разлеглись в синебах\\nгорам перемалывая всхлипынапраслины\\nчерез стремглавит солнца лапта\\nфарфоровый павильон\\nтам младенцыистоки реки\\nна меня поглазеть через рыхлые плечи',\n",
       "       'из сборника\\nв иероглифах мифа бархат\\nзубами стен назои скрипок\\nгрызет и грезит полночьжужелица\\nгвоздей звездящих сыпких бус ли\\nпуть конквистадоров\\nгангреной пищи обложил\\nпосевы звезд взойти мерещатся\\nзеленозвездое тысячеточье\\nнабрызган мраку емкий ковшик\\nвращает небосвод\\nи если голову закину\\nшушуки спален проколовши\\nувижу время с донным звоном\\nночной торговли ноют гусли\\nнад мыком городамонарха\\nи апельсины фонарей\\nзызыкнут гзонгом звонари\\nторжественный как свод законов\\nжуя перегрызают жилы\\nчудовно зреют у дверей\\nбагрея зреют фонари\\nоцепенело неба в стуже лицо\\nдраконью кожу распяли ночью\\nиз язв харчевен тучный выпах\\nпо древесине века резчица',\n",
       "       'из сборника\\nголубь извне к стеклу жмется\\nконьки на шкафу зазвякали\\nгород в нижнем белье\\nхрупкие листья червонцами на горностаевое боа\\nа глаза у него морознооранжевые\\nмелки положены на подоконники\\nоранжевокрасное небо\\nпуть конквистадоров',\n",
       "       'из сборника\\nпод грозовыми облаками\\nпарное молоко обдает\\nпервая спица мигнула в колесе\\nпервый дымок новой трубы\\nбелый комок снега первого\\nдайте на руки\\nрасправляется\\nстихотворения\\nпобожись что не будешь как все',\n",
       "       'из сборника\\nна закукорки сев неряха\\nсо сраму ль подолом зеленым закрыла\\nгребенки и шпильки соборов\\nв старичьем шамкале запах косушки\\nтужит поромы утлые\\nспод подолу река\\nвтыкает во вшивые кудлы\\nроссии грязная ватка\\nв заборах застряла домишками\\nмыста мол тоже не сопля на рогоже\\nвлезла в овраги лапой\\nрыжие простыни смяв\\nплечом чешась о город что боров\\nвразвалку разбряка\\nнемытое рыло\\nгубы развесила что белье для просушки\\nстарая растяпа\\nфарфоровый павильон\\nс еловым умишком',\n",
       "       'пей пей пена перельется\\nсо святыми упокой\\nшарят горбатые люди\\nиз сборника\\nисайя ликуй\\nвместо лиц платки носовые\\nкадило воздух проломило\\nфарфоровый павильон\\nполем пахнет',\n",
       "       'из сборника\\nперевит паровик\\nоблаков козлиная пряжа\\nв карманы тоннелей звончей и быстрее вал\\nи только на вышках ушами хлопала\\nноровит ось рычать\\nпод грозовыми облаками\\nжелезной кобылой горы простреливал\\nверстоглот в колокола галопа\\nмигдень мигночь певуч ковач\\nи снова выскакивал снежный хохол\\nтонули в тоннели летун рвач\\nв черепе скал зрачки искал\\nсвирелями рельс ореян\\nбагулом и гулом\\nвсколотил подмышками кряжа\\nстихотворения\\nтоннели тянули черный чехол',\n",
       "       'орни глоткой рабочей\\nиз сборника\\nесли когданибудь после смерти\\nи прочая и прочая\\nшвырь огого хахаха во взрыв\\nпока летят каменья\\nесли нашей строкой\\nстолькото золотом\\nкомсомольским билетом\\nассигнуют по смете\\nи ближнею ж ночью\\nбоевым кулаком\\nпо черепу бить бить бить\\nвдребезги и навзрыд\\nне позволим\\nглыбы собьют на глыбы\\nвали наши книги\\nнам говорить спасибо\\nговорите короче\\nи пятиконечной звездой\\nвыстрелом сердца\\nкрасенью губ\\nбыл жив и остер\\nо гегемонии гегегениев\\nчтоб собственный выгиб\\nпод каменный трон\\nи рукопожимом товарища\\nнашей же книгой\\nнам футуристам в драке измолотым\\nночью вложить динамитный патрон\\nчугун футуристов\\nу столба гегегения\\nучись учись такойсякой\\nбудут бить как портновским аршином\\nне сметь перечить великим теням\\nбровями сведенными вчтооо\\nдо мездры мозгов\\nсо всхлипом на многоточиях\\nфарфоровый павильон\\nнас становить чугунных\\nзаводским гудком\\nи с той кто целует тебя',\n",
       "       'из сборника\\nобведен самый дальний увал\\nа легкая плоская лунка\\nхолод ошеломил поля\\nрасколется легче стекла\\nи воздух дрогнет как струнка\\nпод грозовыми облаками\\nплавниками не шевеля\\nи вязаный шарф до ушей\\nоблако проплывает как рыба\\nпродавит озер зеркала\\nтвердый лес после летнего флирта\\nнеподвижна воздуха глыба\\nв октябре есть привкус спирта\\nнад серьезью речных голышей\\nу меня румянец тунеядца\\nзолотые кольца сковал\\nстихотворения\\nи хочется вслух рассмеяться'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('data/all_poems.csv').text.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8863284c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>путь конквистадоров\\nбоже правый на скале но о...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>зимним вечером поёт\\nплатье тонкое распорет\\nс...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>й фрер мой аркаша онкль бинокль это\\nребёнок ч...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>гость ночной тебя не стало вдруг исчез ты на б...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>всероссийского союза поэтов стихов александрав...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>нам восхищенье неизвестно нам туго пасмурно и ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>путь конквистадоров\\nрим и с монашкой говорим ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>бог рыба и небо исчез тот кусок навсегда очеви...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>он думал уснув что это идёт по дороге не тело ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>мне страшно что я при взгляде на две одинаковы...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>путь конквистадоров\\nа в руках белое полотенце...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text\n",
       "0   путь конквистадоров\\nбоже правый на скале но о...\n",
       "1   зимним вечером поёт\\nплатье тонкое распорет\\nс...\n",
       "2   й фрер мой аркаша онкль бинокль это\\nребёнок ч...\n",
       "3   гость ночной тебя не стало вдруг исчез ты на б...\n",
       "4   всероссийского союза поэтов стихов александрав...\n",
       "5   нам восхищенье неизвестно нам туго пасмурно и ...\n",
       "6   путь конквистадоров\\nрим и с монашкой говорим ...\n",
       "7   бог рыба и небо исчез тот кусок навсегда очеви...\n",
       "8   он думал уснув что это идёт по дороге не тело ...\n",
       "9   мне страшно что я при взгляде на две одинаковы...\n",
       "11  путь конквистадоров\\nа в руках белое полотенце..."
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = df.drop(index=10)\n",
    "df.head(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bd37caaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "df = pd.read_csv('data/all_poems.csv')\n",
    "for i, value in enumerate(df.text.values):\n",
    "    if len(re.findall('\\n', value)) == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e57c7e52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43, 1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "df = pd.DataFrame(columns=['text'])\n",
    "poems = []\n",
    "\n",
    "for poem in os.listdir('data/poems/'):\n",
    "#     print(pd.read_csv(f'data/poems/{poems}'))\n",
    "    poems.append(pd.read_csv(f'data/poems/{poem}'))\n",
    "    \n",
    "df = pd.concat(poems)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4f88d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data  lyrics-generator\trequirements.txt  teaching_a_model.ipynb  venv\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4629a2f4",
   "metadata": {},
   "source": [
    "# Installing needed packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "daf2ac82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow_text in ./myenv/lib/python3.9/site-packages (2.7.3)\n",
      "Requirement already satisfied: tensorflow-hub>=0.8.0 in ./myenv/lib/python3.9/site-packages (from tensorflow_text) (0.9.0)\n",
      "Requirement already satisfied: tensorflow<2.8,>=2.7.0 in ./myenv/lib/python3.9/site-packages (from tensorflow_text) (2.7.4)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in ./myenv/lib/python3.9/site-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.6.3)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in ./myenv/lib/python3.9/site-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (3.19.6)\n",
      "Requirement already satisfied: h5py>=2.9.0 in ./myenv/lib/python3.9/site-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (3.9.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./myenv/lib/python3.9/site-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.59.0)\n",
      "Requirement already satisfied: flatbuffers<3.0,>=1.12 in ./myenv/lib/python3.9/site-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (2.0.7)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in ./myenv/lib/python3.9/site-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (0.34.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./myenv/lib/python3.9/site-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (2.3.0)\n",
      "Requirement already satisfied: libclang>=9.0.1 in ./myenv/lib/python3.9/site-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (16.0.6)\n",
      "Requirement already satisfied: six>=1.12.0 in ./myenv/lib/python3.9/site-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.15.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in ./myenv/lib/python3.9/site-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.1.2)\n",
      "Requirement already satisfied: gast<0.5.0,>=0.2.1 in ./myenv/lib/python3.9/site-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (0.4.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in ./myenv/lib/python3.9/site-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.15.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in ./myenv/lib/python3.9/site-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (2.7.0)\n",
      "Requirement already satisfied: tensorboard~=2.6 in ./myenv/lib/python3.9/site-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (2.14.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in ./myenv/lib/python3.9/site-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (4.8.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in ./myenv/lib/python3.9/site-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in ./myenv/lib/python3.9/site-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (3.3.0)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in ./myenv/lib/python3.9/site-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (2.0.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.32.0 in ./myenv/lib/python3.9/site-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (0.37.1)\n",
      "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in ./myenv/lib/python3.9/site-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (2.7.0)\n",
      "Requirement already satisfied: numpy>=1.14.5 in ./myenv/lib/python3.9/site-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.26.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in ./myenv/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (59.6.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./myenv/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (3.0.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in ./myenv/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (1.0.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in ./myenv/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (2.23.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./myenv/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (0.7.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./myenv/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (3.4.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./myenv/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (2.31.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./myenv/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in ./myenv/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./myenv/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (0.3.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in ./myenv/lib/python3.9/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in ./myenv/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (6.8.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./myenv/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./myenv/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (1.26.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./myenv/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (2023.7.22)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./myenv/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (3.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./myenv/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (2.1.3)\n",
      "Requirement already satisfied: zipp>=0.5 in ./myenv/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (3.17.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in ./myenv/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in ./myenv/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fc101a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in ./venv/lib/python3.9/site-packages (22.0.2)\n",
      "Collecting pip\n",
      "  Using cached pip-23.2.1-py3-none-any.whl (2.1 MB)\n",
      "Requirement already satisfied: numpy in ./venv/lib/python3.9/site-packages (1.25.2)\n",
      "Collecting numpy\n",
      "  Downloading numpy-1.26.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wheel in ./venv/lib/python3.9/site-packages (0.37.1)\n",
      "Collecting wheel\n",
      "  Using cached wheel-0.41.2-py3-none-any.whl (64 kB)\n",
      "Collecting packaging\n",
      "  Using cached packaging-23.2-py3-none-any.whl (53 kB)\n",
      "Requirement already satisfied: requests in ./venv/lib/python3.9/site-packages (2.31.0)\n",
      "Requirement already satisfied: opt_einsum in ./venv/lib/python3.9/site-packages (3.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.9/site-packages (from requests) (3.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.9/site-packages (from requests) (2023.7.22)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.9/site-packages (from requests) (1.26.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.9/site-packages (from requests) (3.4)\n",
      "Installing collected packages: wheel, pip, packaging, numpy\n",
      "  Attempting uninstall: wheel\n",
      "    Found existing installation: wheel 0.37.1\n",
      "    Uninstalling wheel-0.37.1:\n",
      "      Successfully uninstalled wheel-0.37.1\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 22.0.2\n",
      "    Uninstalling pip-22.0.2:\n",
      "      Successfully uninstalled pip-22.0.2\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.25.2\n",
      "    Uninstalling numpy-1.25.2:\n",
      "      Successfully uninstalled numpy-1.25.2\n",
      "Successfully installed numpy-1.26.0 packaging-23.2 pip-23.2.1 wheel-0.41.2\n",
      "Requirement already satisfied: keras_preprocessing in ./venv/lib/python3.9/site-packages (1.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U pip numpy wheel packaging requests opt_einsum\n",
    "!pip install -U keras_preprocessing --no-deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ed6c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo apt-get update && sudo apt-get install -y llvm-16 clang-16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d61e9e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: better_profanity in ./venv/lib/python3.9/site-packages (0.6.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install better_profa`nity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd93b93e",
   "metadata": {},
   "source": [
    "# Test version of model with accuracy 52% and loss 2.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8159d7d4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-02 11:00:41.892535: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-10-02 11:00:41.892560: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "Loading song data from ../data/cleaned_poems_of_mandelshtamp.csv\n",
      "Will use 370 songs from all artists\n",
      "Preparing proper newlines\n",
      "Took 0:00:00.002943\n",
      "Fitting tokenizer to texts\n",
      "Took 0:00:00.056964\n",
      "Encoding all songs to integer sequences\n",
      "Took 0:00:00.024954\n",
      "\n",
      "Find the average/median line length for all songs\n",
      "Took 0:00:00.005426\n",
      "\n",
      "Median/mean line length from 6268 lines: 4.0/4\n",
      "Will include 4 lines for sequences.\n",
      "\n",
      "Creating training data\n",
      "Took 0:00:00.166676\n",
      "\n",
      "Total number of samples: 32763\n",
      "Using precreated embeddings from ./data/glove.6B.50d.txt\n",
      "Loading embedding mapping file ./data/glove.6B.50d.txt\n",
      "Creating embedding mappings for faster lookup\n",
      "Creating embedding matrix\n",
      "Took 0:00:00.002556\n",
      "Found 22 words in mapping (0.2%)\n",
      "0 words were ignored because they are infrequent\n",
      "Model will be created without tfjs support\n",
      "2023-10-02 11:00:48.400359: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_COMPAT_NOT_SUPPORTED_ON_DEVICE: forward compatibility was attempted on non supported HW\n",
      "2023-10-02 11:00:48.400457: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: jollyreap-B450-AORUS-ELITE\n",
      "2023-10-02 11:00:48.400464: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: jollyreap-B450-AORUS-ELITE\n",
      "2023-10-02 11:00:48.400791: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 535.113.1\n",
      "2023-10-02 11:00:48.400831: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 535.104.5\n",
      "2023-10-02 11:00:48.400838: E tensorflow/stream_executor/cuda/cuda_diagnostics.cc:313] kernel version 535.104.5 does not match DSO version 535.113.1 -- cannot find working devices in this configuration\n",
      "2023-10-02 11:00:48.401521: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 19)]              0         \n",
      "                                                                 \n",
      " song_embedding (Embedding)  (None, 19, 50)            614100    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 19, 256)          138240    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 256)              296448    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 12282)             1584378   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,666,062\n",
      "Trainable params: 2,666,062\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Running training with batch size 256 and maximum epochs 100\n",
      "Epoch 1/100\n",
      "  9/128 [=>............................] - ETA: 37s - loss: 8.4230 - accuracy: 0.1619\n",
      "Epoch 00001: loss improved from inf to 8.30423, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 19/128 [===>..........................] - ETA: 33s - loss: 7.9688 - accuracy: 0.1684\n",
      "Epoch 00001: loss improved from 8.30423 to 7.95506, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 29/128 [=====>........................] - ETA: 31s - loss: 7.8303 - accuracy: 0.1717\n",
      "Epoch 00001: loss improved from 7.95506 to 7.82682, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 39/128 [========>.....................] - ETA: 29s - loss: 7.7334 - accuracy: 0.1749\n",
      "Epoch 00001: loss improved from 7.82682 to 7.72481, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 49/128 [==========>...................] - ETA: 26s - loss: 7.6730 - accuracy: 0.1770\n",
      "Epoch 00001: loss improved from 7.72481 to 7.67294, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 59/128 [============>.................] - ETA: 23s - loss: 7.6553 - accuracy: 0.1756\n",
      "Epoch 00001: loss improved from 7.67294 to 7.65420, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 69/128 [===============>..............] - ETA: 19s - loss: 7.6651 - accuracy: 0.1747\n",
      "Epoch 00001: loss did not improve from 7.65420\n",
      " 79/128 [=================>............] - ETA: 16s - loss: 7.6443 - accuracy: 0.1762\n",
      "Epoch 00001: loss improved from 7.65420 to 7.64139, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 89/128 [===================>..........] - ETA: 13s - loss: 7.6402 - accuracy: 0.1762\n",
      "Epoch 00001: loss improved from 7.64139 to 7.63903, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 99/128 [======================>.......] - ETA: 9s - loss: 7.6192 - accuracy: 0.1783 \n",
      "Epoch 00001: loss improved from 7.63903 to 7.62858, saving model to ./export/2023-10-02T110043/model.h5\n",
      "109/128 [========================>.....] - ETA: 6s - loss: 7.6239 - accuracy: 0.1777\n",
      "Epoch 00001: loss improved from 7.62858 to 7.62141, saving model to ./export/2023-10-02T110043/model.h5\n",
      "119/128 [==========================>...] - ETA: 2s - loss: 7.6081 - accuracy: 0.1781\n",
      "Epoch 00001: loss improved from 7.62141 to 7.60850, saving model to ./export/2023-10-02T110043/model.h5\n",
      "128/128 [==============================] - 48s 326ms/step - loss: 7.6002 - accuracy: 0.1786\n",
      "Epoch 2/100\n",
      "  1/128 [..............................] - ETA: 32s - loss: 6.8893 - accuracy: 0.1758\n",
      "Epoch 00002: loss improved from 7.60850 to 7.05005, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 11/128 [=>............................] - ETA: 30s - loss: 7.1741 - accuracy: 0.1786\n",
      "Epoch 00002: loss did not improve from 7.05005\n",
      " 21/128 [===>..........................] - ETA: 28s - loss: 7.2014 - accuracy: 0.1778\n",
      "Epoch 00002: loss did not improve from 7.05005\n",
      " 31/128 [======>.......................] - ETA: 25s - loss: 7.1629 - accuracy: 0.1804\n",
      "Epoch 00002: loss did not improve from 7.05005\n",
      " 41/128 [========>.....................] - ETA: 23s - loss: 7.1798 - accuracy: 0.1792\n",
      "Epoch 00002: loss did not improve from 7.05005\n",
      " 51/128 [==========>...................] - ETA: 20s - loss: 7.1505 - accuracy: 0.1817\n",
      "Epoch 00002: loss did not improve from 7.05005\n",
      " 61/128 [=============>................] - ETA: 18s - loss: 7.1700 - accuracy: 0.1824\n",
      "Epoch 00002: loss did not improve from 7.05005\n",
      " 71/128 [===============>..............] - ETA: 15s - loss: 7.1757 - accuracy: 0.1828\n",
      "Epoch 00002: loss did not improve from 7.05005\n",
      " 81/128 [=================>............] - ETA: 12s - loss: 7.1746 - accuracy: 0.1858\n",
      "Epoch 00002: loss did not improve from 7.05005\n",
      " 91/128 [====================>.........] - ETA: 10s - loss: 7.1705 - accuracy: 0.1881\n",
      "Epoch 00002: loss did not improve from 7.05005\n",
      "101/128 [======================>.......] - ETA: 7s - loss: 7.1756 - accuracy: 0.1903\n",
      "Epoch 00002: loss did not improve from 7.05005\n",
      "111/128 [=========================>....] - ETA: 4s - loss: 7.1826 - accuracy: 0.1912\n",
      "Epoch 00002: loss did not improve from 7.05005\n",
      "121/128 [===========================>..] - ETA: 1s - loss: 7.1900 - accuracy: 0.1916\n",
      "Epoch 00002: loss did not improve from 7.05005\n",
      "128/128 [==============================] - 34s 269ms/step - loss: 7.1869 - accuracy: 0.1923\n",
      "Epoch 3/100\n",
      "  3/128 [..............................] - ETA: 35s - loss: 6.7269 - accuracy: 0.2031\n",
      "Epoch 00003: loss improved from 7.05005 to 6.78711, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 13/128 [==>...........................] - ETA: 30s - loss: 6.8265 - accuracy: 0.2085\n",
      "Epoch 00003: loss did not improve from 6.78711\n",
      " 23/128 [====>.........................] - ETA: 28s - loss: 6.8746 - accuracy: 0.2036\n",
      "Epoch 00003: loss did not improve from 6.78711\n",
      " 33/128 [======>.......................] - ETA: 25s - loss: 6.8593 - accuracy: 0.2066\n",
      "Epoch 00003: loss did not improve from 6.78711\n",
      " 43/128 [=========>....................] - ETA: 22s - loss: 6.8603 - accuracy: 0.2061\n",
      "Epoch 00003: loss did not improve from 6.78711\n",
      " 53/128 [===========>..................] - ETA: 19s - loss: 6.8896 - accuracy: 0.2053\n",
      "Epoch 00003: loss did not improve from 6.78711\n",
      " 63/128 [=============>................] - ETA: 17s - loss: 6.8896 - accuracy: 0.2065\n",
      "Epoch 00003: loss did not improve from 6.78711\n",
      " 73/128 [================>.............] - ETA: 14s - loss: 6.9052 - accuracy: 0.2060\n",
      "Epoch 00003: loss did not improve from 6.78711\n",
      " 83/128 [==================>...........] - ETA: 12s - loss: 6.8837 - accuracy: 0.2083\n",
      "Epoch 00003: loss did not improve from 6.78711\n",
      " 93/128 [====================>.........] - ETA: 9s - loss: 6.8981 - accuracy: 0.2071\n",
      "Epoch 00003: loss did not improve from 6.78711\n",
      "103/128 [=======================>......] - ETA: 6s - loss: 6.9029 - accuracy: 0.2071\n",
      "Epoch 00003: loss did not improve from 6.78711\n",
      "113/128 [=========================>....] - ETA: 4s - loss: 6.9142 - accuracy: 0.2068\n",
      "Epoch 00003: loss did not improve from 6.78711\n",
      "123/128 [===========================>..] - ETA: 1s - loss: 6.9298 - accuracy: 0.2064\n",
      "Epoch 00003: loss did not improve from 6.78711\n",
      "128/128 [==============================] - 35s 270ms/step - loss: 6.9357 - accuracy: 0.2061\n",
      "Epoch 4/100\n",
      "  5/128 [>.............................] - ETA: 38s - loss: 6.6877 - accuracy: 0.2008\n",
      "Epoch 00004: loss improved from 6.78711 to 6.68777, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 15/128 [==>...........................] - ETA: 31s - loss: 6.6880 - accuracy: 0.2052\n",
      "Epoch 00004: loss improved from 6.68777 to 6.68626, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 25/128 [====>.........................] - ETA: 29s - loss: 6.7146 - accuracy: 0.2052\n",
      "Epoch 00004: loss did not improve from 6.68626\n",
      " 35/128 [=======>......................] - ETA: 25s - loss: 6.7072 - accuracy: 0.2058\n",
      "Epoch 00004: loss did not improve from 6.68626\n",
      " 45/128 [=========>....................] - ETA: 23s - loss: 6.7014 - accuracy: 0.2073\n",
      "Epoch 00004: loss did not improve from 6.68626\n",
      " 55/128 [===========>..................] - ETA: 20s - loss: 6.6996 - accuracy: 0.2070\n",
      "Epoch 00004: loss did not improve from 6.68626\n",
      " 65/128 [==============>...............] - ETA: 17s - loss: 6.7040 - accuracy: 0.2072\n",
      "Epoch 00004: loss did not improve from 6.68626\n",
      " 75/128 [================>.............] - ETA: 14s - loss: 6.7162 - accuracy: 0.2068\n",
      "Epoch 00004: loss did not improve from 6.68626\n",
      " 85/128 [==================>...........] - ETA: 12s - loss: 6.7274 - accuracy: 0.2062\n",
      "Epoch 00004: loss did not improve from 6.68626\n",
      " 95/128 [=====================>........] - ETA: 9s - loss: 6.7173 - accuracy: 0.2075\n",
      "Epoch 00004: loss did not improve from 6.68626\n",
      "105/128 [=======================>......] - ETA: 6s - loss: 6.7239 - accuracy: 0.2083\n",
      "Epoch 00004: loss did not improve from 6.68626\n",
      "115/128 [=========================>....] - ETA: 3s - loss: 6.7396 - accuracy: 0.2076\n",
      "Epoch 00004: loss did not improve from 6.68626\n",
      "125/128 [============================>.] - ETA: 0s - loss: 6.7366 - accuracy: 0.2089\n",
      "Epoch 00004: loss did not improve from 6.68626\n",
      "128/128 [==============================] - 35s 276ms/step - loss: 6.7396 - accuracy: 0.2090\n",
      "Epoch 5/100\n",
      "  7/128 [>.............................] - ETA: 30s - loss: 6.4895 - accuracy: 0.2126\n",
      "Epoch 00005: loss improved from 6.68626 to 6.50343, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 17/128 [==>...........................] - ETA: 32s - loss: 6.5103 - accuracy: 0.2061\n",
      "Epoch 00005: loss did not improve from 6.50343\n",
      " 27/128 [=====>........................] - ETA: 28s - loss: 6.5244 - accuracy: 0.2057\n",
      "Epoch 00005: loss did not improve from 6.50343\n",
      " 37/128 [=======>......................] - ETA: 25s - loss: 6.5407 - accuracy: 0.2083\n",
      "Epoch 00005: loss did not improve from 6.50343\n",
      " 47/128 [==========>...................] - ETA: 22s - loss: 6.5260 - accuracy: 0.2091\n",
      "Epoch 00005: loss did not improve from 6.50343\n",
      " 57/128 [============>.................] - ETA: 19s - loss: 6.5236 - accuracy: 0.2111\n",
      "Epoch 00005: loss did not improve from 6.50343\n",
      " 67/128 [==============>...............] - ETA: 16s - loss: 6.5268 - accuracy: 0.2112\n",
      "Epoch 00005: loss did not improve from 6.50343\n",
      " 77/128 [=================>............] - ETA: 13s - loss: 6.5344 - accuracy: 0.2117\n",
      "Epoch 00005: loss did not improve from 6.50343\n",
      " 87/128 [===================>..........] - ETA: 10s - loss: 6.5449 - accuracy: 0.2117\n",
      "Epoch 00005: loss did not improve from 6.50343\n",
      " 97/128 [=====================>........] - ETA: 8s - loss: 6.5518 - accuracy: 0.2115\n",
      "Epoch 00005: loss did not improve from 6.50343\n",
      "107/128 [========================>.....] - ETA: 5s - loss: 6.5628 - accuracy: 0.2108\n",
      "Epoch 00005: loss did not improve from 6.50343\n",
      "117/128 [==========================>...] - ETA: 2s - loss: 6.5691 - accuracy: 0.2110\n",
      "Epoch 00005: loss did not improve from 6.50343\n",
      "127/128 [============================>.] - ETA: 0s - loss: 6.5794 - accuracy: 0.2108\n",
      "Epoch 00005: loss did not improve from 6.50343\n",
      "128/128 [==============================] - 34s 268ms/step - loss: 6.5780 - accuracy: 0.2109\n",
      "Epoch 6/100\n",
      "  9/128 [=>............................] - ETA: 30s - loss: 6.3288 - accuracy: 0.2174\n",
      "Epoch 00006: loss improved from 6.50343 to 6.32668, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 19/128 [===>..........................] - ETA: 30s - loss: 6.3315 - accuracy: 0.2188\n",
      "Epoch 00006: loss did not improve from 6.32668\n",
      " 29/128 [=====>........................] - ETA: 27s - loss: 6.3602 - accuracy: 0.2142\n",
      "Epoch 00006: loss did not improve from 6.32668\n",
      " 39/128 [========>.....................] - ETA: 24s - loss: 6.3632 - accuracy: 0.2124\n",
      "Epoch 00006: loss did not improve from 6.32668\n",
      " 49/128 [==========>...................] - ETA: 21s - loss: 6.3764 - accuracy: 0.2116\n",
      "Epoch 00006: loss did not improve from 6.32668\n",
      " 59/128 [============>.................] - ETA: 18s - loss: 6.3740 - accuracy: 0.2123\n",
      "Epoch 00006: loss did not improve from 6.32668\n",
      " 69/128 [===============>..............] - ETA: 15s - loss: 6.3986 - accuracy: 0.2104\n",
      "Epoch 00006: loss did not improve from 6.32668\n",
      " 79/128 [=================>............] - ETA: 13s - loss: 6.3897 - accuracy: 0.2115\n",
      "Epoch 00006: loss did not improve from 6.32668\n",
      " 89/128 [===================>..........] - ETA: 10s - loss: 6.4030 - accuracy: 0.2112\n",
      "Epoch 00006: loss did not improve from 6.32668\n",
      " 99/128 [======================>.......] - ETA: 7s - loss: 6.4149 - accuracy: 0.2111\n",
      "Epoch 00006: loss did not improve from 6.32668\n",
      "109/128 [========================>.....] - ETA: 5s - loss: 6.4250 - accuracy: 0.2108\n",
      "Epoch 00006: loss did not improve from 6.32668\n",
      "119/128 [==========================>...] - ETA: 2s - loss: 6.4258 - accuracy: 0.2116\n",
      "Epoch 00006: loss did not improve from 6.32668\n",
      "128/128 [==============================] - 34s 267ms/step - loss: 6.4363 - accuracy: 0.2118\n",
      "Epoch 7/100\n",
      "  1/128 [..............................] - ETA: 34s - loss: 6.7244 - accuracy: 0.1836\n",
      "Epoch 00007: loss did not improve from 6.32668\n",
      " 11/128 [=>............................] - ETA: 32s - loss: 6.3308 - accuracy: 0.2159\n",
      "Epoch 00007: loss did not improve from 6.32668\n",
      " 21/128 [===>..........................] - ETA: 28s - loss: 6.2339 - accuracy: 0.2186\n",
      "Epoch 00007: loss improved from 6.32668 to 6.23115, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 31/128 [======>.......................] - ETA: 27s - loss: 6.2454 - accuracy: 0.2182\n",
      "Epoch 00007: loss did not improve from 6.23115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 41/128 [========>.....................] - ETA: 24s - loss: 6.2397 - accuracy: 0.2186\n",
      "Epoch 00007: loss did not improve from 6.23115\n",
      " 51/128 [==========>...................] - ETA: 21s - loss: 6.2393 - accuracy: 0.2187\n",
      "Epoch 00007: loss did not improve from 6.23115\n",
      " 61/128 [=============>................] - ETA: 18s - loss: 6.2572 - accuracy: 0.2156\n",
      "Epoch 00007: loss did not improve from 6.23115\n",
      " 71/128 [===============>..............] - ETA: 15s - loss: 6.2397 - accuracy: 0.2179\n",
      "Epoch 00007: loss did not improve from 6.23115\n",
      " 81/128 [=================>............] - ETA: 13s - loss: 6.2558 - accuracy: 0.2159\n",
      "Epoch 00007: loss did not improve from 6.23115\n",
      " 91/128 [====================>.........] - ETA: 10s - loss: 6.2571 - accuracy: 0.2147\n",
      "Epoch 00007: loss did not improve from 6.23115\n",
      "101/128 [======================>.......] - ETA: 7s - loss: 6.2854 - accuracy: 0.2136\n",
      "Epoch 00007: loss did not improve from 6.23115\n",
      "111/128 [=========================>....] - ETA: 4s - loss: 6.2948 - accuracy: 0.2134\n",
      "Epoch 00007: loss did not improve from 6.23115\n",
      "121/128 [===========================>..] - ETA: 1s - loss: 6.3080 - accuracy: 0.2125\n",
      "Epoch 00007: loss did not improve from 6.23115\n",
      "128/128 [==============================] - 35s 274ms/step - loss: 6.3160 - accuracy: 0.2122\n",
      "Epoch 8/100\n",
      "  3/128 [..............................] - ETA: 34s - loss: 6.1312 - accuracy: 0.2383\n",
      "Epoch 00008: loss improved from 6.23115 to 6.11220, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 13/128 [==>...........................] - ETA: 31s - loss: 6.1649 - accuracy: 0.2169\n",
      "Epoch 00008: loss did not improve from 6.11220\n",
      " 23/128 [====>.........................] - ETA: 28s - loss: 6.1346 - accuracy: 0.2181\n",
      "Epoch 00008: loss did not improve from 6.11220\n",
      " 33/128 [======>.......................] - ETA: 26s - loss: 6.1704 - accuracy: 0.2138\n",
      "Epoch 00008: loss did not improve from 6.11220\n",
      " 43/128 [=========>....................] - ETA: 23s - loss: 6.1830 - accuracy: 0.2118\n",
      "Epoch 00008: loss did not improve from 6.11220\n",
      " 53/128 [===========>..................] - ETA: 20s - loss: 6.1965 - accuracy: 0.2107\n",
      "Epoch 00008: loss did not improve from 6.11220\n",
      " 63/128 [=============>................] - ETA: 17s - loss: 6.1840 - accuracy: 0.2123\n",
      "Epoch 00008: loss did not improve from 6.11220\n",
      " 73/128 [================>.............] - ETA: 15s - loss: 6.1921 - accuracy: 0.2107\n",
      "Epoch 00008: loss did not improve from 6.11220\n",
      " 83/128 [==================>...........] - ETA: 12s - loss: 6.1863 - accuracy: 0.2118\n",
      "Epoch 00008: loss did not improve from 6.11220\n",
      " 93/128 [====================>.........] - ETA: 9s - loss: 6.1921 - accuracy: 0.2122\n",
      "Epoch 00008: loss did not improve from 6.11220\n",
      "103/128 [=======================>......] - ETA: 6s - loss: 6.1873 - accuracy: 0.2128\n",
      "Epoch 00008: loss did not improve from 6.11220\n",
      "113/128 [=========================>....] - ETA: 4s - loss: 6.1924 - accuracy: 0.2128\n",
      "Epoch 00008: loss did not improve from 6.11220\n",
      "123/128 [===========================>..] - ETA: 1s - loss: 6.1972 - accuracy: 0.2140\n",
      "Epoch 00008: loss did not improve from 6.11220\n",
      "128/128 [==============================] - 34s 269ms/step - loss: 6.1999 - accuracy: 0.2141\n",
      "Epoch 9/100\n",
      "  5/128 [>.............................] - ETA: 35s - loss: 5.9188 - accuracy: 0.2234\n",
      "Epoch 00009: loss improved from 6.11220 to 5.95414, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 15/128 [==>...........................] - ETA: 39s - loss: 5.9439 - accuracy: 0.2180\n",
      "Epoch 00009: loss improved from 5.95414 to 5.94324, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 25/128 [====>.........................] - ETA: 33s - loss: 5.9867 - accuracy: 0.2144\n",
      "Epoch 00009: loss did not improve from 5.94324\n",
      " 35/128 [=======>......................] - ETA: 29s - loss: 5.9626 - accuracy: 0.2208\n",
      "Epoch 00009: loss did not improve from 5.94324\n",
      " 45/128 [=========>....................] - ETA: 25s - loss: 6.0018 - accuracy: 0.2160\n",
      "Epoch 00009: loss did not improve from 5.94324\n",
      " 55/128 [===========>..................] - ETA: 22s - loss: 6.0243 - accuracy: 0.2141\n",
      "Epoch 00009: loss did not improve from 5.94324\n",
      " 65/128 [==============>...............] - ETA: 19s - loss: 6.0311 - accuracy: 0.2150\n",
      "Epoch 00009: loss did not improve from 5.94324\n",
      " 75/128 [================>.............] - ETA: 15s - loss: 6.0477 - accuracy: 0.2130\n",
      "Epoch 00009: loss did not improve from 5.94324\n",
      " 85/128 [==================>...........] - ETA: 12s - loss: 6.0496 - accuracy: 0.2137\n",
      "Epoch 00009: loss did not improve from 5.94324\n",
      " 95/128 [=====================>........] - ETA: 9s - loss: 6.0661 - accuracy: 0.2123 \n",
      "Epoch 00009: loss did not improve from 5.94324\n",
      "105/128 [=======================>......] - ETA: 6s - loss: 6.0775 - accuracy: 0.2124\n",
      "Epoch 00009: loss did not improve from 5.94324\n",
      "115/128 [=========================>....] - ETA: 3s - loss: 6.0717 - accuracy: 0.2136\n",
      "Epoch 00009: loss did not improve from 5.94324\n",
      "125/128 [============================>.] - ETA: 0s - loss: 6.0824 - accuracy: 0.2132\n",
      "Epoch 00009: loss did not improve from 5.94324\n",
      "128/128 [==============================] - 37s 287ms/step - loss: 6.0855 - accuracy: 0.2134\n",
      "Epoch 10/100\n",
      "  7/128 [>.............................] - ETA: 36s - loss: 5.9126 - accuracy: 0.2204\n",
      "Epoch 00010: loss improved from 5.94324 to 5.92086, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 17/128 [==>...........................] - ETA: 32s - loss: 5.8960 - accuracy: 0.2204\n",
      "Epoch 00010: loss improved from 5.92086 to 5.89547, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 27/128 [=====>........................] - ETA: 29s - loss: 5.9216 - accuracy: 0.2177\n",
      "Epoch 00010: loss did not improve from 5.89547\n",
      " 37/128 [=======>......................] - ETA: 25s - loss: 5.9212 - accuracy: 0.2165\n",
      "Epoch 00010: loss did not improve from 5.89547\n",
      " 47/128 [==========>...................] - ETA: 22s - loss: 5.9592 - accuracy: 0.2123\n",
      "Epoch 00010: loss did not improve from 5.89547\n",
      " 57/128 [============>.................] - ETA: 19s - loss: 5.9419 - accuracy: 0.2141\n",
      "Epoch 00010: loss did not improve from 5.89547\n",
      " 67/128 [==============>...............] - ETA: 16s - loss: 5.9518 - accuracy: 0.2139\n",
      "Epoch 00010: loss did not improve from 5.89547\n",
      " 77/128 [=================>............] - ETA: 13s - loss: 5.9570 - accuracy: 0.2137\n",
      "Epoch 00010: loss did not improve from 5.89547\n",
      " 87/128 [===================>..........] - ETA: 11s - loss: 5.9529 - accuracy: 0.2147\n",
      "Epoch 00010: loss did not improve from 5.89547\n",
      " 97/128 [=====================>........] - ETA: 8s - loss: 5.9482 - accuracy: 0.2159\n",
      "Epoch 00010: loss did not improve from 5.89547\n",
      "107/128 [========================>.....] - ETA: 5s - loss: 5.9546 - accuracy: 0.2160\n",
      "Epoch 00010: loss did not improve from 5.89547\n",
      "117/128 [==========================>...] - ETA: 2s - loss: 5.9665 - accuracy: 0.2151\n",
      "Epoch 00010: loss did not improve from 5.89547\n",
      "127/128 [============================>.] - ETA: 0s - loss: 5.9735 - accuracy: 0.2148\n",
      "Epoch 00010: loss did not improve from 5.89547\n",
      "128/128 [==============================] - 34s 266ms/step - loss: 5.9743 - accuracy: 0.2149\n",
      "Epoch 11/100\n",
      "  9/128 [=>............................] - ETA: 33s - loss: 5.7442 - accuracy: 0.2266\n",
      "Epoch 00011: loss improved from 5.89547 to 5.73899, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 19/128 [===>..........................] - ETA: 29s - loss: 5.8089 - accuracy: 0.2150\n",
      "Epoch 00011: loss did not improve from 5.73899\n",
      " 29/128 [=====>........................] - ETA: 26s - loss: 5.8172 - accuracy: 0.2121\n",
      "Epoch 00011: loss did not improve from 5.73899\n",
      " 39/128 [========>.....................] - ETA: 23s - loss: 5.8260 - accuracy: 0.2142\n",
      "Epoch 00011: loss did not improve from 5.73899\n",
      " 49/128 [==========>...................] - ETA: 21s - loss: 5.8274 - accuracy: 0.2146\n",
      "Epoch 00011: loss did not improve from 5.73899\n",
      " 59/128 [============>.................] - ETA: 18s - loss: 5.8366 - accuracy: 0.2142\n",
      "Epoch 00011: loss did not improve from 5.73899\n",
      " 69/128 [===============>..............] - ETA: 15s - loss: 5.8385 - accuracy: 0.2154\n",
      "Epoch 00011: loss did not improve from 5.73899\n",
      " 79/128 [=================>............] - ETA: 12s - loss: 5.8264 - accuracy: 0.2167\n",
      "Epoch 00011: loss did not improve from 5.73899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 89/128 [===================>..........] - ETA: 10s - loss: 5.8333 - accuracy: 0.2162\n",
      "Epoch 00011: loss did not improve from 5.73899\n",
      " 99/128 [======================>.......] - ETA: 7s - loss: 5.8437 - accuracy: 0.2162\n",
      "Epoch 00011: loss did not improve from 5.73899\n",
      "109/128 [========================>.....] - ETA: 5s - loss: 5.8530 - accuracy: 0.2160\n",
      "Epoch 00011: loss did not improve from 5.73899\n",
      "119/128 [==========================>...] - ETA: 2s - loss: 5.8723 - accuracy: 0.2146\n",
      "Epoch 00011: loss did not improve from 5.73899\n",
      "128/128 [==============================] - 34s 267ms/step - loss: 5.8767 - accuracy: 0.2148\n",
      "Epoch 12/100\n",
      "  1/128 [..............................] - ETA: 34s - loss: 5.9256 - accuracy: 0.2070\n",
      "Epoch 00012: loss did not improve from 5.73899\n",
      " 11/128 [=>............................] - ETA: 33s - loss: 5.7007 - accuracy: 0.2131\n",
      "Epoch 00012: loss improved from 5.73899 to 5.70479, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 21/128 [===>..........................] - ETA: 29s - loss: 5.7487 - accuracy: 0.2106\n",
      "Epoch 00012: loss did not improve from 5.70479\n",
      " 31/128 [======>.......................] - ETA: 27s - loss: 5.7539 - accuracy: 0.2127\n",
      "Epoch 00012: loss did not improve from 5.70479\n",
      " 41/128 [========>.....................] - ETA: 23s - loss: 5.7755 - accuracy: 0.2119\n",
      "Epoch 00012: loss did not improve from 5.70479\n",
      " 51/128 [==========>...................] - ETA: 21s - loss: 5.7843 - accuracy: 0.2121\n",
      "Epoch 00012: loss did not improve from 5.70479\n",
      " 61/128 [=============>................] - ETA: 18s - loss: 5.7892 - accuracy: 0.2115\n",
      "Epoch 00012: loss did not improve from 5.70479\n",
      " 71/128 [===============>..............] - ETA: 16s - loss: 5.7744 - accuracy: 0.2132\n",
      "Epoch 00012: loss did not improve from 5.70479\n",
      " 81/128 [=================>............] - ETA: 13s - loss: 5.7700 - accuracy: 0.2135\n",
      "Epoch 00012: loss did not improve from 5.70479\n",
      " 91/128 [====================>.........] - ETA: 10s - loss: 5.7699 - accuracy: 0.2136\n",
      "Epoch 00012: loss did not improve from 5.70479\n",
      "101/128 [======================>.......] - ETA: 7s - loss: 5.7730 - accuracy: 0.2138\n",
      "Epoch 00012: loss did not improve from 5.70479\n",
      "111/128 [=========================>....] - ETA: 4s - loss: 5.7663 - accuracy: 0.2150\n",
      "Epoch 00012: loss did not improve from 5.70479\n",
      "121/128 [===========================>..] - ETA: 1s - loss: 5.7733 - accuracy: 0.2152\n",
      "Epoch 00012: loss did not improve from 5.70479\n",
      "128/128 [==============================] - 36s 285ms/step - loss: 5.7804 - accuracy: 0.2153\n",
      "Epoch 13/100\n",
      "  3/128 [..............................] - ETA: 35s - loss: 5.5907 - accuracy: 0.2161\n",
      "Epoch 00013: loss improved from 5.70479 to 5.57355, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 13/128 [==>...........................] - ETA: 36s - loss: 5.6271 - accuracy: 0.2127\n",
      "Epoch 00013: loss did not improve from 5.57355\n",
      " 23/128 [====>.........................] - ETA: 32s - loss: 5.6365 - accuracy: 0.2121\n",
      "Epoch 00013: loss did not improve from 5.57355\n",
      " 33/128 [======>.......................] - ETA: 29s - loss: 5.5998 - accuracy: 0.2189\n",
      "Epoch 00013: loss did not improve from 5.57355\n",
      " 43/128 [=========>....................] - ETA: 25s - loss: 5.6129 - accuracy: 0.2177\n",
      "Epoch 00013: loss did not improve from 5.57355\n",
      " 53/128 [===========>..................] - ETA: 22s - loss: 5.6289 - accuracy: 0.2176\n",
      "Epoch 00013: loss did not improve from 5.57355\n",
      " 63/128 [=============>................] - ETA: 19s - loss: 5.6293 - accuracy: 0.2172\n",
      "Epoch 00013: loss did not improve from 5.57355\n",
      " 73/128 [================>.............] - ETA: 16s - loss: 5.6327 - accuracy: 0.2177\n",
      "Epoch 00013: loss did not improve from 5.57355\n",
      " 83/128 [==================>...........] - ETA: 13s - loss: 5.6480 - accuracy: 0.2169\n",
      "Epoch 00013: loss did not improve from 5.57355\n",
      " 93/128 [====================>.........] - ETA: 10s - loss: 5.6590 - accuracy: 0.2163\n",
      "Epoch 00013: loss did not improve from 5.57355\n",
      "103/128 [=======================>......] - ETA: 7s - loss: 5.6566 - accuracy: 0.2169\n",
      "Epoch 00013: loss did not improve from 5.57355\n",
      "113/128 [=========================>....] - ETA: 4s - loss: 5.6697 - accuracy: 0.2167\n",
      "Epoch 00013: loss did not improve from 5.57355\n",
      "123/128 [===========================>..] - ETA: 1s - loss: 5.6784 - accuracy: 0.2164\n",
      "Epoch 00013: loss did not improve from 5.57355\n",
      "128/128 [==============================] - 37s 288ms/step - loss: 5.6860 - accuracy: 0.2161\n",
      "Epoch 14/100\n",
      "  5/128 [>.............................] - ETA: 30s - loss: 5.6205 - accuracy: 0.2086\n",
      "Epoch 00014: loss improved from 5.57355 to 5.55205, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 15/128 [==>...........................] - ETA: 33s - loss: 5.5433 - accuracy: 0.2159\n",
      "Epoch 00014: loss improved from 5.55205 to 5.53202, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 25/128 [====>.........................] - ETA: 29s - loss: 5.5189 - accuracy: 0.2164\n",
      "Epoch 00014: loss improved from 5.53202 to 5.50584, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 35/128 [=======>......................] - ETA: 26s - loss: 5.5046 - accuracy: 0.2186\n",
      "Epoch 00014: loss improved from 5.50584 to 5.50364, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 45/128 [=========>....................] - ETA: 23s - loss: 5.5320 - accuracy: 0.2181\n",
      "Epoch 00014: loss did not improve from 5.50364\n",
      " 55/128 [===========>..................] - ETA: 20s - loss: 5.5294 - accuracy: 0.2173\n",
      "Epoch 00014: loss did not improve from 5.50364\n",
      " 65/128 [==============>...............] - ETA: 17s - loss: 5.5432 - accuracy: 0.2174\n",
      "Epoch 00014: loss did not improve from 5.50364\n",
      " 75/128 [================>.............] - ETA: 14s - loss: 5.5417 - accuracy: 0.2186\n",
      "Epoch 00014: loss did not improve from 5.50364\n",
      " 85/128 [==================>...........] - ETA: 11s - loss: 5.5466 - accuracy: 0.2191\n",
      "Epoch 00014: loss did not improve from 5.50364\n",
      " 95/128 [=====================>........] - ETA: 9s - loss: 5.5561 - accuracy: 0.2192\n",
      "Epoch 00014: loss did not improve from 5.50364\n",
      "105/128 [=======================>......] - ETA: 6s - loss: 5.5758 - accuracy: 0.2179\n",
      "Epoch 00014: loss did not improve from 5.50364\n",
      "115/128 [=========================>....] - ETA: 3s - loss: 5.5887 - accuracy: 0.2176\n",
      "Epoch 00014: loss did not improve from 5.50364\n",
      "125/128 [============================>.] - ETA: 0s - loss: 5.5961 - accuracy: 0.2165\n",
      "Epoch 00014: loss did not improve from 5.50364\n",
      "128/128 [==============================] - 35s 274ms/step - loss: 5.5988 - accuracy: 0.2170\n",
      "Epoch 15/100\n",
      "  7/128 [>.............................] - ETA: 31s - loss: 5.4352 - accuracy: 0.2165\n",
      "Epoch 00015: loss improved from 5.50364 to 5.44239, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 17/128 [==>...........................] - ETA: 31s - loss: 5.4747 - accuracy: 0.2137\n",
      "Epoch 00015: loss did not improve from 5.44239\n",
      " 27/128 [=====>........................] - ETA: 28s - loss: 5.4611 - accuracy: 0.2188\n",
      "Epoch 00015: loss did not improve from 5.44239\n",
      " 37/128 [=======>......................] - ETA: 25s - loss: 5.4622 - accuracy: 0.2184\n",
      "Epoch 00015: loss did not improve from 5.44239\n",
      " 47/128 [==========>...................] - ETA: 22s - loss: 5.4599 - accuracy: 0.2192\n",
      "Epoch 00015: loss did not improve from 5.44239\n",
      " 57/128 [============>.................] - ETA: 19s - loss: 5.4741 - accuracy: 0.2172\n",
      "Epoch 00015: loss did not improve from 5.44239\n",
      " 67/128 [==============>...............] - ETA: 16s - loss: 5.4862 - accuracy: 0.2175\n",
      "Epoch 00015: loss did not improve from 5.44239\n",
      " 77/128 [=================>............] - ETA: 13s - loss: 5.4775 - accuracy: 0.2198\n",
      "Epoch 00015: loss did not improve from 5.44239\n",
      " 87/128 [===================>..........] - ETA: 11s - loss: 5.4891 - accuracy: 0.2203\n",
      "Epoch 00015: loss did not improve from 5.44239\n",
      " 97/128 [=====================>........] - ETA: 8s - loss: 5.4968 - accuracy: 0.2191\n",
      "Epoch 00015: loss did not improve from 5.44239\n",
      "107/128 [========================>.....] - ETA: 5s - loss: 5.4933 - accuracy: 0.2198\n",
      "Epoch 00015: loss did not improve from 5.44239\n",
      "117/128 [==========================>...] - ETA: 3s - loss: 5.5078 - accuracy: 0.2193\n",
      "Epoch 00015: loss did not improve from 5.44239\n",
      "127/128 [============================>.] - ETA: 0s - loss: 5.5272 - accuracy: 0.2176\n",
      "Epoch 00015: loss did not improve from 5.44239\n",
      "128/128 [==============================] - 35s 274ms/step - loss: 5.5288 - accuracy: 0.2175\n",
      "Epoch 16/100\n",
      "  9/128 [=>............................] - ETA: 33s - loss: 5.2978 - accuracy: 0.2357\n",
      "Epoch 00016: loss improved from 5.44239 to 5.30709, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 19/128 [===>..........................] - ETA: 28s - loss: 5.3112 - accuracy: 0.2305\n",
      "Epoch 00016: loss improved from 5.30709 to 5.30692, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 29/128 [=====>........................] - ETA: 26s - loss: 5.3484 - accuracy: 0.2251\n",
      "Epoch 00016: loss did not improve from 5.30692\n",
      " 39/128 [========>.....................] - ETA: 23s - loss: 5.3560 - accuracy: 0.2254\n",
      "Epoch 00016: loss did not improve from 5.30692\n",
      " 49/128 [==========>...................] - ETA: 20s - loss: 5.3554 - accuracy: 0.2250\n",
      "Epoch 00016: loss did not improve from 5.30692\n",
      " 59/128 [============>.................] - ETA: 17s - loss: 5.3679 - accuracy: 0.2235\n",
      "Epoch 00016: loss did not improve from 5.30692\n",
      " 69/128 [===============>..............] - ETA: 15s - loss: 5.3857 - accuracy: 0.2221\n",
      "Epoch 00016: loss did not improve from 5.30692\n",
      " 79/128 [=================>............] - ETA: 12s - loss: 5.3960 - accuracy: 0.2209\n",
      "Epoch 00016: loss did not improve from 5.30692\n",
      " 89/128 [===================>..........] - ETA: 10s - loss: 5.4136 - accuracy: 0.2191\n",
      "Epoch 00016: loss did not improve from 5.30692\n",
      " 99/128 [======================>.......] - ETA: 7s - loss: 5.4293 - accuracy: 0.2178\n",
      "Epoch 00016: loss did not improve from 5.30692\n",
      "109/128 [========================>.....] - ETA: 4s - loss: 5.4365 - accuracy: 0.2177\n",
      "Epoch 00016: loss did not improve from 5.30692\n",
      "119/128 [==========================>...] - ETA: 2s - loss: 5.4418 - accuracy: 0.2181\n",
      "Epoch 00016: loss did not improve from 5.30692\n",
      "128/128 [==============================] - 34s 264ms/step - loss: 5.4483 - accuracy: 0.2177\n",
      "Epoch 17/100\n",
      "  1/128 [..............................] - ETA: 31s - loss: 5.5202 - accuracy: 0.1797\n",
      "Epoch 00017: loss did not improve from 5.30692\n",
      " 11/128 [=>............................] - ETA: 31s - loss: 5.2821 - accuracy: 0.2152\n",
      "Epoch 00017: loss improved from 5.30692 to 5.28965, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 21/128 [===>..........................] - ETA: 28s - loss: 5.3575 - accuracy: 0.2072\n",
      "Epoch 00017: loss did not improve from 5.28965\n",
      " 31/128 [======>.......................] - ETA: 26s - loss: 5.3575 - accuracy: 0.2109\n",
      "Epoch 00017: loss did not improve from 5.28965\n",
      " 41/128 [========>.....................] - ETA: 23s - loss: 5.3564 - accuracy: 0.2123\n",
      "Epoch 00017: loss did not improve from 5.28965\n",
      " 51/128 [==========>...................] - ETA: 20s - loss: 5.3823 - accuracy: 0.2109\n",
      "Epoch 00017: loss did not improve from 5.28965\n",
      " 61/128 [=============>................] - ETA: 18s - loss: 5.3665 - accuracy: 0.2143\n",
      "Epoch 00017: loss did not improve from 5.28965\n",
      " 71/128 [===============>..............] - ETA: 15s - loss: 5.3769 - accuracy: 0.2139\n",
      "Epoch 00017: loss did not improve from 5.28965\n",
      " 81/128 [=================>............] - ETA: 12s - loss: 5.3673 - accuracy: 0.2162\n",
      "Epoch 00017: loss did not improve from 5.28965\n",
      " 91/128 [====================>.........] - ETA: 10s - loss: 5.3699 - accuracy: 0.2172\n",
      "Epoch 00017: loss did not improve from 5.28965\n",
      "101/128 [======================>.......] - ETA: 7s - loss: 5.3640 - accuracy: 0.2186\n",
      "Epoch 00017: loss did not improve from 5.28965\n",
      "111/128 [=========================>....] - ETA: 4s - loss: 5.3578 - accuracy: 0.2191\n",
      "Epoch 00017: loss did not improve from 5.28965\n",
      "121/128 [===========================>..] - ETA: 1s - loss: 5.3676 - accuracy: 0.2192\n",
      "Epoch 00017: loss did not improve from 5.28965\n",
      "128/128 [==============================] - 35s 272ms/step - loss: 5.3737 - accuracy: 0.2186\n",
      "Epoch 18/100\n",
      "  3/128 [..............................] - ETA: 32s - loss: 5.2811 - accuracy: 0.2122\n",
      "Epoch 00018: loss did not improve from 5.28965\n",
      " 13/128 [==>...........................] - ETA: 30s - loss: 5.1902 - accuracy: 0.2266\n",
      "Epoch 00018: loss improved from 5.28965 to 5.18302, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 23/128 [====>.........................] - ETA: 28s - loss: 5.2016 - accuracy: 0.2223\n",
      "Epoch 00018: loss did not improve from 5.18302\n",
      " 33/128 [======>.......................] - ETA: 26s - loss: 5.2224 - accuracy: 0.2195\n",
      "Epoch 00018: loss did not improve from 5.18302\n",
      " 43/128 [=========>....................] - ETA: 23s - loss: 5.2255 - accuracy: 0.2224\n",
      "Epoch 00018: loss did not improve from 5.18302\n",
      " 53/128 [===========>..................] - ETA: 20s - loss: 5.2616 - accuracy: 0.2210\n",
      "Epoch 00018: loss did not improve from 5.18302\n",
      " 63/128 [=============>................] - ETA: 18s - loss: 5.2684 - accuracy: 0.2209\n",
      "Epoch 00018: loss did not improve from 5.18302\n",
      " 73/128 [================>.............] - ETA: 15s - loss: 5.2759 - accuracy: 0.2201\n",
      "Epoch 00018: loss did not improve from 5.18302\n",
      " 83/128 [==================>...........] - ETA: 12s - loss: 5.2720 - accuracy: 0.2208\n",
      "Epoch 00018: loss did not improve from 5.18302\n",
      " 93/128 [====================>.........] - ETA: 9s - loss: 5.2807 - accuracy: 0.2199\n",
      "Epoch 00018: loss did not improve from 5.18302\n",
      "103/128 [=======================>......] - ETA: 6s - loss: 5.2905 - accuracy: 0.2191\n",
      "Epoch 00018: loss did not improve from 5.18302\n",
      "113/128 [=========================>....] - ETA: 4s - loss: 5.2946 - accuracy: 0.2191\n",
      "Epoch 00018: loss did not improve from 5.18302\n",
      "123/128 [===========================>..] - ETA: 1s - loss: 5.3059 - accuracy: 0.2191\n",
      "Epoch 00018: loss did not improve from 5.18302\n",
      "128/128 [==============================] - 36s 278ms/step - loss: 5.3040 - accuracy: 0.2193\n",
      "Epoch 19/100\n",
      "  5/128 [>.............................] - ETA: 39s - loss: 5.1524 - accuracy: 0.2250\n",
      "Epoch 00019: loss improved from 5.18302 to 5.16419, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 15/128 [==>...........................] - ETA: 32s - loss: 5.1494 - accuracy: 0.2333\n",
      "Epoch 00019: loss improved from 5.16419 to 5.14863, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 25/128 [====>.........................] - ETA: 29s - loss: 5.1791 - accuracy: 0.2264\n",
      "Epoch 00019: loss did not improve from 5.14863\n",
      " 35/128 [=======>......................] - ETA: 25s - loss: 5.1623 - accuracy: 0.2265\n",
      "Epoch 00019: loss did not improve from 5.14863\n",
      " 45/128 [=========>....................] - ETA: 23s - loss: 5.1722 - accuracy: 0.2244\n",
      "Epoch 00019: loss did not improve from 5.14863\n",
      " 55/128 [===========>..................] - ETA: 20s - loss: 5.1706 - accuracy: 0.2246\n",
      "Epoch 00019: loss did not improve from 5.14863\n",
      " 65/128 [==============>...............] - ETA: 17s - loss: 5.1729 - accuracy: 0.2237\n",
      "Epoch 00019: loss did not improve from 5.14863\n",
      " 75/128 [================>.............] - ETA: 14s - loss: 5.1774 - accuracy: 0.2233\n",
      "Epoch 00019: loss did not improve from 5.14863\n",
      " 85/128 [==================>...........] - ETA: 11s - loss: 5.2024 - accuracy: 0.2211\n",
      "Epoch 00019: loss did not improve from 5.14863\n",
      " 95/128 [=====================>........] - ETA: 9s - loss: 5.2153 - accuracy: 0.2209\n",
      "Epoch 00019: loss did not improve from 5.14863\n",
      "105/128 [=======================>......] - ETA: 6s - loss: 5.2106 - accuracy: 0.2212\n",
      "Epoch 00019: loss did not improve from 5.14863\n",
      "115/128 [=========================>....] - ETA: 3s - loss: 5.2283 - accuracy: 0.2198\n",
      "Epoch 00019: loss did not improve from 5.14863\n",
      "125/128 [============================>.] - ETA: 0s - loss: 5.2361 - accuracy: 0.2198\n",
      "Epoch 00019: loss did not improve from 5.14863\n",
      "128/128 [==============================] - 35s 272ms/step - loss: 5.2369 - accuracy: 0.2198\n",
      "Epoch 20/100\n",
      "  7/128 [>.............................] - ETA: 33s - loss: 5.0670 - accuracy: 0.2338\n",
      "Epoch 00020: loss improved from 5.14863 to 5.09826, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 17/128 [==>...........................] - ETA: 30s - loss: 5.0549 - accuracy: 0.2279\n",
      "Epoch 00020: loss improved from 5.09826 to 5.06175, saving model to ./export/2023-10-02T110043/model.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 27/128 [=====>........................] - ETA: 28s - loss: 5.0887 - accuracy: 0.2251\n",
      "Epoch 00020: loss did not improve from 5.06175\n",
      " 37/128 [=======>......................] - ETA: 25s - loss: 5.0984 - accuracy: 0.2232\n",
      "Epoch 00020: loss did not improve from 5.06175\n",
      " 47/128 [==========>...................] - ETA: 22s - loss: 5.1092 - accuracy: 0.2228\n",
      "Epoch 00020: loss did not improve from 5.06175\n",
      " 57/128 [============>.................] - ETA: 19s - loss: 5.1166 - accuracy: 0.2223\n",
      "Epoch 00020: loss did not improve from 5.06175\n",
      " 67/128 [==============>...............] - ETA: 16s - loss: 5.1074 - accuracy: 0.2239\n",
      "Epoch 00020: loss did not improve from 5.06175\n",
      " 77/128 [=================>............] - ETA: 13s - loss: 5.1144 - accuracy: 0.2241\n",
      "Epoch 00020: loss did not improve from 5.06175\n",
      " 87/128 [===================>..........] - ETA: 11s - loss: 5.1257 - accuracy: 0.2225\n",
      "Epoch 00020: loss did not improve from 5.06175\n",
      " 97/128 [=====================>........] - ETA: 8s - loss: 5.1342 - accuracy: 0.2218\n",
      "Epoch 00020: loss did not improve from 5.06175\n",
      "107/128 [========================>.....] - ETA: 5s - loss: 5.1491 - accuracy: 0.2209\n",
      "Epoch 00020: loss did not improve from 5.06175\n",
      "117/128 [==========================>...] - ETA: 2s - loss: 5.1631 - accuracy: 0.2205\n",
      "Epoch 00020: loss did not improve from 5.06175\n",
      "127/128 [============================>.] - ETA: 0s - loss: 5.1730 - accuracy: 0.2207\n",
      "Epoch 00020: loss did not improve from 5.06175\n",
      "128/128 [==============================] - 35s 270ms/step - loss: 5.1719 - accuracy: 0.2208\n",
      "Epoch 21/100\n",
      "  9/128 [=>............................] - ETA: 33s - loss: 5.0485 - accuracy: 0.2218\n",
      "Epoch 00021: loss improved from 5.06175 to 5.04205, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 19/128 [===>..........................] - ETA: 30s - loss: 5.0084 - accuracy: 0.2288\n",
      "Epoch 00021: loss improved from 5.04205 to 5.01429, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 29/128 [=====>........................] - ETA: 28s - loss: 5.0321 - accuracy: 0.2254\n",
      "Epoch 00021: loss did not improve from 5.01429\n",
      " 39/128 [========>.....................] - ETA: 25s - loss: 5.0203 - accuracy: 0.2278\n",
      "Epoch 00021: loss improved from 5.01429 to 5.01402, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 49/128 [==========>...................] - ETA: 22s - loss: 5.0518 - accuracy: 0.2238\n",
      "Epoch 00021: loss did not improve from 5.01402\n",
      " 59/128 [============>.................] - ETA: 19s - loss: 5.0773 - accuracy: 0.2241\n",
      "Epoch 00021: loss did not improve from 5.01402\n",
      " 69/128 [===============>..............] - ETA: 16s - loss: 5.0876 - accuracy: 0.2235\n",
      "Epoch 00021: loss did not improve from 5.01402\n",
      " 79/128 [=================>............] - ETA: 13s - loss: 5.0881 - accuracy: 0.2238\n",
      "Epoch 00021: loss did not improve from 5.01402\n",
      " 89/128 [===================>..........] - ETA: 10s - loss: 5.1049 - accuracy: 0.2235\n",
      "Epoch 00021: loss did not improve from 5.01402\n",
      " 99/128 [======================>.......] - ETA: 8s - loss: 5.1057 - accuracy: 0.2238\n",
      "Epoch 00021: loss did not improve from 5.01402\n",
      "109/128 [========================>.....] - ETA: 5s - loss: 5.1115 - accuracy: 0.2235\n",
      "Epoch 00021: loss did not improve from 5.01402\n",
      "119/128 [==========================>...] - ETA: 2s - loss: 5.1156 - accuracy: 0.2232\n",
      "Epoch 00021: loss did not improve from 5.01402\n",
      "128/128 [==============================] - 35s 276ms/step - loss: 5.1200 - accuracy: 0.2236\n",
      "Epoch 22/100\n",
      "  1/128 [..............................] - ETA: 32s - loss: 5.1050 - accuracy: 0.1836\n",
      "Epoch 00022: loss did not improve from 5.01402\n",
      " 11/128 [=>............................] - ETA: 30s - loss: 5.0645 - accuracy: 0.2060\n",
      "Epoch 00022: loss did not improve from 5.01402\n",
      " 21/128 [===>..........................] - ETA: 29s - loss: 4.9636 - accuracy: 0.2269\n",
      "Epoch 00022: loss improved from 5.01402 to 4.95600, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 31/128 [======>.......................] - ETA: 26s - loss: 4.9537 - accuracy: 0.2296\n",
      "Epoch 00022: loss improved from 4.95600 to 4.94646, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 41/128 [========>.....................] - ETA: 24s - loss: 4.9425 - accuracy: 0.2310\n",
      "Epoch 00022: loss improved from 4.94646 to 4.94472, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 51/128 [==========>...................] - ETA: 21s - loss: 4.9643 - accuracy: 0.2290\n",
      "Epoch 00022: loss did not improve from 4.94472\n",
      " 61/128 [=============>................] - ETA: 18s - loss: 4.9732 - accuracy: 0.2284\n",
      "Epoch 00022: loss did not improve from 4.94472\n",
      " 71/128 [===============>..............] - ETA: 15s - loss: 4.9798 - accuracy: 0.2292\n",
      "Epoch 00022: loss did not improve from 4.94472\n",
      " 81/128 [=================>............] - ETA: 12s - loss: 4.9919 - accuracy: 0.2281\n",
      "Epoch 00022: loss did not improve from 4.94472\n",
      " 91/128 [====================>.........] - ETA: 10s - loss: 5.0053 - accuracy: 0.2278\n",
      "Epoch 00022: loss did not improve from 4.94472\n",
      "101/128 [======================>.......] - ETA: 7s - loss: 5.0194 - accuracy: 0.2272\n",
      "Epoch 00022: loss did not improve from 4.94472\n",
      "111/128 [=========================>....] - ETA: 4s - loss: 5.0375 - accuracy: 0.2256\n",
      "Epoch 00022: loss did not improve from 4.94472\n",
      "121/128 [===========================>..] - ETA: 1s - loss: 5.0530 - accuracy: 0.2242\n",
      "Epoch 00022: loss did not improve from 4.94472\n",
      "128/128 [==============================] - 35s 271ms/step - loss: 5.0643 - accuracy: 0.2229\n",
      "Epoch 23/100\n",
      "  3/128 [..............................] - ETA: 34s - loss: 4.8710 - accuracy: 0.2422\n",
      "Epoch 00023: loss did not improve from 4.94472\n",
      " 13/128 [==>...........................] - ETA: 30s - loss: 4.9264 - accuracy: 0.2311\n",
      "Epoch 00023: loss did not improve from 4.94472\n",
      " 23/128 [====>.........................] - ETA: 29s - loss: 4.9155 - accuracy: 0.2308\n",
      "Epoch 00023: loss improved from 4.94472 to 4.92104, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 33/128 [======>.......................] - ETA: 26s - loss: 4.9371 - accuracy: 0.2288\n",
      "Epoch 00023: loss did not improve from 4.92104\n",
      " 43/128 [=========>....................] - ETA: 23s - loss: 4.9416 - accuracy: 0.2290\n",
      "Epoch 00023: loss did not improve from 4.92104\n",
      " 53/128 [===========>..................] - ETA: 20s - loss: 4.9510 - accuracy: 0.2290\n",
      "Epoch 00023: loss did not improve from 4.92104\n",
      " 63/128 [=============>................] - ETA: 17s - loss: 4.9496 - accuracy: 0.2288\n",
      "Epoch 00023: loss did not improve from 4.92104\n",
      " 73/128 [================>.............] - ETA: 14s - loss: 4.9685 - accuracy: 0.2252\n",
      "Epoch 00023: loss did not improve from 4.92104\n",
      " 83/128 [==================>...........] - ETA: 12s - loss: 4.9692 - accuracy: 0.2251\n",
      "Epoch 00023: loss did not improve from 4.92104\n",
      " 93/128 [====================>.........] - ETA: 9s - loss: 4.9789 - accuracy: 0.2255\n",
      "Epoch 00023: loss did not improve from 4.92104\n",
      "103/128 [=======================>......] - ETA: 6s - loss: 4.9893 - accuracy: 0.2255\n",
      "Epoch 00023: loss did not improve from 4.92104\n",
      "113/128 [=========================>....] - ETA: 4s - loss: 4.9960 - accuracy: 0.2253\n",
      "Epoch 00023: loss did not improve from 4.92104\n",
      "123/128 [===========================>..] - ETA: 1s - loss: 5.0034 - accuracy: 0.2255\n",
      "Epoch 00023: loss did not improve from 4.92104\n",
      "128/128 [==============================] - 35s 270ms/step - loss: 5.0073 - accuracy: 0.2254\n",
      "Epoch 24/100\n",
      "  5/128 [>.............................] - ETA: 36s - loss: 4.8224 - accuracy: 0.2320\n",
      "Epoch 00024: loss improved from 4.92104 to 4.80800, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 15/128 [==>...........................] - ETA: 33s - loss: 4.8050 - accuracy: 0.2383\n",
      "Epoch 00024: loss improved from 4.80800 to 4.80252, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 25/128 [====>.........................] - ETA: 30s - loss: 4.8045 - accuracy: 0.2409\n",
      "Epoch 00024: loss did not improve from 4.80252\n",
      " 35/128 [=======>......................] - ETA: 26s - loss: 4.8417 - accuracy: 0.2375\n",
      "Epoch 00024: loss did not improve from 4.80252\n",
      " 45/128 [=========>....................] - ETA: 23s - loss: 4.8606 - accuracy: 0.2324\n",
      "Epoch 00024: loss did not improve from 4.80252\n",
      " 55/128 [===========>..................] - ETA: 20s - loss: 4.8716 - accuracy: 0.2307\n",
      "Epoch 00024: loss did not improve from 4.80252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 65/128 [==============>...............] - ETA: 17s - loss: 4.9028 - accuracy: 0.2275\n",
      "Epoch 00024: loss did not improve from 4.80252\n",
      " 75/128 [================>.............] - ETA: 14s - loss: 4.9237 - accuracy: 0.2251\n",
      "Epoch 00024: loss did not improve from 4.80252\n",
      " 85/128 [==================>...........] - ETA: 11s - loss: 4.9184 - accuracy: 0.2262\n",
      "Epoch 00024: loss did not improve from 4.80252\n",
      " 95/128 [=====================>........] - ETA: 9s - loss: 4.9225 - accuracy: 0.2268\n",
      "Epoch 00024: loss did not improve from 4.80252\n",
      "105/128 [=======================>......] - ETA: 6s - loss: 4.9360 - accuracy: 0.2264\n",
      "Epoch 00024: loss did not improve from 4.80252\n",
      "115/128 [=========================>....] - ETA: 3s - loss: 4.9406 - accuracy: 0.2265\n",
      "Epoch 00024: loss did not improve from 4.80252\n",
      "125/128 [============================>.] - ETA: 0s - loss: 4.9482 - accuracy: 0.2268\n",
      "Epoch 00024: loss did not improve from 4.80252\n",
      "128/128 [==============================] - 35s 275ms/step - loss: 4.9484 - accuracy: 0.2266\n",
      "Epoch 25/100\n",
      "  7/128 [>.............................] - ETA: 32s - loss: 4.8450 - accuracy: 0.2294\n",
      "Epoch 00025: loss did not improve from 4.80252\n",
      " 17/128 [==>...........................] - ETA: 30s - loss: 4.8355 - accuracy: 0.2289\n",
      "Epoch 00025: loss did not improve from 4.80252\n",
      " 27/128 [=====>........................] - ETA: 27s - loss: 4.8597 - accuracy: 0.2264\n",
      "Epoch 00025: loss did not improve from 4.80252\n",
      " 37/128 [=======>......................] - ETA: 24s - loss: 4.8752 - accuracy: 0.2248\n",
      "Epoch 00025: loss did not improve from 4.80252\n",
      " 47/128 [==========>...................] - ETA: 21s - loss: 4.8682 - accuracy: 0.2250\n",
      "Epoch 00025: loss did not improve from 4.80252\n",
      " 57/128 [============>.................] - ETA: 19s - loss: 4.8903 - accuracy: 0.2229\n",
      "Epoch 00025: loss did not improve from 4.80252\n",
      " 67/128 [==============>...............] - ETA: 16s - loss: 4.8942 - accuracy: 0.2222\n",
      "Epoch 00025: loss did not improve from 4.80252\n",
      " 77/128 [=================>............] - ETA: 13s - loss: 4.9017 - accuracy: 0.2235\n",
      "Epoch 00025: loss did not improve from 4.80252\n",
      " 87/128 [===================>..........] - ETA: 11s - loss: 4.8968 - accuracy: 0.2252\n",
      "Epoch 00025: loss did not improve from 4.80252\n",
      " 97/128 [=====================>........] - ETA: 8s - loss: 4.8955 - accuracy: 0.2257\n",
      "Epoch 00025: loss did not improve from 4.80252\n",
      "107/128 [========================>.....] - ETA: 5s - loss: 4.9020 - accuracy: 0.2257\n",
      "Epoch 00025: loss did not improve from 4.80252\n",
      "117/128 [==========================>...] - ETA: 2s - loss: 4.9047 - accuracy: 0.2263\n",
      "Epoch 00025: loss did not improve from 4.80252\n",
      "127/128 [============================>.] - ETA: 0s - loss: 4.9048 - accuracy: 0.2276\n",
      "Epoch 00025: loss did not improve from 4.80252\n",
      "128/128 [==============================] - 35s 271ms/step - loss: 4.9044 - accuracy: 0.2276\n",
      "Epoch 26/100\n",
      "  9/128 [=>............................] - ETA: 31s - loss: 4.8433 - accuracy: 0.2235\n",
      "Epoch 00026: loss did not improve from 4.80252\n",
      " 19/128 [===>..........................] - ETA: 29s - loss: 4.7897 - accuracy: 0.2294\n",
      "Epoch 00026: loss improved from 4.80252 to 4.79101, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 29/128 [=====>........................] - ETA: 26s - loss: 4.8094 - accuracy: 0.2255\n",
      "Epoch 00026: loss did not improve from 4.79101\n",
      " 39/128 [========>.....................] - ETA: 24s - loss: 4.8252 - accuracy: 0.2241\n",
      "Epoch 00026: loss did not improve from 4.79101\n",
      " 49/128 [==========>...................] - ETA: 21s - loss: 4.8211 - accuracy: 0.2253\n",
      "Epoch 00026: loss did not improve from 4.79101\n",
      " 59/128 [============>.................] - ETA: 18s - loss: 4.8222 - accuracy: 0.2256\n",
      "Epoch 00026: loss did not improve from 4.79101\n",
      " 69/128 [===============>..............] - ETA: 15s - loss: 4.8249 - accuracy: 0.2264\n",
      "Epoch 00026: loss did not improve from 4.79101\n",
      " 79/128 [=================>............] - ETA: 13s - loss: 4.8256 - accuracy: 0.2275\n",
      "Epoch 00026: loss did not improve from 4.79101\n",
      " 89/128 [===================>..........] - ETA: 10s - loss: 4.8360 - accuracy: 0.2271\n",
      "Epoch 00026: loss did not improve from 4.79101\n",
      " 99/128 [======================>.......] - ETA: 7s - loss: 4.8286 - accuracy: 0.2292\n",
      "Epoch 00026: loss did not improve from 4.79101\n",
      "109/128 [========================>.....] - ETA: 5s - loss: 4.8410 - accuracy: 0.2279\n",
      "Epoch 00026: loss did not improve from 4.79101\n",
      "119/128 [==========================>...] - ETA: 2s - loss: 4.8465 - accuracy: 0.2275\n",
      "Epoch 00026: loss did not improve from 4.79101\n",
      "128/128 [==============================] - 35s 271ms/step - loss: 4.8486 - accuracy: 0.2282\n",
      "Epoch 27/100\n",
      "  1/128 [..............................] - ETA: 35s - loss: 4.9094 - accuracy: 0.1992\n",
      "Epoch 00027: loss did not improve from 4.79101\n",
      " 11/128 [=>............................] - ETA: 30s - loss: 4.8319 - accuracy: 0.2209\n",
      "Epoch 00027: loss did not improve from 4.79101\n",
      " 21/128 [===>..........................] - ETA: 28s - loss: 4.7772 - accuracy: 0.2275\n",
      "Epoch 00027: loss improved from 4.79101 to 4.76146, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 31/128 [======>.......................] - ETA: 26s - loss: 4.7332 - accuracy: 0.2305\n",
      "Epoch 00027: loss improved from 4.76146 to 4.74256, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 41/128 [========>.....................] - ETA: 23s - loss: 4.7517 - accuracy: 0.2296\n",
      "Epoch 00027: loss did not improve from 4.74256\n",
      " 51/128 [==========>...................] - ETA: 20s - loss: 4.7655 - accuracy: 0.2286\n",
      "Epoch 00027: loss did not improve from 4.74256\n",
      " 61/128 [=============>................] - ETA: 18s - loss: 4.7655 - accuracy: 0.2293\n",
      "Epoch 00027: loss did not improve from 4.74256\n",
      " 71/128 [===============>..............] - ETA: 15s - loss: 4.7652 - accuracy: 0.2302\n",
      "Epoch 00027: loss did not improve from 4.74256\n",
      " 81/128 [=================>............] - ETA: 12s - loss: 4.7713 - accuracy: 0.2299\n",
      "Epoch 00027: loss did not improve from 4.74256\n",
      " 91/128 [====================>.........] - ETA: 10s - loss: 4.7773 - accuracy: 0.2291\n",
      "Epoch 00027: loss did not improve from 4.74256\n",
      "101/128 [======================>.......] - ETA: 7s - loss: 4.7761 - accuracy: 0.2297\n",
      "Epoch 00027: loss did not improve from 4.74256\n",
      "111/128 [=========================>....] - ETA: 4s - loss: 4.7721 - accuracy: 0.2317\n",
      "Epoch 00027: loss did not improve from 4.74256\n",
      "121/128 [===========================>..] - ETA: 1s - loss: 4.7785 - accuracy: 0.2315\n",
      "Epoch 00027: loss did not improve from 4.74256\n",
      "128/128 [==============================] - 35s 272ms/step - loss: 4.7851 - accuracy: 0.2311\n",
      "Epoch 28/100\n",
      "  3/128 [..............................] - ETA: 33s - loss: 4.6567 - accuracy: 0.2214\n",
      "Epoch 00028: loss did not improve from 4.74256\n",
      " 13/128 [==>...........................] - ETA: 29s - loss: 4.7699 - accuracy: 0.2206\n",
      "Epoch 00028: loss did not improve from 4.74256\n",
      " 23/128 [====>.........................] - ETA: 28s - loss: 4.7169 - accuracy: 0.2284\n",
      "Epoch 00028: loss improved from 4.74256 to 4.72065, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 33/128 [======>.......................] - ETA: 25s - loss: 4.7297 - accuracy: 0.2279\n",
      "Epoch 00028: loss did not improve from 4.72065\n",
      " 43/128 [=========>....................] - ETA: 22s - loss: 4.7140 - accuracy: 0.2299\n",
      "Epoch 00028: loss did not improve from 4.72065\n",
      " 53/128 [===========>..................] - ETA: 20s - loss: 4.7124 - accuracy: 0.2275\n",
      "Epoch 00028: loss improved from 4.72065 to 4.71143, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 63/128 [=============>................] - ETA: 17s - loss: 4.7061 - accuracy: 0.2290\n",
      "Epoch 00028: loss improved from 4.71143 to 4.70060, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 73/128 [================>.............] - ETA: 14s - loss: 4.7035 - accuracy: 0.2296\n",
      "Epoch 00028: loss did not improve from 4.70060\n",
      " 83/128 [==================>...........] - ETA: 12s - loss: 4.6937 - accuracy: 0.2321\n",
      "Epoch 00028: loss improved from 4.70060 to 4.69516, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 93/128 [====================>.........] - ETA: 9s - loss: 4.7010 - accuracy: 0.2319\n",
      "Epoch 00028: loss did not improve from 4.69516\n",
      "103/128 [=======================>......] - ETA: 6s - loss: 4.7030 - accuracy: 0.2324\n",
      "Epoch 00028: loss did not improve from 4.69516\n",
      "113/128 [=========================>....] - ETA: 4s - loss: 4.7152 - accuracy: 0.2321\n",
      "Epoch 00028: loss did not improve from 4.69516\n",
      "123/128 [===========================>..] - ETA: 1s - loss: 4.7118 - accuracy: 0.2331\n",
      "Epoch 00028: loss did not improve from 4.69516\n",
      "128/128 [==============================] - 35s 273ms/step - loss: 4.7149 - accuracy: 0.2334\n",
      "Epoch 29/100\n",
      "  5/128 [>.............................] - ETA: 32s - loss: 4.4520 - accuracy: 0.2516\n",
      "Epoch 00029: loss improved from 4.69516 to 4.50519, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 15/128 [==>...........................] - ETA: 30s - loss: 4.5204 - accuracy: 0.2404\n",
      "Epoch 00029: loss did not improve from 4.50519\n",
      " 25/128 [====>.........................] - ETA: 28s - loss: 4.5624 - accuracy: 0.2381\n",
      "Epoch 00029: loss did not improve from 4.50519\n",
      " 35/128 [=======>......................] - ETA: 25s - loss: 4.5823 - accuracy: 0.2387\n",
      "Epoch 00029: loss did not improve from 4.50519\n",
      " 45/128 [=========>....................] - ETA: 22s - loss: 4.5804 - accuracy: 0.2402\n",
      "Epoch 00029: loss did not improve from 4.50519\n",
      " 55/128 [===========>..................] - ETA: 19s - loss: 4.6178 - accuracy: 0.2362\n",
      "Epoch 00029: loss did not improve from 4.50519\n",
      " 65/128 [==============>...............] - ETA: 16s - loss: 4.6202 - accuracy: 0.2347\n",
      "Epoch 00029: loss did not improve from 4.50519\n",
      " 75/128 [================>.............] - ETA: 14s - loss: 4.6316 - accuracy: 0.2329\n",
      "Epoch 00029: loss did not improve from 4.50519\n",
      " 85/128 [==================>...........] - ETA: 11s - loss: 4.6292 - accuracy: 0.2336\n",
      "Epoch 00029: loss did not improve from 4.50519\n",
      " 95/128 [=====================>........] - ETA: 8s - loss: 4.6278 - accuracy: 0.2345\n",
      "Epoch 00029: loss did not improve from 4.50519\n",
      "105/128 [=======================>......] - ETA: 6s - loss: 4.6327 - accuracy: 0.2345\n",
      "Epoch 00029: loss did not improve from 4.50519\n",
      "115/128 [=========================>....] - ETA: 3s - loss: 4.6328 - accuracy: 0.2359\n",
      "Epoch 00029: loss did not improve from 4.50519\n",
      "125/128 [============================>.] - ETA: 0s - loss: 4.6452 - accuracy: 0.2342\n",
      "Epoch 00029: loss did not improve from 4.50519\n",
      "128/128 [==============================] - 35s 273ms/step - loss: 4.6459 - accuracy: 0.2340\n",
      "Epoch 30/100\n",
      "  7/128 [>.............................] - ETA: 33s - loss: 4.5453 - accuracy: 0.2327\n",
      "Epoch 00030: loss did not improve from 4.50519\n",
      " 17/128 [==>...........................] - ETA: 30s - loss: 4.5305 - accuracy: 0.2330\n",
      "Epoch 00030: loss did not improve from 4.50519\n",
      " 27/128 [=====>........................] - ETA: 27s - loss: 4.5623 - accuracy: 0.2326\n",
      "Epoch 00030: loss did not improve from 4.50519\n",
      " 37/128 [=======>......................] - ETA: 24s - loss: 4.5364 - accuracy: 0.2373\n",
      "Epoch 00030: loss did not improve from 4.50519\n",
      " 47/128 [==========>...................] - ETA: 21s - loss: 4.5477 - accuracy: 0.2360\n",
      "Epoch 00030: loss did not improve from 4.50519\n",
      " 57/128 [============>.................] - ETA: 19s - loss: 4.5314 - accuracy: 0.2383\n",
      "Epoch 00030: loss did not improve from 4.50519\n",
      " 67/128 [==============>...............] - ETA: 16s - loss: 4.5459 - accuracy: 0.2369\n",
      "Epoch 00030: loss did not improve from 4.50519\n",
      " 77/128 [=================>............] - ETA: 13s - loss: 4.5521 - accuracy: 0.2370\n",
      "Epoch 00030: loss did not improve from 4.50519\n",
      " 87/128 [===================>..........] - ETA: 11s - loss: 4.5618 - accuracy: 0.2369\n",
      "Epoch 00030: loss did not improve from 4.50519\n",
      " 97/128 [=====================>........] - ETA: 8s - loss: 4.5629 - accuracy: 0.2376\n",
      "Epoch 00030: loss did not improve from 4.50519\n",
      "107/128 [========================>.....] - ETA: 5s - loss: 4.5668 - accuracy: 0.2381\n",
      "Epoch 00030: loss did not improve from 4.50519\n",
      "117/128 [==========================>...] - ETA: 2s - loss: 4.5785 - accuracy: 0.2370\n",
      "Epoch 00030: loss did not improve from 4.50519\n",
      "127/128 [============================>.] - ETA: 0s - loss: 4.5896 - accuracy: 0.2360\n",
      "Epoch 00030: loss did not improve from 4.50519\n",
      "128/128 [==============================] - 35s 270ms/step - loss: 4.5909 - accuracy: 0.2360\n",
      "Epoch 31/100\n",
      "  9/128 [=>............................] - ETA: 30s - loss: 4.4039 - accuracy: 0.2448\n",
      "Epoch 00031: loss improved from 4.50519 to 4.40096, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 19/128 [===>..........................] - ETA: 29s - loss: 4.4227 - accuracy: 0.2424\n",
      "Epoch 00031: loss did not improve from 4.40096\n",
      " 29/128 [=====>........................] - ETA: 26s - loss: 4.4265 - accuracy: 0.2418\n",
      "Epoch 00031: loss did not improve from 4.40096\n",
      " 39/128 [========>.....................] - ETA: 23s - loss: 4.4483 - accuracy: 0.2393\n",
      "Epoch 00031: loss did not improve from 4.40096\n",
      " 49/128 [==========>...................] - ETA: 20s - loss: 4.4682 - accuracy: 0.2386\n",
      "Epoch 00031: loss did not improve from 4.40096\n",
      " 59/128 [============>.................] - ETA: 18s - loss: 4.4894 - accuracy: 0.2368\n",
      "Epoch 00031: loss did not improve from 4.40096\n",
      " 69/128 [===============>..............] - ETA: 15s - loss: 4.5028 - accuracy: 0.2365\n",
      "Epoch 00031: loss did not improve from 4.40096\n",
      " 79/128 [=================>............] - ETA: 13s - loss: 4.5065 - accuracy: 0.2369\n",
      "Epoch 00031: loss did not improve from 4.40096\n",
      " 89/128 [===================>..........] - ETA: 10s - loss: 4.5188 - accuracy: 0.2363\n",
      "Epoch 00031: loss did not improve from 4.40096\n",
      " 99/128 [======================>.......] - ETA: 7s - loss: 4.5172 - accuracy: 0.2386\n",
      "Epoch 00031: loss did not improve from 4.40096\n",
      "109/128 [========================>.....] - ETA: 5s - loss: 4.5280 - accuracy: 0.2376\n",
      "Epoch 00031: loss did not improve from 4.40096\n",
      "119/128 [==========================>...] - ETA: 2s - loss: 4.5329 - accuracy: 0.2378\n",
      "Epoch 00031: loss did not improve from 4.40096\n",
      "128/128 [==============================] - 34s 270ms/step - loss: 4.5344 - accuracy: 0.2385\n",
      "Epoch 32/100\n",
      "  1/128 [..............................] - ETA: 33s - loss: 4.5054 - accuracy: 0.2266\n",
      "Epoch 00032: loss improved from 4.40096 to 4.36979, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 11/128 [=>............................] - ETA: 32s - loss: 4.3816 - accuracy: 0.2546\n",
      "Epoch 00032: loss improved from 4.36979 to 4.36721, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 21/128 [===>..........................] - ETA: 30s - loss: 4.3889 - accuracy: 0.2519\n",
      "Epoch 00032: loss did not improve from 4.36721\n",
      " 31/128 [======>.......................] - ETA: 26s - loss: 4.4058 - accuracy: 0.2480\n",
      "Epoch 00032: loss did not improve from 4.36721\n",
      " 41/128 [========>.....................] - ETA: 23s - loss: 4.3911 - accuracy: 0.2485\n",
      "Epoch 00032: loss did not improve from 4.36721\n",
      " 51/128 [==========>...................] - ETA: 20s - loss: 4.4140 - accuracy: 0.2458\n",
      "Epoch 00032: loss did not improve from 4.36721\n",
      " 61/128 [=============>................] - ETA: 18s - loss: 4.4274 - accuracy: 0.2440\n",
      "Epoch 00032: loss did not improve from 4.36721\n",
      " 71/128 [===============>..............] - ETA: 15s - loss: 4.4480 - accuracy: 0.2431\n",
      "Epoch 00032: loss did not improve from 4.36721\n",
      " 81/128 [=================>............] - ETA: 12s - loss: 4.4685 - accuracy: 0.2396\n",
      "Epoch 00032: loss did not improve from 4.36721\n",
      " 91/128 [====================>.........] - ETA: 10s - loss: 4.4691 - accuracy: 0.2416\n",
      "Epoch 00032: loss did not improve from 4.36721\n",
      "101/128 [======================>.......] - ETA: 7s - loss: 4.4726 - accuracy: 0.2408\n",
      "Epoch 00032: loss did not improve from 4.36721\n",
      "111/128 [=========================>....] - ETA: 4s - loss: 4.4848 - accuracy: 0.2402\n",
      "Epoch 00032: loss did not improve from 4.36721\n",
      "121/128 [===========================>..] - ETA: 1s - loss: 4.4861 - accuracy: 0.2405\n",
      "Epoch 00032: loss did not improve from 4.36721\n",
      "128/128 [==============================] - 35s 274ms/step - loss: 4.4868 - accuracy: 0.2411\n",
      "Epoch 33/100\n",
      "  3/128 [..............................] - ETA: 33s - loss: 4.3661 - accuracy: 0.2357\n",
      "Epoch 00033: loss improved from 4.36721 to 4.35485, saving model to ./export/2023-10-02T110043/model.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 13/128 [==>...........................] - ETA: 31s - loss: 4.4241 - accuracy: 0.2323\n",
      "Epoch 00033: loss did not improve from 4.35485\n",
      " 23/128 [====>.........................] - ETA: 28s - loss: 4.4203 - accuracy: 0.2349\n",
      "Epoch 00033: loss did not improve from 4.35485\n",
      " 33/128 [======>.......................] - ETA: 25s - loss: 4.4189 - accuracy: 0.2366\n",
      "Epoch 00033: loss did not improve from 4.35485\n",
      " 43/128 [=========>....................] - ETA: 23s - loss: 4.3880 - accuracy: 0.2419\n",
      "Epoch 00033: loss did not improve from 4.35485\n",
      " 53/128 [===========>..................] - ETA: 20s - loss: 4.3842 - accuracy: 0.2412\n",
      "Epoch 00033: loss did not improve from 4.35485\n",
      " 63/128 [=============>................] - ETA: 17s - loss: 4.3813 - accuracy: 0.2439\n",
      "Epoch 00033: loss did not improve from 4.35485\n",
      " 73/128 [================>.............] - ETA: 15s - loss: 4.3919 - accuracy: 0.2441\n",
      "Epoch 00033: loss did not improve from 4.35485\n",
      " 83/128 [==================>...........] - ETA: 12s - loss: 4.3982 - accuracy: 0.2439\n",
      "Epoch 00033: loss did not improve from 4.35485\n",
      " 93/128 [====================>.........] - ETA: 9s - loss: 4.4022 - accuracy: 0.2449\n",
      "Epoch 00033: loss did not improve from 4.35485\n",
      "103/128 [=======================>......] - ETA: 6s - loss: 4.4139 - accuracy: 0.2441\n",
      "Epoch 00033: loss did not improve from 4.35485\n",
      "113/128 [=========================>....] - ETA: 4s - loss: 4.4211 - accuracy: 0.2446\n",
      "Epoch 00033: loss did not improve from 4.35485\n",
      "123/128 [===========================>..] - ETA: 1s - loss: 4.4229 - accuracy: 0.2449\n",
      "Epoch 00033: loss did not improve from 4.35485\n",
      "128/128 [==============================] - 35s 271ms/step - loss: 4.4307 - accuracy: 0.2437\n",
      "Epoch 34/100\n",
      "  5/128 [>.............................] - ETA: 30s - loss: 4.2159 - accuracy: 0.2641\n",
      "Epoch 00034: loss improved from 4.35485 to 4.20941, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 15/128 [==>...........................] - ETA: 30s - loss: 4.2417 - accuracy: 0.2576\n",
      "Epoch 00034: loss did not improve from 4.20941\n",
      " 25/128 [====>.........................] - ETA: 27s - loss: 4.2676 - accuracy: 0.2566\n",
      "Epoch 00034: loss did not improve from 4.20941\n",
      " 35/128 [=======>......................] - ETA: 25s - loss: 4.3008 - accuracy: 0.2510\n",
      "Epoch 00034: loss did not improve from 4.20941\n",
      " 45/128 [=========>....................] - ETA: 22s - loss: 4.3095 - accuracy: 0.2493\n",
      "Epoch 00034: loss did not improve from 4.20941\n",
      " 55/128 [===========>..................] - ETA: 19s - loss: 4.3299 - accuracy: 0.2459\n",
      "Epoch 00034: loss did not improve from 4.20941\n",
      " 65/128 [==============>...............] - ETA: 17s - loss: 4.3206 - accuracy: 0.2476\n",
      "Epoch 00034: loss did not improve from 4.20941\n",
      " 75/128 [================>.............] - ETA: 15s - loss: 4.3295 - accuracy: 0.2467\n",
      "Epoch 00034: loss did not improve from 4.20941\n",
      " 85/128 [==================>...........] - ETA: 12s - loss: 4.3360 - accuracy: 0.2471\n",
      "Epoch 00034: loss did not improve from 4.20941\n",
      " 95/128 [=====================>........] - ETA: 9s - loss: 4.3412 - accuracy: 0.2470\n",
      "Epoch 00034: loss did not improve from 4.20941\n",
      "105/128 [=======================>......] - ETA: 6s - loss: 4.3446 - accuracy: 0.2472\n",
      "Epoch 00034: loss did not improve from 4.20941\n",
      "115/128 [=========================>....] - ETA: 3s - loss: 4.3522 - accuracy: 0.2470\n",
      "Epoch 00034: loss did not improve from 4.20941\n",
      "125/128 [============================>.] - ETA: 0s - loss: 4.3631 - accuracy: 0.2458\n",
      "Epoch 00034: loss did not improve from 4.20941\n",
      "128/128 [==============================] - 35s 277ms/step - loss: 4.3653 - accuracy: 0.2459\n",
      "Epoch 35/100\n",
      "  7/128 [>.............................] - ETA: 30s - loss: 4.2112 - accuracy: 0.2533\n",
      "Epoch 00035: loss improved from 4.20941 to 4.19381, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 17/128 [==>...........................] - ETA: 29s - loss: 4.1769 - accuracy: 0.2574\n",
      "Epoch 00035: loss improved from 4.19381 to 4.17911, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 27/128 [=====>........................] - ETA: 26s - loss: 4.1917 - accuracy: 0.2569\n",
      "Epoch 00035: loss did not improve from 4.17911\n",
      " 37/128 [=======>......................] - ETA: 24s - loss: 4.1850 - accuracy: 0.2582\n",
      "Epoch 00035: loss did not improve from 4.17911\n",
      " 47/128 [==========>...................] - ETA: 21s - loss: 4.2021 - accuracy: 0.2565\n",
      "Epoch 00035: loss did not improve from 4.17911\n",
      " 57/128 [============>.................] - ETA: 19s - loss: 4.2128 - accuracy: 0.2542\n",
      "Epoch 00035: loss did not improve from 4.17911\n",
      " 67/128 [==============>...............] - ETA: 16s - loss: 4.2198 - accuracy: 0.2551\n",
      "Epoch 00035: loss did not improve from 4.17911\n",
      " 77/128 [=================>............] - ETA: 13s - loss: 4.2307 - accuracy: 0.2541\n",
      "Epoch 00035: loss did not improve from 4.17911\n",
      " 87/128 [===================>..........] - ETA: 10s - loss: 4.2531 - accuracy: 0.2528\n",
      "Epoch 00035: loss did not improve from 4.17911\n",
      " 97/128 [=====================>........] - ETA: 8s - loss: 4.2527 - accuracy: 0.2537\n",
      "Epoch 00035: loss did not improve from 4.17911\n",
      "107/128 [========================>.....] - ETA: 5s - loss: 4.2605 - accuracy: 0.2531\n",
      "Epoch 00035: loss did not improve from 4.17911\n",
      "117/128 [==========================>...] - ETA: 2s - loss: 4.2670 - accuracy: 0.2528\n",
      "Epoch 00035: loss did not improve from 4.17911\n",
      "127/128 [============================>.] - ETA: 0s - loss: 4.2731 - accuracy: 0.2525\n",
      "Epoch 00035: loss did not improve from 4.17911\n",
      "128/128 [==============================] - 34s 268ms/step - loss: 4.2741 - accuracy: 0.2524\n",
      "Epoch 36/100\n",
      "  9/128 [=>............................] - ETA: 31s - loss: 4.1306 - accuracy: 0.2543\n",
      "Epoch 00036: loss improved from 4.17911 to 4.14846, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 19/128 [===>..........................] - ETA: 29s - loss: 4.1639 - accuracy: 0.2521\n",
      "Epoch 00036: loss did not improve from 4.14846\n",
      " 29/128 [=====>........................] - ETA: 27s - loss: 4.1453 - accuracy: 0.2540\n",
      "Epoch 00036: loss improved from 4.14846 to 4.13930, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 39/128 [========>.....................] - ETA: 24s - loss: 4.1439 - accuracy: 0.2548\n",
      "Epoch 00036: loss did not improve from 4.13930\n",
      " 49/128 [==========>...................] - ETA: 21s - loss: 4.1627 - accuracy: 0.2541\n",
      "Epoch 00036: loss did not improve from 4.13930\n",
      " 59/128 [============>.................] - ETA: 18s - loss: 4.1600 - accuracy: 0.2552\n",
      "Epoch 00036: loss did not improve from 4.13930\n",
      " 69/128 [===============>..............] - ETA: 16s - loss: 4.1659 - accuracy: 0.2557\n",
      "Epoch 00036: loss did not improve from 4.13930\n",
      " 79/128 [=================>............] - ETA: 13s - loss: 4.1690 - accuracy: 0.2570\n",
      "Epoch 00036: loss did not improve from 4.13930\n",
      " 89/128 [===================>..........] - ETA: 10s - loss: 4.1844 - accuracy: 0.2553\n",
      "Epoch 00036: loss did not improve from 4.13930\n",
      " 99/128 [======================>.......] - ETA: 7s - loss: 4.1887 - accuracy: 0.2565\n",
      "Epoch 00036: loss did not improve from 4.13930\n",
      "109/128 [========================>.....] - ETA: 5s - loss: 4.1948 - accuracy: 0.2567\n",
      "Epoch 00036: loss did not improve from 4.13930\n",
      "119/128 [==========================>...] - ETA: 2s - loss: 4.2073 - accuracy: 0.2558\n",
      "Epoch 00036: loss did not improve from 4.13930\n",
      "128/128 [==============================] - 34s 266ms/step - loss: 4.2134 - accuracy: 0.2562\n",
      "Epoch 37/100\n",
      "  1/128 [..............................] - ETA: 30s - loss: 3.8548 - accuracy: 0.3203\n",
      "Epoch 00037: loss improved from 4.13930 to 3.99983, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 11/128 [=>............................] - ETA: 30s - loss: 4.0326 - accuracy: 0.2706\n",
      "Epoch 00037: loss did not improve from 3.99983\n",
      " 21/128 [===>..........................] - ETA: 28s - loss: 4.0711 - accuracy: 0.2664\n",
      "Epoch 00037: loss did not improve from 3.99983\n",
      " 31/128 [======>.......................] - ETA: 25s - loss: 4.1100 - accuracy: 0.2601\n",
      "Epoch 00037: loss did not improve from 3.99983\n",
      " 41/128 [========>.....................] - ETA: 22s - loss: 4.1081 - accuracy: 0.2591\n",
      "Epoch 00037: loss did not improve from 3.99983\n",
      " 51/128 [==========>...................] - ETA: 20s - loss: 4.1168 - accuracy: 0.2585\n",
      "Epoch 00037: loss did not improve from 3.99983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 61/128 [=============>................] - ETA: 17s - loss: 4.1269 - accuracy: 0.2576\n",
      "Epoch 00037: loss did not improve from 3.99983\n",
      " 71/128 [===============>..............] - ETA: 15s - loss: 4.1341 - accuracy: 0.2576\n",
      "Epoch 00037: loss did not improve from 3.99983\n",
      " 81/128 [=================>............] - ETA: 12s - loss: 4.1388 - accuracy: 0.2580\n",
      "Epoch 00037: loss did not improve from 3.99983\n",
      " 91/128 [====================>.........] - ETA: 9s - loss: 4.1475 - accuracy: 0.2576 \n",
      "Epoch 00037: loss did not improve from 3.99983\n",
      "101/128 [======================>.......] - ETA: 7s - loss: 4.1485 - accuracy: 0.2577\n",
      "Epoch 00037: loss did not improve from 3.99983\n",
      "111/128 [=========================>....] - ETA: 4s - loss: 4.1542 - accuracy: 0.2586\n",
      "Epoch 00037: loss did not improve from 3.99983\n",
      "121/128 [===========================>..] - ETA: 1s - loss: 4.1626 - accuracy: 0.2587\n",
      "Epoch 00037: loss did not improve from 3.99983\n",
      "128/128 [==============================] - 34s 266ms/step - loss: 4.1668 - accuracy: 0.2586\n",
      "Epoch 38/100\n",
      "  3/128 [..............................] - ETA: 33s - loss: 4.0411 - accuracy: 0.2617\n",
      "Epoch 00038: loss did not improve from 3.99983\n",
      " 13/128 [==>...........................] - ETA: 29s - loss: 4.0301 - accuracy: 0.2650\n",
      "Epoch 00038: loss did not improve from 3.99983\n",
      " 23/128 [====>.........................] - ETA: 28s - loss: 4.0187 - accuracy: 0.2677\n",
      "Epoch 00038: loss did not improve from 3.99983\n",
      " 33/128 [======>.......................] - ETA: 26s - loss: 4.0239 - accuracy: 0.2679\n",
      "Epoch 00038: loss did not improve from 3.99983\n",
      " 43/128 [=========>....................] - ETA: 24s - loss: 4.0451 - accuracy: 0.2677\n",
      "Epoch 00038: loss did not improve from 3.99983\n",
      " 53/128 [===========>..................] - ETA: 21s - loss: 4.0724 - accuracy: 0.2644\n",
      "Epoch 00038: loss did not improve from 3.99983\n",
      " 63/128 [=============>................] - ETA: 18s - loss: 4.0606 - accuracy: 0.2651\n",
      "Epoch 00038: loss did not improve from 3.99983\n",
      " 73/128 [================>.............] - ETA: 15s - loss: 4.0732 - accuracy: 0.2643\n",
      "Epoch 00038: loss did not improve from 3.99983\n",
      " 83/128 [==================>...........] - ETA: 12s - loss: 4.0841 - accuracy: 0.2646\n",
      "Epoch 00038: loss did not improve from 3.99983\n",
      " 93/128 [====================>.........] - ETA: 9s - loss: 4.0964 - accuracy: 0.2636\n",
      "Epoch 00038: loss did not improve from 3.99983\n",
      "103/128 [=======================>......] - ETA: 6s - loss: 4.1062 - accuracy: 0.2635\n",
      "Epoch 00038: loss did not improve from 3.99983\n",
      "113/128 [=========================>....] - ETA: 4s - loss: 4.1217 - accuracy: 0.2628\n",
      "Epoch 00038: loss did not improve from 3.99983\n",
      "123/128 [===========================>..] - ETA: 1s - loss: 4.1378 - accuracy: 0.2617\n",
      "Epoch 00038: loss did not improve from 3.99983\n",
      "128/128 [==============================] - 35s 272ms/step - loss: 4.1440 - accuracy: 0.2611\n",
      "Epoch 39/100\n",
      "  5/128 [>.............................] - ETA: 29s - loss: 3.9231 - accuracy: 0.2758\n",
      "Epoch 00039: loss improved from 3.99983 to 3.91281, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 15/128 [==>...........................] - ETA: 29s - loss: 3.9839 - accuracy: 0.2711\n",
      "Epoch 00039: loss did not improve from 3.91281\n",
      " 25/128 [====>.........................] - ETA: 27s - loss: 3.9879 - accuracy: 0.2723\n",
      "Epoch 00039: loss did not improve from 3.91281\n",
      " 35/128 [=======>......................] - ETA: 25s - loss: 4.0046 - accuracy: 0.2731\n",
      "Epoch 00039: loss did not improve from 3.91281\n",
      " 45/128 [=========>....................] - ETA: 22s - loss: 3.9987 - accuracy: 0.2758\n",
      "Epoch 00039: loss did not improve from 3.91281\n",
      " 55/128 [===========>..................] - ETA: 19s - loss: 4.0288 - accuracy: 0.2714\n",
      "Epoch 00039: loss did not improve from 3.91281\n",
      " 65/128 [==============>...............] - ETA: 16s - loss: 4.0315 - accuracy: 0.2719\n",
      "Epoch 00039: loss did not improve from 3.91281\n",
      " 75/128 [================>.............] - ETA: 14s - loss: 4.0554 - accuracy: 0.2691\n",
      "Epoch 00039: loss did not improve from 3.91281\n",
      " 85/128 [==================>...........] - ETA: 11s - loss: 4.0734 - accuracy: 0.2676\n",
      "Epoch 00039: loss did not improve from 3.91281\n",
      " 95/128 [=====================>........] - ETA: 8s - loss: 4.0775 - accuracy: 0.2666\n",
      "Epoch 00039: loss did not improve from 3.91281\n",
      "105/128 [=======================>......] - ETA: 6s - loss: 4.0895 - accuracy: 0.2671\n",
      "Epoch 00039: loss did not improve from 3.91281\n",
      "115/128 [=========================>....] - ETA: 3s - loss: 4.0916 - accuracy: 0.2680\n",
      "Epoch 00039: loss did not improve from 3.91281\n",
      "125/128 [============================>.] - ETA: 0s - loss: 4.0997 - accuracy: 0.2676\n",
      "Epoch 00039: loss did not improve from 3.91281\n",
      "128/128 [==============================] - 34s 268ms/step - loss: 4.1012 - accuracy: 0.2675\n",
      "Epoch 40/100\n",
      "  7/128 [>.............................] - ETA: 32s - loss: 3.8999 - accuracy: 0.2829\n",
      "Epoch 00040: loss did not improve from 3.91281\n",
      " 17/128 [==>...........................] - ETA: 29s - loss: 3.9845 - accuracy: 0.2718\n",
      "Epoch 00040: loss did not improve from 3.91281\n",
      " 27/128 [=====>........................] - ETA: 27s - loss: 3.9604 - accuracy: 0.2731\n",
      "Epoch 00040: loss did not improve from 3.91281\n",
      " 37/128 [=======>......................] - ETA: 25s - loss: 3.9697 - accuracy: 0.2727\n",
      "Epoch 00040: loss did not improve from 3.91281\n",
      " 47/128 [==========>...................] - ETA: 22s - loss: 3.9787 - accuracy: 0.2709\n",
      "Epoch 00040: loss did not improve from 3.91281\n",
      " 57/128 [============>.................] - ETA: 19s - loss: 3.9777 - accuracy: 0.2708\n",
      "Epoch 00040: loss did not improve from 3.91281\n",
      " 67/128 [==============>...............] - ETA: 16s - loss: 3.9860 - accuracy: 0.2717\n",
      "Epoch 00040: loss did not improve from 3.91281\n",
      " 77/128 [=================>............] - ETA: 13s - loss: 3.9925 - accuracy: 0.2719\n",
      "Epoch 00040: loss did not improve from 3.91281\n",
      " 87/128 [===================>..........] - ETA: 11s - loss: 4.0172 - accuracy: 0.2702\n",
      "Epoch 00040: loss did not improve from 3.91281\n",
      " 97/128 [=====================>........] - ETA: 8s - loss: 4.0316 - accuracy: 0.2692\n",
      "Epoch 00040: loss did not improve from 3.91281\n",
      "107/128 [========================>.....] - ETA: 5s - loss: 4.0425 - accuracy: 0.2693\n",
      "Epoch 00040: loss did not improve from 3.91281\n",
      "117/128 [==========================>...] - ETA: 2s - loss: 4.0550 - accuracy: 0.2686\n",
      "Epoch 00040: loss did not improve from 3.91281\n",
      "127/128 [============================>.] - ETA: 0s - loss: 4.0694 - accuracy: 0.2681\n",
      "Epoch 00040: loss did not improve from 3.91281\n",
      "128/128 [==============================] - 34s 269ms/step - loss: 4.0722 - accuracy: 0.2680\n",
      "Epoch 41/100\n",
      "  9/128 [=>............................] - ETA: 32s - loss: 4.0400 - accuracy: 0.2665\n",
      "Epoch 00041: loss did not improve from 3.91281\n",
      " 19/128 [===>..........................] - ETA: 31s - loss: 4.0307 - accuracy: 0.2677\n",
      "Epoch 00041: loss did not improve from 3.91281\n",
      " 29/128 [=====>........................] - ETA: 28s - loss: 4.0070 - accuracy: 0.2702\n",
      "Epoch 00041: loss did not improve from 3.91281\n",
      " 39/128 [========>.....................] - ETA: 25s - loss: 4.0181 - accuracy: 0.2694\n",
      "Epoch 00041: loss did not improve from 3.91281\n",
      " 49/128 [==========>...................] - ETA: 22s - loss: 3.9938 - accuracy: 0.2738\n",
      "Epoch 00041: loss did not improve from 3.91281\n",
      " 59/128 [============>.................] - ETA: 19s - loss: 3.9918 - accuracy: 0.2733\n",
      "Epoch 00041: loss did not improve from 3.91281\n",
      " 69/128 [===============>..............] - ETA: 16s - loss: 3.9966 - accuracy: 0.2730\n",
      "Epoch 00041: loss did not improve from 3.91281\n",
      " 79/128 [=================>............] - ETA: 13s - loss: 4.0046 - accuracy: 0.2731\n",
      "Epoch 00041: loss did not improve from 3.91281\n",
      " 89/128 [===================>..........] - ETA: 10s - loss: 4.0118 - accuracy: 0.2736\n",
      "Epoch 00041: loss did not improve from 3.91281\n",
      " 99/128 [======================>.......] - ETA: 7s - loss: 4.0230 - accuracy: 0.2721\n",
      "Epoch 00041: loss did not improve from 3.91281\n",
      "109/128 [========================>.....] - ETA: 5s - loss: 4.0309 - accuracy: 0.2727\n",
      "Epoch 00041: loss did not improve from 3.91281\n",
      "119/128 [==========================>...] - ETA: 2s - loss: 4.0474 - accuracy: 0.2716\n",
      "Epoch 00041: loss did not improve from 3.91281\n",
      "128/128 [==============================] - 35s 274ms/step - loss: 4.0529 - accuracy: 0.2713\n",
      "Epoch 42/100\n",
      "  1/128 [..............................] - ETA: 30s - loss: 3.9612 - accuracy: 0.2656\n",
      "Epoch 00042: loss did not improve from 3.91281\n",
      " 11/128 [=>............................] - ETA: 30s - loss: 3.9159 - accuracy: 0.2781\n",
      "Epoch 00042: loss did not improve from 3.91281\n",
      " 21/128 [===>..........................] - ETA: 28s - loss: 3.9072 - accuracy: 0.2786\n",
      "Epoch 00042: loss improved from 3.91281 to 3.90503, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 31/128 [======>.......................] - ETA: 25s - loss: 3.9088 - accuracy: 0.2814\n",
      "Epoch 00042: loss did not improve from 3.90503\n",
      " 41/128 [========>.....................] - ETA: 22s - loss: 3.9199 - accuracy: 0.2796\n",
      "Epoch 00042: loss did not improve from 3.90503\n",
      " 51/128 [==========>...................] - ETA: 20s - loss: 3.9266 - accuracy: 0.2787\n",
      "Epoch 00042: loss did not improve from 3.90503\n",
      " 61/128 [=============>................] - ETA: 17s - loss: 3.9325 - accuracy: 0.2780\n",
      "Epoch 00042: loss did not improve from 3.90503\n",
      " 71/128 [===============>..............] - ETA: 14s - loss: 3.9402 - accuracy: 0.2784\n",
      "Epoch 00042: loss did not improve from 3.90503\n",
      " 81/128 [=================>............] - ETA: 12s - loss: 3.9607 - accuracy: 0.2767\n",
      "Epoch 00042: loss did not improve from 3.90503\n",
      " 91/128 [====================>.........] - ETA: 9s - loss: 3.9721 - accuracy: 0.2758 \n",
      "Epoch 00042: loss did not improve from 3.90503\n",
      "101/128 [======================>.......] - ETA: 7s - loss: 3.9887 - accuracy: 0.2749\n",
      "Epoch 00042: loss did not improve from 3.90503\n",
      "111/128 [=========================>....] - ETA: 4s - loss: 4.0004 - accuracy: 0.2744\n",
      "Epoch 00042: loss did not improve from 3.90503\n",
      "121/128 [===========================>..] - ETA: 1s - loss: 4.0130 - accuracy: 0.2733\n",
      "Epoch 00042: loss did not improve from 3.90503\n",
      "128/128 [==============================] - 35s 271ms/step - loss: 4.0194 - accuracy: 0.2732\n",
      "Epoch 43/100\n",
      "  3/128 [..............................] - ETA: 33s - loss: 3.7281 - accuracy: 0.3008\n",
      "Epoch 00043: loss improved from 3.90503 to 3.76863, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 13/128 [==>...........................] - ETA: 31s - loss: 3.8431 - accuracy: 0.2936\n",
      "Epoch 00043: loss did not improve from 3.76863\n",
      " 23/128 [====>.........................] - ETA: 28s - loss: 3.8733 - accuracy: 0.2877\n",
      "Epoch 00043: loss did not improve from 3.76863\n",
      " 33/128 [======>.......................] - ETA: 25s - loss: 3.9024 - accuracy: 0.2827\n",
      "Epoch 00043: loss did not improve from 3.76863\n",
      " 43/128 [=========>....................] - ETA: 22s - loss: 3.9195 - accuracy: 0.2800\n",
      "Epoch 00043: loss did not improve from 3.76863\n",
      " 53/128 [===========>..................] - ETA: 19s - loss: 3.9292 - accuracy: 0.2794\n",
      "Epoch 00043: loss did not improve from 3.76863\n",
      " 63/128 [=============>................] - ETA: 16s - loss: 3.9319 - accuracy: 0.2799\n",
      "Epoch 00043: loss did not improve from 3.76863\n",
      " 73/128 [================>.............] - ETA: 14s - loss: 3.9501 - accuracy: 0.2792\n",
      "Epoch 00043: loss did not improve from 3.76863\n",
      " 83/128 [==================>...........] - ETA: 11s - loss: 3.9469 - accuracy: 0.2800\n",
      "Epoch 00043: loss did not improve from 3.76863\n",
      " 93/128 [====================>.........] - ETA: 9s - loss: 3.9630 - accuracy: 0.2778\n",
      "Epoch 00043: loss did not improve from 3.76863\n",
      "103/128 [=======================>......] - ETA: 6s - loss: 3.9786 - accuracy: 0.2774\n",
      "Epoch 00043: loss did not improve from 3.76863\n",
      "113/128 [=========================>....] - ETA: 3s - loss: 3.9852 - accuracy: 0.2773\n",
      "Epoch 00043: loss did not improve from 3.76863\n",
      "123/128 [===========================>..] - ETA: 1s - loss: 3.9990 - accuracy: 0.2766\n",
      "Epoch 00043: loss did not improve from 3.76863\n",
      "128/128 [==============================] - 34s 267ms/step - loss: 4.0032 - accuracy: 0.2764\n",
      "Epoch 44/100\n",
      "  5/128 [>.............................] - ETA: 37s - loss: 3.7683 - accuracy: 0.2937\n",
      "Epoch 00044: loss did not improve from 3.76863\n",
      " 15/128 [==>...........................] - ETA: 33s - loss: 3.9617 - accuracy: 0.2721\n",
      "Epoch 00044: loss did not improve from 3.76863\n",
      " 25/128 [====>.........................] - ETA: 28s - loss: 3.9308 - accuracy: 0.2753\n",
      "Epoch 00044: loss did not improve from 3.76863\n",
      " 35/128 [=======>......................] - ETA: 25s - loss: 3.9187 - accuracy: 0.2761\n",
      "Epoch 00044: loss did not improve from 3.76863\n",
      " 45/128 [=========>....................] - ETA: 22s - loss: 3.9253 - accuracy: 0.2792\n",
      "Epoch 00044: loss did not improve from 3.76863\n",
      " 55/128 [===========>..................] - ETA: 20s - loss: 3.9345 - accuracy: 0.2777\n",
      "Epoch 00044: loss did not improve from 3.76863\n",
      " 65/128 [==============>...............] - ETA: 17s - loss: 3.9362 - accuracy: 0.2801\n",
      "Epoch 00044: loss did not improve from 3.76863\n",
      " 75/128 [================>.............] - ETA: 14s - loss: 3.9402 - accuracy: 0.2790\n",
      "Epoch 00044: loss did not improve from 3.76863\n",
      " 85/128 [==================>...........] - ETA: 11s - loss: 3.9451 - accuracy: 0.2801\n",
      "Epoch 00044: loss did not improve from 3.76863\n",
      " 95/128 [=====================>........] - ETA: 8s - loss: 3.9564 - accuracy: 0.2798\n",
      "Epoch 00044: loss did not improve from 3.76863\n",
      "105/128 [=======================>......] - ETA: 6s - loss: 3.9681 - accuracy: 0.2786\n",
      "Epoch 00044: loss did not improve from 3.76863\n",
      "115/128 [=========================>....] - ETA: 3s - loss: 3.9726 - accuracy: 0.2790\n",
      "Epoch 00044: loss did not improve from 3.76863\n",
      "125/128 [============================>.] - ETA: 0s - loss: 3.9779 - accuracy: 0.2785\n",
      "Epoch 00044: loss did not improve from 3.76863\n",
      "128/128 [==============================] - 35s 274ms/step - loss: 3.9823 - accuracy: 0.2781\n",
      "Epoch 45/100\n",
      "  7/128 [>.............................] - ETA: 30s - loss: 3.7809 - accuracy: 0.3036\n",
      "Epoch 00045: loss did not improve from 3.76863\n",
      " 17/128 [==>...........................] - ETA: 29s - loss: 3.7850 - accuracy: 0.3015\n",
      "Epoch 00045: loss did not improve from 3.76863\n",
      " 27/128 [=====>........................] - ETA: 25s - loss: 3.8467 - accuracy: 0.2908\n",
      "Epoch 00045: loss did not improve from 3.76863\n",
      " 37/128 [=======>......................] - ETA: 23s - loss: 3.8359 - accuracy: 0.2882\n",
      "Epoch 00045: loss did not improve from 3.76863\n",
      " 47/128 [==========>...................] - ETA: 20s - loss: 3.8467 - accuracy: 0.2877\n",
      "Epoch 00045: loss did not improve from 3.76863\n",
      " 57/128 [============>.................] - ETA: 18s - loss: 3.8489 - accuracy: 0.2875\n",
      "Epoch 00045: loss did not improve from 3.76863\n",
      " 67/128 [==============>...............] - ETA: 16s - loss: 3.8770 - accuracy: 0.2845\n",
      "Epoch 00045: loss did not improve from 3.76863\n",
      " 77/128 [=================>............] - ETA: 13s - loss: 3.9022 - accuracy: 0.2828\n",
      "Epoch 00045: loss did not improve from 3.76863\n",
      " 87/128 [===================>..........] - ETA: 10s - loss: 3.9122 - accuracy: 0.2818\n",
      "Epoch 00045: loss did not improve from 3.76863\n",
      " 97/128 [=====================>........] - ETA: 8s - loss: 3.9151 - accuracy: 0.2829\n",
      "Epoch 00045: loss did not improve from 3.76863\n",
      "107/128 [========================>.....] - ETA: 5s - loss: 3.9221 - accuracy: 0.2829\n",
      "Epoch 00045: loss did not improve from 3.76863\n",
      "117/128 [==========================>...] - ETA: 2s - loss: 3.9234 - accuracy: 0.2837\n",
      "Epoch 00045: loss did not improve from 3.76863\n",
      "127/128 [============================>.] - ETA: 0s - loss: 3.9331 - accuracy: 0.2829\n",
      "Epoch 00045: loss did not improve from 3.76863\n",
      "128/128 [==============================] - 34s 264ms/step - loss: 3.9355 - accuracy: 0.2828\n",
      "Epoch 46/100\n",
      "  9/128 [=>............................] - ETA: 30s - loss: 3.8518 - accuracy: 0.2839\n",
      "Epoch 00046: loss did not improve from 3.76863\n",
      " 19/128 [===>..........................] - ETA: 28s - loss: 3.8756 - accuracy: 0.2858\n",
      "Epoch 00046: loss did not improve from 3.76863\n",
      " 29/128 [=====>........................] - ETA: 25s - loss: 3.8610 - accuracy: 0.2897\n",
      "Epoch 00046: loss did not improve from 3.76863\n",
      " 39/128 [========>.....................] - ETA: 22s - loss: 3.8498 - accuracy: 0.2916\n",
      "Epoch 00046: loss did not improve from 3.76863\n",
      " 49/128 [==========>...................] - ETA: 20s - loss: 3.8467 - accuracy: 0.2911\n",
      "Epoch 00046: loss did not improve from 3.76863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 59/128 [============>.................] - ETA: 17s - loss: 3.8425 - accuracy: 0.2898\n",
      "Epoch 00046: loss did not improve from 3.76863\n",
      " 69/128 [===============>..............] - ETA: 15s - loss: 3.8524 - accuracy: 0.2893\n",
      "Epoch 00046: loss did not improve from 3.76863\n",
      " 79/128 [=================>............] - ETA: 12s - loss: 3.8628 - accuracy: 0.2899\n",
      "Epoch 00046: loss did not improve from 3.76863\n",
      " 89/128 [===================>..........] - ETA: 10s - loss: 3.8707 - accuracy: 0.2884\n",
      "Epoch 00046: loss did not improve from 3.76863\n",
      " 99/128 [======================>.......] - ETA: 7s - loss: 3.8842 - accuracy: 0.2872\n",
      "Epoch 00046: loss did not improve from 3.76863\n",
      "109/128 [========================>.....] - ETA: 4s - loss: 3.8859 - accuracy: 0.2874\n",
      "Epoch 00046: loss did not improve from 3.76863\n",
      "119/128 [==========================>...] - ETA: 2s - loss: 3.8953 - accuracy: 0.2865\n",
      "Epoch 00046: loss did not improve from 3.76863\n",
      "128/128 [==============================] - 34s 264ms/step - loss: 3.9028 - accuracy: 0.2856\n",
      "Epoch 47/100\n",
      "  1/128 [..............................] - ETA: 36s - loss: 3.7570 - accuracy: 0.3086\n",
      "Epoch 00047: loss did not improve from 3.76863\n",
      " 11/128 [=>............................] - ETA: 33s - loss: 3.7748 - accuracy: 0.2962\n",
      "Epoch 00047: loss improved from 3.76863 to 3.75981, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 21/128 [===>..........................] - ETA: 29s - loss: 3.7413 - accuracy: 0.2961\n",
      "Epoch 00047: loss improved from 3.75981 to 3.73147, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 31/128 [======>.......................] - ETA: 27s - loss: 3.7229 - accuracy: 0.2990\n",
      "Epoch 00047: loss improved from 3.73147 to 3.72653, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 41/128 [========>.....................] - ETA: 24s - loss: 3.7427 - accuracy: 0.2962\n",
      "Epoch 00047: loss did not improve from 3.72653\n",
      " 51/128 [==========>...................] - ETA: 21s - loss: 3.7531 - accuracy: 0.2956\n",
      "Epoch 00047: loss did not improve from 3.72653\n",
      " 61/128 [=============>................] - ETA: 18s - loss: 3.7603 - accuracy: 0.2946\n",
      "Epoch 00047: loss did not improve from 3.72653\n",
      " 71/128 [===============>..............] - ETA: 15s - loss: 3.7683 - accuracy: 0.2941\n",
      "Epoch 00047: loss did not improve from 3.72653\n",
      " 81/128 [=================>............] - ETA: 13s - loss: 3.7847 - accuracy: 0.2921\n",
      "Epoch 00047: loss did not improve from 3.72653\n",
      " 91/128 [====================>.........] - ETA: 10s - loss: 3.7889 - accuracy: 0.2919\n",
      "Epoch 00047: loss did not improve from 3.72653\n",
      "101/128 [======================>.......] - ETA: 7s - loss: 3.8070 - accuracy: 0.2898\n",
      "Epoch 00047: loss did not improve from 3.72653\n",
      "111/128 [=========================>....] - ETA: 4s - loss: 3.8243 - accuracy: 0.2886\n",
      "Epoch 00047: loss did not improve from 3.72653\n",
      "121/128 [===========================>..] - ETA: 1s - loss: 3.8299 - accuracy: 0.2888\n",
      "Epoch 00047: loss did not improve from 3.72653\n",
      "128/128 [==============================] - 35s 274ms/step - loss: 3.8400 - accuracy: 0.2878\n",
      "Epoch 48/100\n",
      "  3/128 [..............................] - ETA: 36s - loss: 3.6874 - accuracy: 0.2956\n",
      "Epoch 00048: loss improved from 3.72653 to 3.68221, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 13/128 [==>...........................] - ETA: 31s - loss: 3.6981 - accuracy: 0.3035\n",
      "Epoch 00048: loss did not improve from 3.68221\n",
      " 23/128 [====>.........................] - ETA: 28s - loss: 3.7140 - accuracy: 0.3003\n",
      "Epoch 00048: loss did not improve from 3.68221\n",
      " 33/128 [======>.......................] - ETA: 25s - loss: 3.7316 - accuracy: 0.2972\n",
      "Epoch 00048: loss did not improve from 3.68221\n",
      " 43/128 [=========>....................] - ETA: 22s - loss: 3.7326 - accuracy: 0.2963\n",
      "Epoch 00048: loss did not improve from 3.68221\n",
      " 53/128 [===========>..................] - ETA: 20s - loss: 3.7534 - accuracy: 0.2928\n",
      "Epoch 00048: loss did not improve from 3.68221\n",
      " 63/128 [=============>................] - ETA: 17s - loss: 3.7605 - accuracy: 0.2913\n",
      "Epoch 00048: loss did not improve from 3.68221\n",
      " 73/128 [================>.............] - ETA: 14s - loss: 3.7672 - accuracy: 0.2906\n",
      "Epoch 00048: loss did not improve from 3.68221\n",
      " 83/128 [==================>...........] - ETA: 12s - loss: 3.7769 - accuracy: 0.2904\n",
      "Epoch 00048: loss did not improve from 3.68221\n",
      " 93/128 [====================>.........] - ETA: 9s - loss: 3.7764 - accuracy: 0.2905\n",
      "Epoch 00048: loss did not improve from 3.68221\n",
      "103/128 [=======================>......] - ETA: 6s - loss: 3.7870 - accuracy: 0.2898\n",
      "Epoch 00048: loss did not improve from 3.68221\n",
      "113/128 [=========================>....] - ETA: 4s - loss: 3.7962 - accuracy: 0.2897\n",
      "Epoch 00048: loss did not improve from 3.68221\n",
      "123/128 [===========================>..] - ETA: 1s - loss: 3.7990 - accuracy: 0.2907\n",
      "Epoch 00048: loss did not improve from 3.68221\n",
      "128/128 [==============================] - 34s 269ms/step - loss: 3.8097 - accuracy: 0.2899\n",
      "Epoch 49/100\n",
      "  5/128 [>.............................] - ETA: 34s - loss: 3.7774 - accuracy: 0.2953\n",
      "Epoch 00049: loss did not improve from 3.68221\n",
      " 15/128 [==>...........................] - ETA: 31s - loss: 3.7222 - accuracy: 0.3000\n",
      "Epoch 00049: loss did not improve from 3.68221\n",
      " 25/128 [====>.........................] - ETA: 27s - loss: 3.7020 - accuracy: 0.2991\n",
      "Epoch 00049: loss did not improve from 3.68221\n",
      " 35/128 [=======>......................] - ETA: 25s - loss: 3.6918 - accuracy: 0.2990\n",
      "Epoch 00049: loss did not improve from 3.68221\n",
      " 45/128 [=========>....................] - ETA: 22s - loss: 3.7106 - accuracy: 0.2976\n",
      "Epoch 00049: loss did not improve from 3.68221\n",
      " 55/128 [===========>..................] - ETA: 19s - loss: 3.7087 - accuracy: 0.2980\n",
      "Epoch 00049: loss did not improve from 3.68221\n",
      " 65/128 [==============>...............] - ETA: 16s - loss: 3.7168 - accuracy: 0.2982\n",
      "Epoch 00049: loss did not improve from 3.68221\n",
      " 75/128 [================>.............] - ETA: 14s - loss: 3.7267 - accuracy: 0.2971\n",
      "Epoch 00049: loss did not improve from 3.68221\n",
      " 85/128 [==================>...........] - ETA: 11s - loss: 3.7241 - accuracy: 0.2972\n",
      "Epoch 00049: loss did not improve from 3.68221\n",
      " 95/128 [=====================>........] - ETA: 8s - loss: 3.7352 - accuracy: 0.2954\n",
      "Epoch 00049: loss did not improve from 3.68221\n",
      "105/128 [=======================>......] - ETA: 6s - loss: 3.7384 - accuracy: 0.2962\n",
      "Epoch 00049: loss did not improve from 3.68221\n",
      "115/128 [=========================>....] - ETA: 3s - loss: 3.7510 - accuracy: 0.2953\n",
      "Epoch 00049: loss did not improve from 3.68221\n",
      "125/128 [============================>.] - ETA: 0s - loss: 3.7614 - accuracy: 0.2941\n",
      "Epoch 00049: loss did not improve from 3.68221\n",
      "128/128 [==============================] - 35s 271ms/step - loss: 3.7637 - accuracy: 0.2937\n",
      "Epoch 50/100\n",
      "  7/128 [>.............................] - ETA: 34s - loss: 3.5397 - accuracy: 0.3270\n",
      "Epoch 00050: loss improved from 3.68221 to 3.57864, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 17/128 [==>...........................] - ETA: 31s - loss: 3.5854 - accuracy: 0.3166\n",
      "Epoch 00050: loss did not improve from 3.57864\n",
      " 27/128 [=====>........................] - ETA: 28s - loss: 3.6203 - accuracy: 0.3105\n",
      "Epoch 00050: loss did not improve from 3.57864\n",
      " 37/128 [=======>......................] - ETA: 24s - loss: 3.6290 - accuracy: 0.3070\n",
      "Epoch 00050: loss did not improve from 3.57864\n",
      " 47/128 [==========>...................] - ETA: 22s - loss: 3.6577 - accuracy: 0.3029\n",
      "Epoch 00050: loss did not improve from 3.57864\n",
      " 57/128 [============>.................] - ETA: 19s - loss: 3.6655 - accuracy: 0.3008\n",
      "Epoch 00050: loss did not improve from 3.57864\n",
      " 67/128 [==============>...............] - ETA: 16s - loss: 3.6689 - accuracy: 0.3012\n",
      "Epoch 00050: loss did not improve from 3.57864\n",
      " 77/128 [=================>............] - ETA: 13s - loss: 3.6758 - accuracy: 0.3003\n",
      "Epoch 00050: loss did not improve from 3.57864\n",
      " 87/128 [===================>..........] - ETA: 11s - loss: 3.6963 - accuracy: 0.2988\n",
      "Epoch 00050: loss did not improve from 3.57864\n",
      " 97/128 [=====================>........] - ETA: 8s - loss: 3.7030 - accuracy: 0.2974\n",
      "Epoch 00050: loss did not improve from 3.57864\n",
      "107/128 [========================>.....] - ETA: 5s - loss: 3.7050 - accuracy: 0.2973\n",
      "Epoch 00050: loss did not improve from 3.57864\n",
      "117/128 [==========================>...] - ETA: 2s - loss: 3.7090 - accuracy: 0.2976\n",
      "Epoch 00050: loss did not improve from 3.57864\n",
      "127/128 [============================>.] - ETA: 0s - loss: 3.7215 - accuracy: 0.2967\n",
      "Epoch 00050: loss did not improve from 3.57864\n",
      "128/128 [==============================] - 35s 270ms/step - loss: 3.7230 - accuracy: 0.2966\n",
      "Epoch 51/100\n",
      "  9/128 [=>............................] - ETA: 32s - loss: 3.6398 - accuracy: 0.3008\n",
      "Epoch 00051: loss did not improve from 3.57864\n",
      " 19/128 [===>..........................] - ETA: 28s - loss: 3.6638 - accuracy: 0.2950\n",
      "Epoch 00051: loss did not improve from 3.57864\n",
      " 29/128 [=====>........................] - ETA: 26s - loss: 3.6635 - accuracy: 0.2966\n",
      "Epoch 00051: loss did not improve from 3.57864\n",
      " 39/128 [========>.....................] - ETA: 23s - loss: 3.6318 - accuracy: 0.3025\n",
      "Epoch 00051: loss did not improve from 3.57864\n",
      " 49/128 [==========>...................] - ETA: 21s - loss: 3.6288 - accuracy: 0.3036\n",
      "Epoch 00051: loss did not improve from 3.57864\n",
      " 59/128 [============>.................] - ETA: 18s - loss: 3.6276 - accuracy: 0.3042\n",
      "Epoch 00051: loss did not improve from 3.57864\n",
      " 69/128 [===============>..............] - ETA: 15s - loss: 3.6391 - accuracy: 0.3030\n",
      "Epoch 00051: loss did not improve from 3.57864\n",
      " 79/128 [=================>............] - ETA: 13s - loss: 3.6383 - accuracy: 0.3049\n",
      "Epoch 00051: loss did not improve from 3.57864\n",
      " 89/128 [===================>..........] - ETA: 10s - loss: 3.6522 - accuracy: 0.3046\n",
      "Epoch 00051: loss did not improve from 3.57864\n",
      " 99/128 [======================>.......] - ETA: 7s - loss: 3.6525 - accuracy: 0.3061\n",
      "Epoch 00051: loss did not improve from 3.57864\n",
      "109/128 [========================>.....] - ETA: 5s - loss: 3.6668 - accuracy: 0.3041\n",
      "Epoch 00051: loss did not improve from 3.57864\n",
      "119/128 [==========================>...] - ETA: 2s - loss: 3.6750 - accuracy: 0.3022\n",
      "Epoch 00051: loss did not improve from 3.57864\n",
      "128/128 [==============================] - 34s 269ms/step - loss: 3.6885 - accuracy: 0.3020\n",
      "Epoch 52/100\n",
      "  1/128 [..............................] - ETA: 32s - loss: 3.6588 - accuracy: 0.2891\n",
      "Epoch 00052: loss did not improve from 3.57864\n",
      " 11/128 [=>............................] - ETA: 31s - loss: 3.6143 - accuracy: 0.2972\n",
      "Epoch 00052: loss did not improve from 3.57864\n",
      " 21/128 [===>..........................] - ETA: 28s - loss: 3.6031 - accuracy: 0.3064\n",
      "Epoch 00052: loss did not improve from 3.57864\n",
      " 31/128 [======>.......................] - ETA: 26s - loss: 3.5668 - accuracy: 0.3111\n",
      "Epoch 00052: loss improved from 3.57864 to 3.56352, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 41/128 [========>.....................] - ETA: 23s - loss: 3.5573 - accuracy: 0.3108\n",
      "Epoch 00052: loss improved from 3.56352 to 3.56047, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 51/128 [==========>...................] - ETA: 20s - loss: 3.5626 - accuracy: 0.3128\n",
      "Epoch 00052: loss did not improve from 3.56047\n",
      " 61/128 [=============>................] - ETA: 17s - loss: 3.5891 - accuracy: 0.3087\n",
      "Epoch 00052: loss did not improve from 3.56047\n",
      " 71/128 [===============>..............] - ETA: 15s - loss: 3.5785 - accuracy: 0.3109\n",
      "Epoch 00052: loss did not improve from 3.56047\n",
      " 81/128 [=================>............] - ETA: 12s - loss: 3.5865 - accuracy: 0.3110\n",
      "Epoch 00052: loss did not improve from 3.56047\n",
      " 91/128 [====================>.........] - ETA: 10s - loss: 3.5987 - accuracy: 0.3100\n",
      "Epoch 00052: loss did not improve from 3.56047\n",
      "101/128 [======================>.......] - ETA: 7s - loss: 3.6206 - accuracy: 0.3072\n",
      "Epoch 00052: loss did not improve from 3.56047\n",
      "111/128 [=========================>....] - ETA: 4s - loss: 3.6311 - accuracy: 0.3068\n",
      "Epoch 00052: loss did not improve from 3.56047\n",
      "121/128 [===========================>..] - ETA: 1s - loss: 3.6376 - accuracy: 0.3060\n",
      "Epoch 00052: loss did not improve from 3.56047\n",
      "128/128 [==============================] - 35s 272ms/step - loss: 3.6449 - accuracy: 0.3056\n",
      "Epoch 53/100\n",
      "  3/128 [..............................] - ETA: 34s - loss: 3.4388 - accuracy: 0.3294\n",
      "Epoch 00053: loss improved from 3.56047 to 3.45917, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 13/128 [==>...........................] - ETA: 31s - loss: 3.5263 - accuracy: 0.3194\n",
      "Epoch 00053: loss did not improve from 3.45917\n",
      " 23/128 [====>.........................] - ETA: 28s - loss: 3.5120 - accuracy: 0.3201\n",
      "Epoch 00053: loss did not improve from 3.45917\n",
      " 33/128 [======>.......................] - ETA: 25s - loss: 3.5223 - accuracy: 0.3164\n",
      "Epoch 00053: loss did not improve from 3.45917\n",
      " 43/128 [=========>....................] - ETA: 22s - loss: 3.5400 - accuracy: 0.3133\n",
      "Epoch 00053: loss did not improve from 3.45917\n",
      " 53/128 [===========>..................] - ETA: 19s - loss: 3.5341 - accuracy: 0.3154\n",
      "Epoch 00053: loss did not improve from 3.45917\n",
      " 63/128 [=============>................] - ETA: 17s - loss: 3.5437 - accuracy: 0.3137\n",
      "Epoch 00053: loss did not improve from 3.45917\n",
      " 73/128 [================>.............] - ETA: 14s - loss: 3.5582 - accuracy: 0.3108\n",
      "Epoch 00053: loss did not improve from 3.45917\n",
      " 83/128 [==================>...........] - ETA: 12s - loss: 3.5592 - accuracy: 0.3112\n",
      "Epoch 00053: loss did not improve from 3.45917\n",
      " 93/128 [====================>.........] - ETA: 9s - loss: 3.5763 - accuracy: 0.3098\n",
      "Epoch 00053: loss did not improve from 3.45917\n",
      "103/128 [=======================>......] - ETA: 6s - loss: 3.5980 - accuracy: 0.3070\n",
      "Epoch 00053: loss did not improve from 3.45917\n",
      "113/128 [=========================>....] - ETA: 4s - loss: 3.6039 - accuracy: 0.3074\n",
      "Epoch 00053: loss did not improve from 3.45917\n",
      "123/128 [===========================>..] - ETA: 1s - loss: 3.6028 - accuracy: 0.3087\n",
      "Epoch 00053: loss did not improve from 3.45917\n",
      "128/128 [==============================] - 34s 268ms/step - loss: 3.6107 - accuracy: 0.3082\n",
      "Epoch 54/100\n",
      "  5/128 [>.............................] - ETA: 33s - loss: 3.4862 - accuracy: 0.3289\n",
      "Epoch 00054: loss did not improve from 3.45917\n",
      " 15/128 [==>...........................] - ETA: 30s - loss: 3.4516 - accuracy: 0.3289\n",
      "Epoch 00054: loss improved from 3.45917 to 3.45028, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 25/128 [====>.........................] - ETA: 28s - loss: 3.4374 - accuracy: 0.3267\n",
      "Epoch 00054: loss improved from 3.45028 to 3.43241, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 35/128 [=======>......................] - ETA: 25s - loss: 3.4654 - accuracy: 0.3241\n",
      "Epoch 00054: loss did not improve from 3.43241\n",
      " 45/128 [=========>....................] - ETA: 22s - loss: 3.4916 - accuracy: 0.3203\n",
      "Epoch 00054: loss did not improve from 3.43241\n",
      " 55/128 [===========>..................] - ETA: 19s - loss: 3.5034 - accuracy: 0.3190\n",
      "Epoch 00054: loss did not improve from 3.43241\n",
      " 65/128 [==============>...............] - ETA: 17s - loss: 3.5080 - accuracy: 0.3157\n",
      "Epoch 00054: loss did not improve from 3.43241\n",
      " 75/128 [================>.............] - ETA: 14s - loss: 3.5220 - accuracy: 0.3156\n",
      "Epoch 00054: loss did not improve from 3.43241\n",
      " 85/128 [==================>...........] - ETA: 11s - loss: 3.5343 - accuracy: 0.3153\n",
      "Epoch 00054: loss did not improve from 3.43241\n",
      " 95/128 [=====================>........] - ETA: 8s - loss: 3.5400 - accuracy: 0.3155\n",
      "Epoch 00054: loss did not improve from 3.43241\n",
      "105/128 [=======================>......] - ETA: 6s - loss: 3.5632 - accuracy: 0.3134\n",
      "Epoch 00054: loss did not improve from 3.43241\n",
      "115/128 [=========================>....] - ETA: 3s - loss: 3.5776 - accuracy: 0.3122\n",
      "Epoch 00054: loss did not improve from 3.43241\n",
      "125/128 [============================>.] - ETA: 0s - loss: 3.5819 - accuracy: 0.3117\n",
      "Epoch 00054: loss did not improve from 3.43241\n",
      "128/128 [==============================] - 35s 270ms/step - loss: 3.5861 - accuracy: 0.3111\n",
      "Epoch 55/100\n",
      "  7/128 [>.............................] - ETA: 33s - loss: 3.3669 - accuracy: 0.3331\n",
      "Epoch 00055: loss improved from 3.43241 to 3.40192, saving model to ./export/2023-10-02T110043/model.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 17/128 [==>...........................] - ETA: 30s - loss: 3.4149 - accuracy: 0.3323\n",
      "Epoch 00055: loss improved from 3.40192 to 3.40190, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 27/128 [=====>........................] - ETA: 28s - loss: 3.4360 - accuracy: 0.3323\n",
      "Epoch 00055: loss did not improve from 3.40190\n",
      " 37/128 [=======>......................] - ETA: 24s - loss: 3.4415 - accuracy: 0.3299\n",
      "Epoch 00055: loss did not improve from 3.40190\n",
      " 47/128 [==========>...................] - ETA: 22s - loss: 3.4459 - accuracy: 0.3275\n",
      "Epoch 00055: loss did not improve from 3.40190\n",
      " 57/128 [============>.................] - ETA: 19s - loss: 3.4683 - accuracy: 0.3252\n",
      "Epoch 00055: loss did not improve from 3.40190\n",
      " 67/128 [==============>...............] - ETA: 16s - loss: 3.4592 - accuracy: 0.3266\n",
      "Epoch 00055: loss did not improve from 3.40190\n",
      " 77/128 [=================>............] - ETA: 14s - loss: 3.4841 - accuracy: 0.3224\n",
      "Epoch 00055: loss did not improve from 3.40190\n",
      " 87/128 [===================>..........] - ETA: 11s - loss: 3.4843 - accuracy: 0.3235\n",
      "Epoch 00055: loss did not improve from 3.40190\n",
      " 97/128 [=====================>........] - ETA: 8s - loss: 3.4931 - accuracy: 0.3223\n",
      "Epoch 00055: loss did not improve from 3.40190\n",
      "107/128 [========================>.....] - ETA: 5s - loss: 3.5032 - accuracy: 0.3213\n",
      "Epoch 00055: loss did not improve from 3.40190\n",
      "117/128 [==========================>...] - ETA: 3s - loss: 3.5132 - accuracy: 0.3214\n",
      "Epoch 00055: loss did not improve from 3.40190\n",
      "127/128 [============================>.] - ETA: 0s - loss: 3.5268 - accuracy: 0.3194\n",
      "Epoch 00055: loss did not improve from 3.40190\n",
      "128/128 [==============================] - 35s 273ms/step - loss: 3.5267 - accuracy: 0.3192\n",
      "Epoch 56/100\n",
      "  9/128 [=>............................] - ETA: 31s - loss: 3.3625 - accuracy: 0.3312\n",
      "Epoch 00056: loss improved from 3.40190 to 3.35671, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 19/128 [===>..........................] - ETA: 29s - loss: 3.3545 - accuracy: 0.3312\n",
      "Epoch 00056: loss did not improve from 3.35671\n",
      " 29/128 [=====>........................] - ETA: 26s - loss: 3.3753 - accuracy: 0.3335\n",
      "Epoch 00056: loss did not improve from 3.35671\n",
      " 39/128 [========>.....................] - ETA: 23s - loss: 3.3922 - accuracy: 0.3289\n",
      "Epoch 00056: loss did not improve from 3.35671\n",
      " 49/128 [==========>...................] - ETA: 21s - loss: 3.3976 - accuracy: 0.3274\n",
      "Epoch 00056: loss did not improve from 3.35671\n",
      " 59/128 [============>.................] - ETA: 18s - loss: 3.4131 - accuracy: 0.3267\n",
      "Epoch 00056: loss did not improve from 3.35671\n",
      " 69/128 [===============>..............] - ETA: 16s - loss: 3.4199 - accuracy: 0.3267\n",
      "Epoch 00056: loss did not improve from 3.35671\n",
      " 79/128 [=================>............] - ETA: 13s - loss: 3.4243 - accuracy: 0.3259\n",
      "Epoch 00056: loss did not improve from 3.35671\n",
      " 89/128 [===================>..........] - ETA: 10s - loss: 3.4377 - accuracy: 0.3245\n",
      "Epoch 00056: loss did not improve from 3.35671\n",
      " 99/128 [======================>.......] - ETA: 7s - loss: 3.4485 - accuracy: 0.3228\n",
      "Epoch 00056: loss did not improve from 3.35671\n",
      "109/128 [========================>.....] - ETA: 5s - loss: 3.4608 - accuracy: 0.3218\n",
      "Epoch 00056: loss did not improve from 3.35671\n",
      "119/128 [==========================>...] - ETA: 2s - loss: 3.4668 - accuracy: 0.3210\n",
      "Epoch 00056: loss did not improve from 3.35671\n",
      "128/128 [==============================] - 34s 268ms/step - loss: 3.4772 - accuracy: 0.3200\n",
      "Epoch 57/100\n",
      "  1/128 [..............................] - ETA: 32s - loss: 3.3678 - accuracy: 0.3359\n",
      "Epoch 00057: loss improved from 3.35671 to 3.34191, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 11/128 [=>............................] - ETA: 33s - loss: 3.2950 - accuracy: 0.3327\n",
      "Epoch 00057: loss improved from 3.34191 to 3.30821, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 21/128 [===>..........................] - ETA: 29s - loss: 3.3358 - accuracy: 0.3305\n",
      "Epoch 00057: loss did not improve from 3.30821\n",
      " 31/128 [======>.......................] - ETA: 26s - loss: 3.3427 - accuracy: 0.3343\n",
      "Epoch 00057: loss did not improve from 3.30821\n",
      " 41/128 [========>.....................] - ETA: 23s - loss: 3.3615 - accuracy: 0.3310\n",
      "Epoch 00057: loss did not improve from 3.30821\n",
      " 51/128 [==========>...................] - ETA: 20s - loss: 3.3634 - accuracy: 0.3303\n",
      "Epoch 00057: loss did not improve from 3.30821\n",
      " 61/128 [=============>................] - ETA: 18s - loss: 3.3744 - accuracy: 0.3285\n",
      "Epoch 00057: loss did not improve from 3.30821\n",
      " 71/128 [===============>..............] - ETA: 15s - loss: 3.3800 - accuracy: 0.3282\n",
      "Epoch 00057: loss did not improve from 3.30821\n",
      " 81/128 [=================>............] - ETA: 12s - loss: 3.3755 - accuracy: 0.3292\n",
      "Epoch 00057: loss did not improve from 3.30821\n",
      " 91/128 [====================>.........] - ETA: 10s - loss: 3.3874 - accuracy: 0.3286\n",
      "Epoch 00057: loss did not improve from 3.30821\n",
      "101/128 [======================>.......] - ETA: 7s - loss: 3.3979 - accuracy: 0.3282\n",
      "Epoch 00057: loss did not improve from 3.30821\n",
      "111/128 [=========================>....] - ETA: 4s - loss: 3.4014 - accuracy: 0.3278\n",
      "Epoch 00057: loss did not improve from 3.30821\n",
      "121/128 [===========================>..] - ETA: 1s - loss: 3.4121 - accuracy: 0.3262\n",
      "Epoch 00057: loss did not improve from 3.30821\n",
      "128/128 [==============================] - 35s 270ms/step - loss: 3.4200 - accuracy: 0.3254\n",
      "Epoch 58/100\n",
      "  3/128 [..............................] - ETA: 30s - loss: 3.4176 - accuracy: 0.3099\n",
      "Epoch 00058: loss did not improve from 3.30821\n",
      " 13/128 [==>...........................] - ETA: 31s - loss: 3.2923 - accuracy: 0.3302\n",
      "Epoch 00058: loss improved from 3.30821 to 3.27790, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 23/128 [====>.........................] - ETA: 27s - loss: 3.2528 - accuracy: 0.3419\n",
      "Epoch 00058: loss improved from 3.27790 to 3.24149, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 33/128 [======>.......................] - ETA: 26s - loss: 3.2493 - accuracy: 0.3430\n",
      "Epoch 00058: loss did not improve from 3.24149\n",
      " 43/128 [=========>....................] - ETA: 23s - loss: 3.2798 - accuracy: 0.3386\n",
      "Epoch 00058: loss did not improve from 3.24149\n",
      " 53/128 [===========>..................] - ETA: 20s - loss: 3.2898 - accuracy: 0.3367\n",
      "Epoch 00058: loss did not improve from 3.24149\n",
      " 63/128 [=============>................] - ETA: 18s - loss: 3.2947 - accuracy: 0.3364\n",
      "Epoch 00058: loss did not improve from 3.24149\n",
      " 73/128 [================>.............] - ETA: 15s - loss: 3.3094 - accuracy: 0.3339\n",
      "Epoch 00058: loss did not improve from 3.24149\n",
      " 83/128 [==================>...........] - ETA: 12s - loss: 3.3218 - accuracy: 0.3323\n",
      "Epoch 00058: loss did not improve from 3.24149\n",
      " 93/128 [====================>.........] - ETA: 9s - loss: 3.3362 - accuracy: 0.3307\n",
      "Epoch 00058: loss did not improve from 3.24149\n",
      "103/128 [=======================>......] - ETA: 6s - loss: 3.3513 - accuracy: 0.3290\n",
      "Epoch 00058: loss did not improve from 3.24149\n",
      "113/128 [=========================>....] - ETA: 4s - loss: 3.3596 - accuracy: 0.3291\n",
      "Epoch 00058: loss did not improve from 3.24149\n",
      "123/128 [===========================>..] - ETA: 1s - loss: 3.3605 - accuracy: 0.3294\n",
      "Epoch 00058: loss did not improve from 3.24149\n",
      "128/128 [==============================] - 35s 273ms/step - loss: 3.3671 - accuracy: 0.3294\n",
      "Epoch 59/100\n",
      "  5/128 [>.............................] - ETA: 34s - loss: 3.2478 - accuracy: 0.3398\n",
      "Epoch 00059: loss did not improve from 3.24149\n",
      " 15/128 [==>...........................] - ETA: 30s - loss: 3.3411 - accuracy: 0.3234\n",
      "Epoch 00059: loss did not improve from 3.24149\n",
      " 25/128 [====>.........................] - ETA: 27s - loss: 3.2927 - accuracy: 0.3334\n",
      "Epoch 00059: loss did not improve from 3.24149\n",
      " 35/128 [=======>......................] - ETA: 24s - loss: 3.2962 - accuracy: 0.3323\n",
      "Epoch 00059: loss did not improve from 3.24149\n",
      " 45/128 [=========>....................] - ETA: 22s - loss: 3.2907 - accuracy: 0.3330\n",
      "Epoch 00059: loss did not improve from 3.24149\n",
      " 55/128 [===========>..................] - ETA: 19s - loss: 3.2943 - accuracy: 0.3344\n",
      "Epoch 00059: loss did not improve from 3.24149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 65/128 [==============>...............] - ETA: 17s - loss: 3.3010 - accuracy: 0.3344\n",
      "Epoch 00059: loss did not improve from 3.24149\n",
      " 75/128 [================>.............] - ETA: 14s - loss: 3.3084 - accuracy: 0.3339\n",
      "Epoch 00059: loss did not improve from 3.24149\n",
      " 85/128 [==================>...........] - ETA: 11s - loss: 3.3110 - accuracy: 0.3342\n",
      "Epoch 00059: loss did not improve from 3.24149\n",
      " 95/128 [=====================>........] - ETA: 8s - loss: 3.3225 - accuracy: 0.3323\n",
      "Epoch 00059: loss did not improve from 3.24149\n",
      "105/128 [=======================>......] - ETA: 6s - loss: 3.3279 - accuracy: 0.3322\n",
      "Epoch 00059: loss did not improve from 3.24149\n",
      "115/128 [=========================>....] - ETA: 3s - loss: 3.3346 - accuracy: 0.3318\n",
      "Epoch 00059: loss did not improve from 3.24149\n",
      "125/128 [============================>.] - ETA: 0s - loss: 3.3469 - accuracy: 0.3316\n",
      "Epoch 00059: loss did not improve from 3.24149\n",
      "128/128 [==============================] - 34s 269ms/step - loss: 3.3502 - accuracy: 0.3310\n",
      "Epoch 60/100\n",
      "  7/128 [>.............................] - ETA: 33s - loss: 3.2084 - accuracy: 0.3432\n",
      "Epoch 00060: loss improved from 3.24149 to 3.22593, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 17/128 [==>...........................] - ETA: 30s - loss: 3.2409 - accuracy: 0.3421\n",
      "Epoch 00060: loss did not improve from 3.22593\n",
      " 27/128 [=====>........................] - ETA: 28s - loss: 3.2297 - accuracy: 0.3451\n",
      "Epoch 00060: loss did not improve from 3.22593\n",
      " 37/128 [=======>......................] - ETA: 25s - loss: 3.2236 - accuracy: 0.3439\n",
      "Epoch 00060: loss improved from 3.22593 to 3.22514, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 47/128 [==========>...................] - ETA: 22s - loss: 3.2399 - accuracy: 0.3411\n",
      "Epoch 00060: loss did not improve from 3.22514\n",
      " 57/128 [============>.................] - ETA: 19s - loss: 3.2396 - accuracy: 0.3425\n",
      "Epoch 00060: loss did not improve from 3.22514\n",
      " 67/128 [==============>...............] - ETA: 16s - loss: 3.2473 - accuracy: 0.3406\n",
      "Epoch 00060: loss did not improve from 3.22514\n",
      " 77/128 [=================>............] - ETA: 14s - loss: 3.2480 - accuracy: 0.3416\n",
      "Epoch 00060: loss did not improve from 3.22514\n",
      " 87/128 [===================>..........] - ETA: 11s - loss: 3.2654 - accuracy: 0.3402\n",
      "Epoch 00060: loss did not improve from 3.22514\n",
      " 97/128 [=====================>........] - ETA: 8s - loss: 3.2743 - accuracy: 0.3399\n",
      "Epoch 00060: loss did not improve from 3.22514\n",
      "107/128 [========================>.....] - ETA: 5s - loss: 3.2903 - accuracy: 0.3381\n",
      "Epoch 00060: loss did not improve from 3.22514\n",
      "117/128 [==========================>...] - ETA: 3s - loss: 3.2938 - accuracy: 0.3386\n",
      "Epoch 00060: loss did not improve from 3.22514\n",
      "127/128 [============================>.] - ETA: 0s - loss: 3.3094 - accuracy: 0.3371\n",
      "Epoch 00060: loss did not improve from 3.22514\n",
      "128/128 [==============================] - 35s 272ms/step - loss: 3.3102 - accuracy: 0.3371\n",
      "Epoch 61/100\n",
      "  9/128 [=>............................] - ETA: 33s - loss: 3.1478 - accuracy: 0.3641\n",
      "Epoch 00061: loss improved from 3.22514 to 3.15972, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 19/128 [===>..........................] - ETA: 29s - loss: 3.2135 - accuracy: 0.3475\n",
      "Epoch 00061: loss did not improve from 3.15972\n",
      " 29/128 [=====>........................] - ETA: 27s - loss: 3.2245 - accuracy: 0.3464\n",
      "Epoch 00061: loss did not improve from 3.15972\n",
      " 39/128 [========>.....................] - ETA: 24s - loss: 3.2370 - accuracy: 0.3465\n",
      "Epoch 00061: loss did not improve from 3.15972\n",
      " 49/128 [==========>...................] - ETA: 21s - loss: 3.2254 - accuracy: 0.3469\n",
      "Epoch 00061: loss did not improve from 3.15972\n",
      " 59/128 [============>.................] - ETA: 19s - loss: 3.2310 - accuracy: 0.3469\n",
      "Epoch 00061: loss did not improve from 3.15972\n",
      " 69/128 [===============>..............] - ETA: 16s - loss: 3.2336 - accuracy: 0.3458\n",
      "Epoch 00061: loss did not improve from 3.15972\n",
      " 79/128 [=================>............] - ETA: 13s - loss: 3.2393 - accuracy: 0.3457\n",
      "Epoch 00061: loss did not improve from 3.15972\n",
      " 89/128 [===================>..........] - ETA: 10s - loss: 3.2358 - accuracy: 0.3468\n",
      "Epoch 00061: loss did not improve from 3.15972\n",
      " 99/128 [======================>.......] - ETA: 7s - loss: 3.2487 - accuracy: 0.3448\n",
      "Epoch 00061: loss did not improve from 3.15972\n",
      "109/128 [========================>.....] - ETA: 5s - loss: 3.2551 - accuracy: 0.3436\n",
      "Epoch 00061: loss did not improve from 3.15972\n",
      "119/128 [==========================>...] - ETA: 2s - loss: 3.2578 - accuracy: 0.3428\n",
      "Epoch 00061: loss did not improve from 3.15972\n",
      "128/128 [==============================] - 35s 272ms/step - loss: 3.2653 - accuracy: 0.3422\n",
      "Epoch 62/100\n",
      "  1/128 [..............................] - ETA: 32s - loss: 3.1160 - accuracy: 0.3711\n",
      "Epoch 00062: loss improved from 3.15972 to 3.09397, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 11/128 [=>............................] - ETA: 32s - loss: 3.1967 - accuracy: 0.3537\n",
      "Epoch 00062: loss did not improve from 3.09397\n",
      " 21/128 [===>..........................] - ETA: 29s - loss: 3.1632 - accuracy: 0.3560\n",
      "Epoch 00062: loss did not improve from 3.09397\n",
      " 31/128 [======>.......................] - ETA: 26s - loss: 3.1418 - accuracy: 0.3592\n",
      "Epoch 00062: loss did not improve from 3.09397\n",
      " 41/128 [========>.....................] - ETA: 24s - loss: 3.1464 - accuracy: 0.3576\n",
      "Epoch 00062: loss did not improve from 3.09397\n",
      " 51/128 [==========>...................] - ETA: 20s - loss: 3.1649 - accuracy: 0.3563\n",
      "Epoch 00062: loss did not improve from 3.09397\n",
      " 61/128 [=============>................] - ETA: 18s - loss: 3.1778 - accuracy: 0.3544\n",
      "Epoch 00062: loss did not improve from 3.09397\n",
      " 71/128 [===============>..............] - ETA: 15s - loss: 3.1866 - accuracy: 0.3540\n",
      "Epoch 00062: loss did not improve from 3.09397\n",
      " 81/128 [=================>............] - ETA: 12s - loss: 3.1933 - accuracy: 0.3523\n",
      "Epoch 00062: loss did not improve from 3.09397\n",
      " 91/128 [====================>.........] - ETA: 9s - loss: 3.1996 - accuracy: 0.3514 \n",
      "Epoch 00062: loss did not improve from 3.09397\n",
      "101/128 [======================>.......] - ETA: 7s - loss: 3.2005 - accuracy: 0.3516\n",
      "Epoch 00062: loss did not improve from 3.09397\n",
      "111/128 [=========================>....] - ETA: 4s - loss: 3.2141 - accuracy: 0.3506\n",
      "Epoch 00062: loss did not improve from 3.09397\n",
      "121/128 [===========================>..] - ETA: 1s - loss: 3.2277 - accuracy: 0.3490\n",
      "Epoch 00062: loss did not improve from 3.09397\n",
      "128/128 [==============================] - 35s 270ms/step - loss: 3.2324 - accuracy: 0.3487\n",
      "Epoch 63/100\n",
      "  3/128 [..............................] - ETA: 35s - loss: 3.0763 - accuracy: 0.3763\n",
      "Epoch 00063: loss improved from 3.09397 to 3.06994, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 13/128 [==>...........................] - ETA: 31s - loss: 3.1553 - accuracy: 0.3507\n",
      "Epoch 00063: loss did not improve from 3.06994\n",
      " 23/128 [====>.........................] - ETA: 29s - loss: 3.1436 - accuracy: 0.3561\n",
      "Epoch 00063: loss did not improve from 3.06994\n",
      " 33/128 [======>.......................] - ETA: 26s - loss: 3.1405 - accuracy: 0.3581\n",
      "Epoch 00063: loss did not improve from 3.06994\n",
      " 43/128 [=========>....................] - ETA: 23s - loss: 3.1367 - accuracy: 0.3594\n",
      "Epoch 00063: loss did not improve from 3.06994\n",
      " 53/128 [===========>..................] - ETA: 20s - loss: 3.1389 - accuracy: 0.3592\n",
      "Epoch 00063: loss did not improve from 3.06994\n",
      " 63/128 [=============>................] - ETA: 17s - loss: 3.1475 - accuracy: 0.3576\n",
      "Epoch 00063: loss did not improve from 3.06994\n",
      " 73/128 [================>.............] - ETA: 14s - loss: 3.1561 - accuracy: 0.3561\n",
      "Epoch 00063: loss did not improve from 3.06994\n",
      " 83/128 [==================>...........] - ETA: 12s - loss: 3.1700 - accuracy: 0.3556\n",
      "Epoch 00063: loss did not improve from 3.06994\n",
      " 93/128 [====================>.........] - ETA: 9s - loss: 3.1790 - accuracy: 0.3548\n",
      "Epoch 00063: loss did not improve from 3.06994\n",
      "103/128 [=======================>......] - ETA: 6s - loss: 3.1849 - accuracy: 0.3542\n",
      "Epoch 00063: loss did not improve from 3.06994\n",
      "113/128 [=========================>....] - ETA: 4s - loss: 3.1975 - accuracy: 0.3525\n",
      "Epoch 00063: loss did not improve from 3.06994\n",
      "123/128 [===========================>..] - ETA: 1s - loss: 3.2052 - accuracy: 0.3512\n",
      "Epoch 00063: loss did not improve from 3.06994\n",
      "128/128 [==============================] - 35s 270ms/step - loss: 3.2071 - accuracy: 0.3513\n",
      "Epoch 64/100\n",
      "  5/128 [>.............................] - ETA: 35s - loss: 3.0265 - accuracy: 0.3695\n",
      "Epoch 00064: loss improved from 3.06994 to 3.06675, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 15/128 [==>...........................] - ETA: 34s - loss: 3.1575 - accuracy: 0.3500\n",
      "Epoch 00064: loss did not improve from 3.06675\n",
      " 25/128 [====>.........................] - ETA: 30s - loss: 3.0974 - accuracy: 0.3616\n",
      "Epoch 00064: loss did not improve from 3.06675\n",
      " 35/128 [=======>......................] - ETA: 26s - loss: 3.0941 - accuracy: 0.3628\n",
      "Epoch 00064: loss did not improve from 3.06675\n",
      " 45/128 [=========>....................] - ETA: 23s - loss: 3.0918 - accuracy: 0.3639\n",
      "Epoch 00064: loss did not improve from 3.06675\n",
      " 55/128 [===========>..................] - ETA: 20s - loss: 3.0998 - accuracy: 0.3621\n",
      "Epoch 00064: loss did not improve from 3.06675\n",
      " 65/128 [==============>...............] - ETA: 17s - loss: 3.0999 - accuracy: 0.3634\n",
      "Epoch 00064: loss did not improve from 3.06675\n",
      " 75/128 [================>.............] - ETA: 14s - loss: 3.1154 - accuracy: 0.3607\n",
      "Epoch 00064: loss did not improve from 3.06675\n",
      " 85/128 [==================>...........] - ETA: 11s - loss: 3.1188 - accuracy: 0.3605\n",
      "Epoch 00064: loss did not improve from 3.06675\n",
      " 95/128 [=====================>........] - ETA: 9s - loss: 3.1317 - accuracy: 0.3595\n",
      "Epoch 00064: loss did not improve from 3.06675\n",
      "105/128 [=======================>......] - ETA: 6s - loss: 3.1412 - accuracy: 0.3581\n",
      "Epoch 00064: loss did not improve from 3.06675\n",
      "115/128 [=========================>....] - ETA: 3s - loss: 3.1474 - accuracy: 0.3575\n",
      "Epoch 00064: loss did not improve from 3.06675\n",
      "125/128 [============================>.] - ETA: 0s - loss: 3.1706 - accuracy: 0.3550\n",
      "Epoch 00064: loss did not improve from 3.06675\n",
      "128/128 [==============================] - 35s 272ms/step - loss: 3.1753 - accuracy: 0.3546\n",
      "Epoch 65/100\n",
      "  7/128 [>.............................] - ETA: 34s - loss: 3.1093 - accuracy: 0.3583\n",
      "Epoch 00065: loss did not improve from 3.06675\n",
      " 17/128 [==>...........................] - ETA: 30s - loss: 3.0841 - accuracy: 0.3647\n",
      "Epoch 00065: loss did not improve from 3.06675\n",
      " 27/128 [=====>........................] - ETA: 27s - loss: 3.1106 - accuracy: 0.3639\n",
      "Epoch 00065: loss did not improve from 3.06675\n",
      " 37/128 [=======>......................] - ETA: 24s - loss: 3.1063 - accuracy: 0.3635\n",
      "Epoch 00065: loss did not improve from 3.06675\n",
      " 47/128 [==========>...................] - ETA: 21s - loss: 3.1047 - accuracy: 0.3642\n",
      "Epoch 00065: loss did not improve from 3.06675\n",
      " 57/128 [============>.................] - ETA: 19s - loss: 3.0956 - accuracy: 0.3653\n",
      "Epoch 00065: loss did not improve from 3.06675\n",
      " 67/128 [==============>...............] - ETA: 16s - loss: 3.1006 - accuracy: 0.3643\n",
      "Epoch 00065: loss did not improve from 3.06675\n",
      " 77/128 [=================>............] - ETA: 13s - loss: 3.1185 - accuracy: 0.3607\n",
      "Epoch 00065: loss did not improve from 3.06675\n",
      " 87/128 [===================>..........] - ETA: 10s - loss: 3.1190 - accuracy: 0.3617\n",
      "Epoch 00065: loss did not improve from 3.06675\n",
      " 97/128 [=====================>........] - ETA: 8s - loss: 3.1314 - accuracy: 0.3604\n",
      "Epoch 00065: loss did not improve from 3.06675\n",
      "107/128 [========================>.....] - ETA: 5s - loss: 3.1450 - accuracy: 0.3589\n",
      "Epoch 00065: loss did not improve from 3.06675\n",
      "117/128 [==========================>...] - ETA: 2s - loss: 3.1576 - accuracy: 0.3576\n",
      "Epoch 00065: loss did not improve from 3.06675\n",
      "127/128 [============================>.] - ETA: 0s - loss: 3.1587 - accuracy: 0.3578\n",
      "Epoch 00065: loss did not improve from 3.06675\n",
      "128/128 [==============================] - 34s 268ms/step - loss: 3.1607 - accuracy: 0.3578\n",
      "Epoch 66/100\n",
      "  9/128 [=>............................] - ETA: 34s - loss: 3.0424 - accuracy: 0.3776\n",
      "Epoch 00066: loss improved from 3.06675 to 3.04982, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 19/128 [===>..........................] - ETA: 30s - loss: 3.0231 - accuracy: 0.3762\n",
      "Epoch 00066: loss improved from 3.04982 to 3.01678, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 29/128 [=====>........................] - ETA: 27s - loss: 3.0487 - accuracy: 0.3745\n",
      "Epoch 00066: loss did not improve from 3.01678\n",
      " 39/128 [========>.....................] - ETA: 24s - loss: 3.0241 - accuracy: 0.3773\n",
      "Epoch 00066: loss did not improve from 3.01678\n",
      " 49/128 [==========>...................] - ETA: 21s - loss: 3.0455 - accuracy: 0.3724\n",
      "Epoch 00066: loss did not improve from 3.01678\n",
      " 59/128 [============>.................] - ETA: 18s - loss: 3.0493 - accuracy: 0.3723\n",
      "Epoch 00066: loss did not improve from 3.01678\n",
      " 69/128 [===============>..............] - ETA: 15s - loss: 3.0546 - accuracy: 0.3727\n",
      "Epoch 00066: loss did not improve from 3.01678\n",
      " 79/128 [=================>............] - ETA: 13s - loss: 3.0662 - accuracy: 0.3717\n",
      "Epoch 00066: loss did not improve from 3.01678\n",
      " 89/128 [===================>..........] - ETA: 10s - loss: 3.0671 - accuracy: 0.3697\n",
      "Epoch 00066: loss did not improve from 3.01678\n",
      " 99/128 [======================>.......] - ETA: 7s - loss: 3.0731 - accuracy: 0.3687\n",
      "Epoch 00066: loss did not improve from 3.01678\n",
      "109/128 [========================>.....] - ETA: 5s - loss: 3.0786 - accuracy: 0.3689\n",
      "Epoch 00066: loss did not improve from 3.01678\n",
      "119/128 [==========================>...] - ETA: 2s - loss: 3.0933 - accuracy: 0.3669\n",
      "Epoch 00066: loss did not improve from 3.01678\n",
      "128/128 [==============================] - 35s 273ms/step - loss: 3.1053 - accuracy: 0.3652\n",
      "Epoch 67/100\n",
      "  1/128 [..............................] - ETA: 34s - loss: 3.0823 - accuracy: 0.3672\n",
      "Epoch 00067: loss improved from 3.01678 to 3.01609, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 11/128 [=>............................] - ETA: 31s - loss: 2.9193 - accuracy: 0.3857\n",
      "Epoch 00067: loss improved from 3.01609 to 2.95587, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 21/128 [===>..........................] - ETA: 29s - loss: 2.9744 - accuracy: 0.3811\n",
      "Epoch 00067: loss did not improve from 2.95587\n",
      " 31/128 [======>.......................] - ETA: 26s - loss: 2.9896 - accuracy: 0.3799\n",
      "Epoch 00067: loss did not improve from 2.95587\n",
      " 41/128 [========>.....................] - ETA: 23s - loss: 3.0137 - accuracy: 0.3755\n",
      "Epoch 00067: loss did not improve from 2.95587\n",
      " 51/128 [==========>...................] - ETA: 20s - loss: 3.0238 - accuracy: 0.3749\n",
      "Epoch 00067: loss did not improve from 2.95587\n",
      " 61/128 [=============>................] - ETA: 18s - loss: 3.0183 - accuracy: 0.3730\n",
      "Epoch 00067: loss did not improve from 2.95587\n",
      " 71/128 [===============>..............] - ETA: 15s - loss: 3.0275 - accuracy: 0.3716\n",
      "Epoch 00067: loss did not improve from 2.95587\n",
      " 81/128 [=================>............] - ETA: 12s - loss: 3.0338 - accuracy: 0.3710\n",
      "Epoch 00067: loss did not improve from 2.95587\n",
      " 91/128 [====================>.........] - ETA: 9s - loss: 3.0350 - accuracy: 0.3709 \n",
      "Epoch 00067: loss did not improve from 2.95587\n",
      "101/128 [======================>.......] - ETA: 7s - loss: 3.0472 - accuracy: 0.3697\n",
      "Epoch 00067: loss did not improve from 2.95587\n",
      "111/128 [=========================>....] - ETA: 4s - loss: 3.0612 - accuracy: 0.3681\n",
      "Epoch 00067: loss did not improve from 2.95587\n",
      "121/128 [===========================>..] - ETA: 1s - loss: 3.0740 - accuracy: 0.3661\n",
      "Epoch 00067: loss did not improve from 2.95587\n",
      "128/128 [==============================] - 35s 270ms/step - loss: 3.0717 - accuracy: 0.3669\n",
      "Epoch 68/100\n",
      "  3/128 [..............................] - ETA: 35s - loss: 2.9376 - accuracy: 0.3815\n",
      "Epoch 00068: loss improved from 2.95587 to 2.93572, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 13/128 [==>...........................] - ETA: 31s - loss: 2.8896 - accuracy: 0.3903\n",
      "Epoch 00068: loss improved from 2.93572 to 2.89274, saving model to ./export/2023-10-02T110043/model.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 23/128 [====>.........................] - ETA: 29s - loss: 2.9157 - accuracy: 0.3913\n",
      "Epoch 00068: loss did not improve from 2.89274\n",
      " 33/128 [======>.......................] - ETA: 25s - loss: 2.9524 - accuracy: 0.3833\n",
      "Epoch 00068: loss did not improve from 2.89274\n",
      " 43/128 [=========>....................] - ETA: 23s - loss: 2.9581 - accuracy: 0.3809\n",
      "Epoch 00068: loss did not improve from 2.89274\n",
      " 53/128 [===========>..................] - ETA: 20s - loss: 2.9670 - accuracy: 0.3795\n",
      "Epoch 00068: loss did not improve from 2.89274\n",
      " 63/128 [=============>................] - ETA: 17s - loss: 2.9759 - accuracy: 0.3777\n",
      "Epoch 00068: loss did not improve from 2.89274\n",
      " 73/128 [================>.............] - ETA: 14s - loss: 2.9898 - accuracy: 0.3752\n",
      "Epoch 00068: loss did not improve from 2.89274\n",
      " 83/128 [==================>...........] - ETA: 12s - loss: 2.9979 - accuracy: 0.3739\n",
      "Epoch 00068: loss did not improve from 2.89274\n",
      " 93/128 [====================>.........] - ETA: 9s - loss: 3.0072 - accuracy: 0.3727\n",
      "Epoch 00068: loss did not improve from 2.89274\n",
      "103/128 [=======================>......] - ETA: 6s - loss: 3.0167 - accuracy: 0.3725\n",
      "Epoch 00068: loss did not improve from 2.89274\n",
      "113/128 [=========================>....] - ETA: 4s - loss: 3.0227 - accuracy: 0.3716\n",
      "Epoch 00068: loss did not improve from 2.89274\n",
      "123/128 [===========================>..] - ETA: 1s - loss: 3.0333 - accuracy: 0.3707\n",
      "Epoch 00068: loss did not improve from 2.89274\n",
      "128/128 [==============================] - 35s 270ms/step - loss: 3.0378 - accuracy: 0.3702\n",
      "Epoch 69/100\n",
      "  5/128 [>.............................] - ETA: 35s - loss: 2.8997 - accuracy: 0.3930\n",
      "Epoch 00069: loss did not improve from 2.89274\n",
      " 15/128 [==>...........................] - ETA: 30s - loss: 2.9188 - accuracy: 0.3930\n",
      "Epoch 00069: loss did not improve from 2.89274\n",
      " 25/128 [====>.........................] - ETA: 27s - loss: 2.9289 - accuracy: 0.3908\n",
      "Epoch 00069: loss did not improve from 2.89274\n",
      " 35/128 [=======>......................] - ETA: 24s - loss: 2.9403 - accuracy: 0.3883\n",
      "Epoch 00069: loss did not improve from 2.89274\n",
      " 45/128 [=========>....................] - ETA: 22s - loss: 2.9531 - accuracy: 0.3862\n",
      "Epoch 00069: loss did not improve from 2.89274\n",
      " 55/128 [===========>..................] - ETA: 19s - loss: 2.9603 - accuracy: 0.3847\n",
      "Epoch 00069: loss did not improve from 2.89274\n",
      " 65/128 [==============>...............] - ETA: 16s - loss: 2.9793 - accuracy: 0.3815\n",
      "Epoch 00069: loss did not improve from 2.89274\n",
      " 75/128 [================>.............] - ETA: 14s - loss: 2.9672 - accuracy: 0.3819\n",
      "Epoch 00069: loss did not improve from 2.89274\n",
      " 85/128 [==================>...........] - ETA: 11s - loss: 2.9577 - accuracy: 0.3836\n",
      "Epoch 00069: loss did not improve from 2.89274\n",
      " 95/128 [=====================>........] - ETA: 8s - loss: 2.9686 - accuracy: 0.3815\n",
      "Epoch 00069: loss did not improve from 2.89274\n",
      "105/128 [=======================>......] - ETA: 6s - loss: 2.9708 - accuracy: 0.3815\n",
      "Epoch 00069: loss did not improve from 2.89274\n",
      "115/128 [=========================>....] - ETA: 3s - loss: 2.9771 - accuracy: 0.3806\n",
      "Epoch 00069: loss did not improve from 2.89274\n",
      "125/128 [============================>.] - ETA: 0s - loss: 2.9925 - accuracy: 0.3782\n",
      "Epoch 00069: loss did not improve from 2.89274\n",
      "128/128 [==============================] - 35s 270ms/step - loss: 2.9922 - accuracy: 0.3779\n",
      "Epoch 70/100\n",
      "  7/128 [>.............................] - ETA: 33s - loss: 2.8746 - accuracy: 0.3934\n",
      "Epoch 00070: loss improved from 2.89274 to 2.84477, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 17/128 [==>...........................] - ETA: 31s - loss: 2.9348 - accuracy: 0.3821\n",
      "Epoch 00070: loss did not improve from 2.84477\n",
      " 27/128 [=====>........................] - ETA: 27s - loss: 2.9132 - accuracy: 0.3882\n",
      "Epoch 00070: loss did not improve from 2.84477\n",
      " 37/128 [=======>......................] - ETA: 24s - loss: 2.8921 - accuracy: 0.3886\n",
      "Epoch 00070: loss did not improve from 2.84477\n",
      " 47/128 [==========>...................] - ETA: 21s - loss: 2.8871 - accuracy: 0.3885\n",
      "Epoch 00070: loss did not improve from 2.84477\n",
      " 57/128 [============>.................] - ETA: 19s - loss: 2.8912 - accuracy: 0.3893\n",
      "Epoch 00070: loss did not improve from 2.84477\n",
      " 67/128 [==============>...............] - ETA: 16s - loss: 2.8970 - accuracy: 0.3887\n",
      "Epoch 00070: loss did not improve from 2.84477\n",
      " 77/128 [=================>............] - ETA: 13s - loss: 2.9017 - accuracy: 0.3888\n",
      "Epoch 00070: loss did not improve from 2.84477\n",
      " 87/128 [===================>..........] - ETA: 10s - loss: 2.9117 - accuracy: 0.3872\n",
      "Epoch 00070: loss did not improve from 2.84477\n",
      " 97/128 [=====================>........] - ETA: 8s - loss: 2.9169 - accuracy: 0.3871\n",
      "Epoch 00070: loss did not improve from 2.84477\n",
      "107/128 [========================>.....] - ETA: 5s - loss: 2.9279 - accuracy: 0.3855\n",
      "Epoch 00070: loss did not improve from 2.84477\n",
      "117/128 [==========================>...] - ETA: 2s - loss: 2.9395 - accuracy: 0.3845\n",
      "Epoch 00070: loss did not improve from 2.84477\n",
      "127/128 [============================>.] - ETA: 0s - loss: 2.9547 - accuracy: 0.3826\n",
      "Epoch 00070: loss did not improve from 2.84477\n",
      "128/128 [==============================] - 35s 270ms/step - loss: 2.9555 - accuracy: 0.3826\n",
      "Epoch 71/100\n",
      "  9/128 [=>............................] - ETA: 33s - loss: 2.8482 - accuracy: 0.3880\n",
      "Epoch 00071: loss improved from 2.84477 to 2.83875, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 19/128 [===>..........................] - ETA: 29s - loss: 2.8466 - accuracy: 0.3892\n",
      "Epoch 00071: loss did not improve from 2.83875\n",
      " 29/128 [=====>........................] - ETA: 26s - loss: 2.8226 - accuracy: 0.3955\n",
      "Epoch 00071: loss improved from 2.83875 to 2.81820, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 39/128 [========>.....................] - ETA: 24s - loss: 2.8389 - accuracy: 0.3948\n",
      "Epoch 00071: loss did not improve from 2.81820\n",
      " 49/128 [==========>...................] - ETA: 21s - loss: 2.8326 - accuracy: 0.3946\n",
      "Epoch 00071: loss did not improve from 2.81820\n",
      " 59/128 [============>.................] - ETA: 18s - loss: 2.8276 - accuracy: 0.3951\n",
      "Epoch 00071: loss did not improve from 2.81820\n",
      " 69/128 [===============>..............] - ETA: 16s - loss: 2.8293 - accuracy: 0.3953\n",
      "Epoch 00071: loss did not improve from 2.81820\n",
      " 79/128 [=================>............] - ETA: 13s - loss: 2.8414 - accuracy: 0.3952\n",
      "Epoch 00071: loss did not improve from 2.81820\n",
      " 89/128 [===================>..........] - ETA: 10s - loss: 2.8506 - accuracy: 0.3937\n",
      "Epoch 00071: loss did not improve from 2.81820\n",
      " 99/128 [======================>.......] - ETA: 7s - loss: 2.8654 - accuracy: 0.3917\n",
      "Epoch 00071: loss did not improve from 2.81820\n",
      "109/128 [========================>.....] - ETA: 5s - loss: 2.8785 - accuracy: 0.3901\n",
      "Epoch 00071: loss did not improve from 2.81820\n",
      "119/128 [==========================>...] - ETA: 2s - loss: 2.8911 - accuracy: 0.3886\n",
      "Epoch 00071: loss did not improve from 2.81820\n",
      "128/128 [==============================] - 34s 262ms/step - loss: 2.8999 - accuracy: 0.3873\n",
      "Epoch 72/100\n",
      "  1/128 [..............................] - ETA: 28s - loss: 2.5858 - accuracy: 0.4102\n",
      "Epoch 00072: loss improved from 2.81820 to 2.73494, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 11/128 [=>............................] - ETA: 30s - loss: 2.7820 - accuracy: 0.4031\n",
      "Epoch 00072: loss did not improve from 2.73494\n",
      " 21/128 [===>..........................] - ETA: 26s - loss: 2.7855 - accuracy: 0.4040\n",
      "Epoch 00072: loss did not improve from 2.73494\n",
      " 31/128 [======>.......................] - ETA: 23s - loss: 2.8011 - accuracy: 0.3989\n",
      "Epoch 00072: loss did not improve from 2.73494\n",
      " 41/128 [========>.....................] - ETA: 21s - loss: 2.8195 - accuracy: 0.3950\n",
      "Epoch 00072: loss did not improve from 2.73494\n",
      " 51/128 [==========>...................] - ETA: 18s - loss: 2.8293 - accuracy: 0.3961\n",
      "Epoch 00072: loss did not improve from 2.73494\n",
      " 61/128 [=============>................] - ETA: 16s - loss: 2.8301 - accuracy: 0.3965\n",
      "Epoch 00072: loss did not improve from 2.73494\n",
      " 71/128 [===============>..............] - ETA: 13s - loss: 2.8480 - accuracy: 0.3956\n",
      "Epoch 00072: loss did not improve from 2.73494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 81/128 [=================>............] - ETA: 11s - loss: 2.8516 - accuracy: 0.3944\n",
      "Epoch 00072: loss did not improve from 2.73494\n",
      " 91/128 [====================>.........] - ETA: 9s - loss: 2.8554 - accuracy: 0.3944\n",
      "Epoch 00072: loss did not improve from 2.73494\n",
      "101/128 [======================>.......] - ETA: 6s - loss: 2.8673 - accuracy: 0.3929\n",
      "Epoch 00072: loss did not improve from 2.73494\n",
      "111/128 [=========================>....] - ETA: 4s - loss: 2.8723 - accuracy: 0.3918\n",
      "Epoch 00072: loss did not improve from 2.73494\n",
      "121/128 [===========================>..] - ETA: 1s - loss: 2.8806 - accuracy: 0.3918\n",
      "Epoch 00072: loss did not improve from 2.73494\n",
      "128/128 [==============================] - 31s 244ms/step - loss: 2.8794 - accuracy: 0.3925\n",
      "Epoch 73/100\n",
      "  3/128 [..............................] - ETA: 29s - loss: 2.8344 - accuracy: 0.4258\n",
      "Epoch 00073: loss did not improve from 2.73494\n",
      " 13/128 [==>...........................] - ETA: 29s - loss: 2.7660 - accuracy: 0.4129\n",
      "Epoch 00073: loss did not improve from 2.73494\n",
      " 23/128 [====>.........................] - ETA: 25s - loss: 2.7468 - accuracy: 0.4169\n",
      "Epoch 00073: loss did not improve from 2.73494\n",
      " 33/128 [======>.......................] - ETA: 23s - loss: 2.7759 - accuracy: 0.4107\n",
      "Epoch 00073: loss did not improve from 2.73494\n",
      " 43/128 [=========>....................] - ETA: 20s - loss: 2.7775 - accuracy: 0.4098\n",
      "Epoch 00073: loss did not improve from 2.73494\n",
      " 53/128 [===========>..................] - ETA: 18s - loss: 2.7800 - accuracy: 0.4075\n",
      "Epoch 00073: loss did not improve from 2.73494\n",
      " 63/128 [=============>................] - ETA: 15s - loss: 2.7988 - accuracy: 0.4058\n",
      "Epoch 00073: loss did not improve from 2.73494\n",
      " 73/128 [================>.............] - ETA: 13s - loss: 2.8038 - accuracy: 0.4065\n",
      "Epoch 00073: loss did not improve from 2.73494\n",
      " 83/128 [==================>...........] - ETA: 10s - loss: 2.8174 - accuracy: 0.4027\n",
      "Epoch 00073: loss did not improve from 2.73494\n",
      " 93/128 [====================>.........] - ETA: 8s - loss: 2.8267 - accuracy: 0.4018\n",
      "Epoch 00073: loss did not improve from 2.73494\n",
      "103/128 [=======================>......] - ETA: 6s - loss: 2.8324 - accuracy: 0.4001\n",
      "Epoch 00073: loss did not improve from 2.73494\n",
      "113/128 [=========================>....] - ETA: 3s - loss: 2.8341 - accuracy: 0.4001\n",
      "Epoch 00073: loss did not improve from 2.73494\n",
      "123/128 [===========================>..] - ETA: 1s - loss: 2.8396 - accuracy: 0.3992\n",
      "Epoch 00073: loss did not improve from 2.73494\n",
      "128/128 [==============================] - 31s 243ms/step - loss: 2.8454 - accuracy: 0.3983\n",
      "Epoch 74/100\n",
      "  5/128 [>.............................] - ETA: 31s - loss: 2.6411 - accuracy: 0.4258\n",
      "Epoch 00074: loss improved from 2.73494 to 2.65300, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 15/128 [==>...........................] - ETA: 28s - loss: 2.7124 - accuracy: 0.4245\n",
      "Epoch 00074: loss did not improve from 2.65300\n",
      " 25/128 [====>.........................] - ETA: 25s - loss: 2.7371 - accuracy: 0.4172\n",
      "Epoch 00074: loss did not improve from 2.65300\n",
      " 35/128 [=======>......................] - ETA: 22s - loss: 2.7716 - accuracy: 0.4112\n",
      "Epoch 00074: loss did not improve from 2.65300\n",
      " 45/128 [=========>....................] - ETA: 20s - loss: 2.7744 - accuracy: 0.4088\n",
      "Epoch 00074: loss did not improve from 2.65300\n",
      " 55/128 [===========>..................] - ETA: 17s - loss: 2.7818 - accuracy: 0.4064\n",
      "Epoch 00074: loss did not improve from 2.65300\n",
      " 65/128 [==============>...............] - ETA: 15s - loss: 2.7916 - accuracy: 0.4061\n",
      "Epoch 00074: loss did not improve from 2.65300\n",
      " 75/128 [================>.............] - ETA: 12s - loss: 2.7847 - accuracy: 0.4062\n",
      "Epoch 00074: loss did not improve from 2.65300\n",
      " 85/128 [==================>...........] - ETA: 10s - loss: 2.7817 - accuracy: 0.4048\n",
      "Epoch 00074: loss did not improve from 2.65300\n",
      " 95/128 [=====================>........] - ETA: 8s - loss: 2.7937 - accuracy: 0.4028\n",
      "Epoch 00074: loss did not improve from 2.65300\n",
      "105/128 [=======================>......] - ETA: 5s - loss: 2.7961 - accuracy: 0.4032\n",
      "Epoch 00074: loss did not improve from 2.65300\n",
      "115/128 [=========================>....] - ETA: 3s - loss: 2.8121 - accuracy: 0.4012\n",
      "Epoch 00074: loss did not improve from 2.65300\n",
      "125/128 [============================>.] - ETA: 0s - loss: 2.8226 - accuracy: 0.3993\n",
      "Epoch 00074: loss did not improve from 2.65300\n",
      "128/128 [==============================] - 31s 244ms/step - loss: 2.8226 - accuracy: 0.3996\n",
      "Epoch 75/100\n",
      "  7/128 [>.............................] - ETA: 31s - loss: 2.8169 - accuracy: 0.3996\n",
      "Epoch 00075: loss did not improve from 2.65300\n",
      " 17/128 [==>...........................] - ETA: 26s - loss: 2.7753 - accuracy: 0.4106\n",
      "Epoch 00075: loss did not improve from 2.65300\n",
      " 27/128 [=====>........................] - ETA: 24s - loss: 2.7548 - accuracy: 0.4157\n",
      "Epoch 00075: loss did not improve from 2.65300\n",
      " 37/128 [=======>......................] - ETA: 21s - loss: 2.7515 - accuracy: 0.4161\n",
      "Epoch 00075: loss did not improve from 2.65300\n",
      " 47/128 [==========>...................] - ETA: 19s - loss: 2.7607 - accuracy: 0.4141\n",
      "Epoch 00075: loss did not improve from 2.65300\n",
      " 57/128 [============>.................] - ETA: 17s - loss: 2.7485 - accuracy: 0.4149\n",
      "Epoch 00075: loss did not improve from 2.65300\n",
      " 67/128 [==============>...............] - ETA: 14s - loss: 2.7544 - accuracy: 0.4140\n",
      "Epoch 00075: loss did not improve from 2.65300\n",
      " 77/128 [=================>............] - ETA: 12s - loss: 2.7548 - accuracy: 0.4124\n",
      "Epoch 00075: loss did not improve from 2.65300\n",
      " 87/128 [===================>..........] - ETA: 9s - loss: 2.7530 - accuracy: 0.4127 \n",
      "Epoch 00075: loss did not improve from 2.65300\n",
      " 97/128 [=====================>........] - ETA: 7s - loss: 2.7507 - accuracy: 0.4141\n",
      "Epoch 00075: loss did not improve from 2.65300\n",
      "107/128 [========================>.....] - ETA: 5s - loss: 2.7610 - accuracy: 0.4128\n",
      "Epoch 00075: loss did not improve from 2.65300\n",
      "117/128 [==========================>...] - ETA: 2s - loss: 2.7711 - accuracy: 0.4103\n",
      "Epoch 00075: loss did not improve from 2.65300\n",
      "127/128 [============================>.] - ETA: 0s - loss: 2.7821 - accuracy: 0.4085\n",
      "Epoch 00075: loss did not improve from 2.65300\n",
      "128/128 [==============================] - 31s 244ms/step - loss: 2.7842 - accuracy: 0.4081\n",
      "Epoch 76/100\n",
      "  9/128 [=>............................] - ETA: 27s - loss: 2.6677 - accuracy: 0.4227\n",
      "Epoch 00076: loss did not improve from 2.65300\n",
      " 19/128 [===>..........................] - ETA: 26s - loss: 2.6946 - accuracy: 0.4198\n",
      "Epoch 00076: loss did not improve from 2.65300\n",
      " 29/128 [=====>........................] - ETA: 24s - loss: 2.6910 - accuracy: 0.4165\n",
      "Epoch 00076: loss did not improve from 2.65300\n",
      " 39/128 [========>.....................] - ETA: 21s - loss: 2.6944 - accuracy: 0.4180\n",
      "Epoch 00076: loss did not improve from 2.65300\n",
      " 49/128 [==========>...................] - ETA: 19s - loss: 2.7041 - accuracy: 0.4158\n",
      "Epoch 00076: loss did not improve from 2.65300\n",
      " 59/128 [============>.................] - ETA: 16s - loss: 2.7165 - accuracy: 0.4124\n",
      "Epoch 00076: loss did not improve from 2.65300\n",
      " 69/128 [===============>..............] - ETA: 14s - loss: 2.7065 - accuracy: 0.4131\n",
      "Epoch 00076: loss did not improve from 2.65300\n",
      " 79/128 [=================>............] - ETA: 11s - loss: 2.7041 - accuracy: 0.4152\n",
      "Epoch 00076: loss did not improve from 2.65300\n",
      " 89/128 [===================>..........] - ETA: 9s - loss: 2.7113 - accuracy: 0.4139\n",
      "Epoch 00076: loss did not improve from 2.65300\n",
      " 99/128 [======================>.......] - ETA: 7s - loss: 2.7172 - accuracy: 0.4142\n",
      "Epoch 00076: loss did not improve from 2.65300\n",
      "109/128 [========================>.....] - ETA: 4s - loss: 2.7285 - accuracy: 0.4131\n",
      "Epoch 00076: loss did not improve from 2.65300\n",
      "119/128 [==========================>...] - ETA: 2s - loss: 2.7396 - accuracy: 0.4105\n",
      "Epoch 00076: loss did not improve from 2.65300\n",
      "128/128 [==============================] - 31s 243ms/step - loss: 2.7507 - accuracy: 0.4098\n",
      "Epoch 77/100\n",
      "  1/128 [..............................] - ETA: 31s - loss: 2.6308 - accuracy: 0.4453\n",
      "Epoch 00077: loss improved from 2.65300 to 2.62195, saving model to ./export/2023-10-02T110043/model.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 11/128 [=>............................] - ETA: 27s - loss: 2.6759 - accuracy: 0.4276\n",
      "Epoch 00077: loss did not improve from 2.62195\n",
      " 21/128 [===>..........................] - ETA: 27s - loss: 2.6546 - accuracy: 0.4288\n",
      "Epoch 00077: loss did not improve from 2.62195\n",
      " 31/128 [======>.......................] - ETA: 24s - loss: 2.6763 - accuracy: 0.4257\n",
      "Epoch 00077: loss did not improve from 2.62195\n",
      " 41/128 [========>.....................] - ETA: 21s - loss: 2.6758 - accuracy: 0.4241\n",
      "Epoch 00077: loss did not improve from 2.62195\n",
      " 51/128 [==========>...................] - ETA: 18s - loss: 2.6722 - accuracy: 0.4230\n",
      "Epoch 00077: loss did not improve from 2.62195\n",
      " 61/128 [=============>................] - ETA: 16s - loss: 2.6666 - accuracy: 0.4237\n",
      "Epoch 00077: loss did not improve from 2.62195\n",
      " 71/128 [===============>..............] - ETA: 13s - loss: 2.6836 - accuracy: 0.4207\n",
      "Epoch 00077: loss did not improve from 2.62195\n",
      " 81/128 [=================>............] - ETA: 11s - loss: 2.6805 - accuracy: 0.4226\n",
      "Epoch 00077: loss did not improve from 2.62195\n",
      " 91/128 [====================>.........] - ETA: 9s - loss: 2.6837 - accuracy: 0.4205\n",
      "Epoch 00077: loss did not improve from 2.62195\n",
      "101/128 [======================>.......] - ETA: 6s - loss: 2.6904 - accuracy: 0.4201\n",
      "Epoch 00077: loss did not improve from 2.62195\n",
      "111/128 [=========================>....] - ETA: 4s - loss: 2.6987 - accuracy: 0.4186\n",
      "Epoch 00077: loss did not improve from 2.62195\n",
      "121/128 [===========================>..] - ETA: 1s - loss: 2.7045 - accuracy: 0.4169\n",
      "Epoch 00077: loss did not improve from 2.62195\n",
      "128/128 [==============================] - 31s 244ms/step - loss: 2.7119 - accuracy: 0.4161\n",
      "Epoch 78/100\n",
      "  3/128 [..............................] - ETA: 28s - loss: 2.4721 - accuracy: 0.4583\n",
      "Epoch 00078: loss improved from 2.62195 to 2.52173, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 13/128 [==>...........................] - ETA: 28s - loss: 2.5121 - accuracy: 0.4492\n",
      "Epoch 00078: loss improved from 2.52173 to 2.51923, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 23/128 [====>.........................] - ETA: 26s - loss: 2.5333 - accuracy: 0.4441\n",
      "Epoch 00078: loss did not improve from 2.51923\n",
      " 33/128 [======>.......................] - ETA: 24s - loss: 2.5683 - accuracy: 0.4360\n",
      "Epoch 00078: loss did not improve from 2.51923\n",
      " 43/128 [=========>....................] - ETA: 21s - loss: 2.5962 - accuracy: 0.4318\n",
      "Epoch 00078: loss did not improve from 2.51923\n",
      " 53/128 [===========>..................] - ETA: 18s - loss: 2.6157 - accuracy: 0.4295\n",
      "Epoch 00078: loss did not improve from 2.51923\n",
      " 63/128 [=============>................] - ETA: 16s - loss: 2.6241 - accuracy: 0.4291\n",
      "Epoch 00078: loss did not improve from 2.51923\n",
      " 73/128 [================>.............] - ETA: 13s - loss: 2.6249 - accuracy: 0.4283\n",
      "Epoch 00078: loss did not improve from 2.51923\n",
      " 83/128 [==================>...........] - ETA: 11s - loss: 2.6270 - accuracy: 0.4287\n",
      "Epoch 00078: loss did not improve from 2.51923\n",
      " 93/128 [====================>.........] - ETA: 8s - loss: 2.6345 - accuracy: 0.4285\n",
      "Epoch 00078: loss did not improve from 2.51923\n",
      "103/128 [=======================>......] - ETA: 6s - loss: 2.6414 - accuracy: 0.4272\n",
      "Epoch 00078: loss did not improve from 2.51923\n",
      "113/128 [=========================>....] - ETA: 3s - loss: 2.6531 - accuracy: 0.4248\n",
      "Epoch 00078: loss did not improve from 2.51923\n",
      "123/128 [===========================>..] - ETA: 1s - loss: 2.6655 - accuracy: 0.4228\n",
      "Epoch 00078: loss did not improve from 2.51923\n",
      "128/128 [==============================] - 31s 245ms/step - loss: 2.6752 - accuracy: 0.4218\n",
      "Epoch 79/100\n",
      "  5/128 [>.............................] - ETA: 31s - loss: 2.5046 - accuracy: 0.4422\n",
      "Epoch 00079: loss did not improve from 2.51923\n",
      " 15/128 [==>...........................] - ETA: 28s - loss: 2.6016 - accuracy: 0.4346\n",
      "Epoch 00079: loss did not improve from 2.51923\n",
      " 25/128 [====>.........................] - ETA: 25s - loss: 2.6294 - accuracy: 0.4306\n",
      "Epoch 00079: loss did not improve from 2.51923\n",
      " 35/128 [=======>......................] - ETA: 23s - loss: 2.6097 - accuracy: 0.4362\n",
      "Epoch 00079: loss did not improve from 2.51923\n",
      " 45/128 [=========>....................] - ETA: 21s - loss: 2.6171 - accuracy: 0.4354\n",
      "Epoch 00079: loss did not improve from 2.51923\n",
      " 55/128 [===========>..................] - ETA: 18s - loss: 2.6232 - accuracy: 0.4342\n",
      "Epoch 00079: loss did not improve from 2.51923\n",
      " 65/128 [==============>...............] - ETA: 15s - loss: 2.6335 - accuracy: 0.4311\n",
      "Epoch 00079: loss did not improve from 2.51923\n",
      " 75/128 [================>.............] - ETA: 13s - loss: 2.6300 - accuracy: 0.4320\n",
      "Epoch 00079: loss did not improve from 2.51923\n",
      " 85/128 [==================>...........] - ETA: 10s - loss: 2.6338 - accuracy: 0.4318\n",
      "Epoch 00079: loss did not improve from 2.51923\n",
      " 95/128 [=====================>........] - ETA: 8s - loss: 2.6444 - accuracy: 0.4301\n",
      "Epoch 00079: loss did not improve from 2.51923\n",
      "105/128 [=======================>......] - ETA: 5s - loss: 2.6491 - accuracy: 0.4288\n",
      "Epoch 00079: loss did not improve from 2.51923\n",
      "115/128 [=========================>....] - ETA: 3s - loss: 2.6587 - accuracy: 0.4264\n",
      "Epoch 00079: loss did not improve from 2.51923\n",
      "125/128 [============================>.] - ETA: 0s - loss: 2.6631 - accuracy: 0.4260\n",
      "Epoch 00079: loss did not improve from 2.51923\n",
      "128/128 [==============================] - 32s 246ms/step - loss: 2.6637 - accuracy: 0.4261\n",
      "Epoch 80/100\n",
      "  7/128 [>.............................] - ETA: 27s - loss: 2.4890 - accuracy: 0.4487\n",
      "Epoch 00080: loss improved from 2.51923 to 2.50133, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 17/128 [==>...........................] - ETA: 27s - loss: 2.4979 - accuracy: 0.4432\n",
      "Epoch 00080: loss improved from 2.50133 to 2.50121, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 27/128 [=====>........................] - ETA: 24s - loss: 2.5056 - accuracy: 0.4469\n",
      "Epoch 00080: loss did not improve from 2.50121\n",
      " 37/128 [=======>......................] - ETA: 22s - loss: 2.5396 - accuracy: 0.4401\n",
      "Epoch 00080: loss did not improve from 2.50121\n",
      " 47/128 [==========>...................] - ETA: 20s - loss: 2.5641 - accuracy: 0.4368\n",
      "Epoch 00080: loss did not improve from 2.50121\n",
      " 57/128 [============>.................] - ETA: 17s - loss: 2.5704 - accuracy: 0.4383\n",
      "Epoch 00080: loss did not improve from 2.50121\n",
      " 67/128 [==============>...............] - ETA: 15s - loss: 2.5779 - accuracy: 0.4376\n",
      "Epoch 00080: loss did not improve from 2.50121\n",
      " 77/128 [=================>............] - ETA: 12s - loss: 2.5884 - accuracy: 0.4356\n",
      "Epoch 00080: loss did not improve from 2.50121\n",
      " 87/128 [===================>..........] - ETA: 10s - loss: 2.6045 - accuracy: 0.4327\n",
      "Epoch 00080: loss did not improve from 2.50121\n",
      " 97/128 [=====================>........] - ETA: 7s - loss: 2.6125 - accuracy: 0.4311\n",
      "Epoch 00080: loss did not improve from 2.50121\n",
      "107/128 [========================>.....] - ETA: 5s - loss: 2.6187 - accuracy: 0.4298\n",
      "Epoch 00080: loss did not improve from 2.50121\n",
      "117/128 [==========================>...] - ETA: 2s - loss: 2.6214 - accuracy: 0.4287\n",
      "Epoch 00080: loss did not improve from 2.50121\n",
      "127/128 [============================>.] - ETA: 0s - loss: 2.6259 - accuracy: 0.4284\n",
      "Epoch 00080: loss did not improve from 2.50121\n",
      "128/128 [==============================] - 31s 244ms/step - loss: 2.6276 - accuracy: 0.4283\n",
      "Epoch 81/100\n",
      "  9/128 [=>............................] - ETA: 29s - loss: 2.5074 - accuracy: 0.4466\n",
      "Epoch 00081: loss improved from 2.50121 to 2.48135, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 19/128 [===>..........................] - ETA: 26s - loss: 2.5177 - accuracy: 0.4439\n",
      "Epoch 00081: loss did not improve from 2.48135\n",
      " 29/128 [=====>........................] - ETA: 24s - loss: 2.5389 - accuracy: 0.4442\n",
      "Epoch 00081: loss did not improve from 2.48135\n",
      " 39/128 [========>.....................] - ETA: 21s - loss: 2.5364 - accuracy: 0.4410\n",
      "Epoch 00081: loss did not improve from 2.48135\n",
      " 49/128 [==========>...................] - ETA: 19s - loss: 2.5329 - accuracy: 0.4422\n",
      "Epoch 00081: loss did not improve from 2.48135\n",
      " 59/128 [============>.................] - ETA: 17s - loss: 2.5395 - accuracy: 0.4419\n",
      "Epoch 00081: loss did not improve from 2.48135\n",
      " 69/128 [===============>..............] - ETA: 14s - loss: 2.5536 - accuracy: 0.4398\n",
      "Epoch 00081: loss did not improve from 2.48135\n",
      " 79/128 [=================>............] - ETA: 12s - loss: 2.5646 - accuracy: 0.4377\n",
      "Epoch 00081: loss did not improve from 2.48135\n",
      " 89/128 [===================>..........] - ETA: 9s - loss: 2.5710 - accuracy: 0.4361\n",
      "Epoch 00081: loss did not improve from 2.48135\n",
      " 99/128 [======================>.......] - ETA: 7s - loss: 2.5789 - accuracy: 0.4356\n",
      "Epoch 00081: loss did not improve from 2.48135\n",
      "109/128 [========================>.....] - ETA: 4s - loss: 2.5808 - accuracy: 0.4350\n",
      "Epoch 00081: loss did not improve from 2.48135\n",
      "119/128 [==========================>...] - ETA: 2s - loss: 2.5859 - accuracy: 0.4348\n",
      "Epoch 00081: loss did not improve from 2.48135\n",
      "128/128 [==============================] - 31s 244ms/step - loss: 2.5946 - accuracy: 0.4337\n",
      "Epoch 82/100\n",
      "  1/128 [..............................] - ETA: 32s - loss: 2.3611 - accuracy: 0.4961\n",
      "Epoch 00082: loss did not improve from 2.48135\n",
      " 11/128 [=>............................] - ETA: 29s - loss: 2.4958 - accuracy: 0.4517\n",
      "Epoch 00082: loss did not improve from 2.48135\n",
      " 21/128 [===>..........................] - ETA: 25s - loss: 2.5300 - accuracy: 0.4427\n",
      "Epoch 00082: loss did not improve from 2.48135\n",
      " 31/128 [======>.......................] - ETA: 23s - loss: 2.5071 - accuracy: 0.4506\n",
      "Epoch 00082: loss did not improve from 2.48135\n",
      " 41/128 [========>.....................] - ETA: 21s - loss: 2.5391 - accuracy: 0.4455\n",
      "Epoch 00082: loss did not improve from 2.48135\n",
      " 51/128 [==========>...................] - ETA: 19s - loss: 2.5286 - accuracy: 0.4470\n",
      "Epoch 00082: loss did not improve from 2.48135\n",
      " 61/128 [=============>................] - ETA: 16s - loss: 2.5364 - accuracy: 0.4451\n",
      "Epoch 00082: loss did not improve from 2.48135\n",
      " 71/128 [===============>..............] - ETA: 14s - loss: 2.5308 - accuracy: 0.4444\n",
      "Epoch 00082: loss did not improve from 2.48135\n",
      " 81/128 [=================>............] - ETA: 11s - loss: 2.5414 - accuracy: 0.4440\n",
      "Epoch 00082: loss did not improve from 2.48135\n",
      " 91/128 [====================>.........] - ETA: 9s - loss: 2.5402 - accuracy: 0.4445\n",
      "Epoch 00082: loss did not improve from 2.48135\n",
      "101/128 [======================>.......] - ETA: 6s - loss: 2.5489 - accuracy: 0.4419\n",
      "Epoch 00082: loss did not improve from 2.48135\n",
      "111/128 [=========================>....] - ETA: 4s - loss: 2.5572 - accuracy: 0.4409\n",
      "Epoch 00082: loss did not improve from 2.48135\n",
      "121/128 [===========================>..] - ETA: 1s - loss: 2.5615 - accuracy: 0.4401\n",
      "Epoch 00082: loss did not improve from 2.48135\n",
      "128/128 [==============================] - 31s 246ms/step - loss: 2.5656 - accuracy: 0.4396\n",
      "Epoch 83/100\n",
      "  3/128 [..............................] - ETA: 27s - loss: 2.4752 - accuracy: 0.4805\n",
      "Epoch 00083: loss improved from 2.48135 to 2.45016, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 13/128 [==>...........................] - ETA: 28s - loss: 2.4673 - accuracy: 0.4603\n",
      "Epoch 00083: loss did not improve from 2.45016\n",
      " 23/128 [====>.........................] - ETA: 25s - loss: 2.4766 - accuracy: 0.4611\n",
      "Epoch 00083: loss did not improve from 2.45016\n",
      " 33/128 [======>.......................] - ETA: 23s - loss: 2.4954 - accuracy: 0.4557\n",
      "Epoch 00083: loss did not improve from 2.45016\n",
      " 43/128 [=========>....................] - ETA: 20s - loss: 2.4938 - accuracy: 0.4560\n",
      "Epoch 00083: loss did not improve from 2.45016\n",
      " 53/128 [===========>..................] - ETA: 18s - loss: 2.5089 - accuracy: 0.4533\n",
      "Epoch 00083: loss did not improve from 2.45016\n",
      " 63/128 [=============>................] - ETA: 16s - loss: 2.5039 - accuracy: 0.4529\n",
      "Epoch 00083: loss did not improve from 2.45016\n",
      " 73/128 [================>.............] - ETA: 13s - loss: 2.5102 - accuracy: 0.4513\n",
      "Epoch 00083: loss did not improve from 2.45016\n",
      " 83/128 [==================>...........] - ETA: 11s - loss: 2.5162 - accuracy: 0.4493\n",
      "Epoch 00083: loss did not improve from 2.45016\n",
      " 93/128 [====================>.........] - ETA: 8s - loss: 2.5286 - accuracy: 0.4474\n",
      "Epoch 00083: loss did not improve from 2.45016\n",
      "103/128 [=======================>......] - ETA: 6s - loss: 2.5338 - accuracy: 0.4457\n",
      "Epoch 00083: loss did not improve from 2.45016\n",
      "113/128 [=========================>....] - ETA: 3s - loss: 2.5394 - accuracy: 0.4446\n",
      "Epoch 00083: loss did not improve from 2.45016\n",
      "123/128 [===========================>..] - ETA: 1s - loss: 2.5448 - accuracy: 0.4438\n",
      "Epoch 00083: loss did not improve from 2.45016\n",
      "128/128 [==============================] - 31s 244ms/step - loss: 2.5474 - accuracy: 0.4434\n",
      "Epoch 84/100\n",
      "  5/128 [>.............................] - ETA: 30s - loss: 2.3714 - accuracy: 0.4688\n",
      "Epoch 00084: loss improved from 2.45016 to 2.40126, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 15/128 [==>...........................] - ETA: 28s - loss: 2.3926 - accuracy: 0.4643\n",
      "Epoch 00084: loss did not improve from 2.40126\n",
      " 25/128 [====>.........................] - ETA: 25s - loss: 2.4396 - accuracy: 0.4577\n",
      "Epoch 00084: loss did not improve from 2.40126\n",
      " 35/128 [=======>......................] - ETA: 22s - loss: 2.4446 - accuracy: 0.4596\n",
      "Epoch 00084: loss did not improve from 2.40126\n",
      " 45/128 [=========>....................] - ETA: 20s - loss: 2.4606 - accuracy: 0.4570\n",
      "Epoch 00084: loss did not improve from 2.40126\n",
      " 55/128 [===========>..................] - ETA: 17s - loss: 2.4724 - accuracy: 0.4541\n",
      "Epoch 00084: loss did not improve from 2.40126\n",
      " 65/128 [==============>...............] - ETA: 15s - loss: 2.4830 - accuracy: 0.4519\n",
      "Epoch 00084: loss did not improve from 2.40126\n",
      " 75/128 [================>.............] - ETA: 13s - loss: 2.4952 - accuracy: 0.4503\n",
      "Epoch 00084: loss did not improve from 2.40126\n",
      " 85/128 [==================>...........] - ETA: 10s - loss: 2.4913 - accuracy: 0.4507\n",
      "Epoch 00084: loss did not improve from 2.40126\n",
      " 95/128 [=====================>........] - ETA: 8s - loss: 2.4952 - accuracy: 0.4507\n",
      "Epoch 00084: loss did not improve from 2.40126\n",
      "105/128 [=======================>......] - ETA: 5s - loss: 2.5038 - accuracy: 0.4498\n",
      "Epoch 00084: loss did not improve from 2.40126\n",
      "115/128 [=========================>....] - ETA: 3s - loss: 2.5110 - accuracy: 0.4489\n",
      "Epoch 00084: loss did not improve from 2.40126\n",
      "125/128 [============================>.] - ETA: 0s - loss: 2.5248 - accuracy: 0.4469\n",
      "Epoch 00084: loss did not improve from 2.40126\n",
      "128/128 [==============================] - 31s 244ms/step - loss: 2.5262 - accuracy: 0.4465\n",
      "Epoch 85/100\n",
      "  7/128 [>.............................] - ETA: 30s - loss: 2.4817 - accuracy: 0.4531\n",
      "Epoch 00085: loss did not improve from 2.40126\n",
      " 17/128 [==>...........................] - ETA: 25s - loss: 2.4335 - accuracy: 0.4612\n",
      "Epoch 00085: loss did not improve from 2.40126\n",
      " 27/128 [=====>........................] - ETA: 24s - loss: 2.4180 - accuracy: 0.4641\n",
      "Epoch 00085: loss did not improve from 2.40126\n",
      " 37/128 [=======>......................] - ETA: 21s - loss: 2.4280 - accuracy: 0.4619\n",
      "Epoch 00085: loss did not improve from 2.40126\n",
      " 47/128 [==========>...................] - ETA: 19s - loss: 2.4283 - accuracy: 0.4619\n",
      "Epoch 00085: loss did not improve from 2.40126\n",
      " 57/128 [============>.................] - ETA: 17s - loss: 2.4374 - accuracy: 0.4589\n",
      "Epoch 00085: loss did not improve from 2.40126\n",
      " 67/128 [==============>...............] - ETA: 14s - loss: 2.4429 - accuracy: 0.4582\n",
      "Epoch 00085: loss did not improve from 2.40126\n",
      " 77/128 [=================>............] - ETA: 12s - loss: 2.4583 - accuracy: 0.4548\n",
      "Epoch 00085: loss did not improve from 2.40126\n",
      " 87/128 [===================>..........] - ETA: 10s - loss: 2.4545 - accuracy: 0.4553\n",
      "Epoch 00085: loss did not improve from 2.40126\n",
      " 97/128 [=====================>........] - ETA: 7s - loss: 2.4714 - accuracy: 0.4540\n",
      "Epoch 00085: loss did not improve from 2.40126\n",
      "107/128 [========================>.....] - ETA: 5s - loss: 2.4795 - accuracy: 0.4527\n",
      "Epoch 00085: loss did not improve from 2.40126\n",
      "117/128 [==========================>...] - ETA: 2s - loss: 2.4765 - accuracy: 0.4529\n",
      "Epoch 00085: loss did not improve from 2.40126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127/128 [============================>.] - ETA: 0s - loss: 2.4848 - accuracy: 0.4517\n",
      "Epoch 00085: loss did not improve from 2.40126\n",
      "128/128 [==============================] - 31s 245ms/step - loss: 2.4858 - accuracy: 0.4514\n",
      "Epoch 86/100\n",
      "  9/128 [=>............................] - ETA: 26s - loss: 2.4366 - accuracy: 0.4601\n",
      "Epoch 00086: loss did not improve from 2.40126\n",
      " 19/128 [===>..........................] - ETA: 26s - loss: 2.4482 - accuracy: 0.4642\n",
      "Epoch 00086: loss did not improve from 2.40126\n",
      " 29/128 [=====>........................] - ETA: 23s - loss: 2.4179 - accuracy: 0.4652\n",
      "Epoch 00086: loss did not improve from 2.40126\n",
      " 39/128 [========>.....................] - ETA: 21s - loss: 2.4252 - accuracy: 0.4660\n",
      "Epoch 00086: loss did not improve from 2.40126\n",
      " 49/128 [==========>...................] - ETA: 18s - loss: 2.4308 - accuracy: 0.4676\n",
      "Epoch 00086: loss did not improve from 2.40126\n",
      " 59/128 [============>.................] - ETA: 16s - loss: 2.4412 - accuracy: 0.4629\n",
      "Epoch 00086: loss did not improve from 2.40126\n",
      " 69/128 [===============>..............] - ETA: 14s - loss: 2.4350 - accuracy: 0.4635\n",
      "Epoch 00086: loss did not improve from 2.40126\n",
      " 79/128 [=================>............] - ETA: 11s - loss: 2.4437 - accuracy: 0.4620\n",
      "Epoch 00086: loss did not improve from 2.40126\n",
      " 89/128 [===================>..........] - ETA: 9s - loss: 2.4545 - accuracy: 0.4601\n",
      "Epoch 00086: loss did not improve from 2.40126\n",
      " 99/128 [======================>.......] - ETA: 7s - loss: 2.4595 - accuracy: 0.4588\n",
      "Epoch 00086: loss did not improve from 2.40126\n",
      "109/128 [========================>.....] - ETA: 4s - loss: 2.4573 - accuracy: 0.4583\n",
      "Epoch 00086: loss did not improve from 2.40126\n",
      "119/128 [==========================>...] - ETA: 2s - loss: 2.4641 - accuracy: 0.4564\n",
      "Epoch 00086: loss did not improve from 2.40126\n",
      "128/128 [==============================] - 31s 243ms/step - loss: 2.4727 - accuracy: 0.4549\n",
      "Epoch 87/100\n",
      "  1/128 [..............................] - ETA: 27s - loss: 2.2949 - accuracy: 0.4883\n",
      "Epoch 00087: loss improved from 2.40126 to 2.34459, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 11/128 [=>............................] - ETA: 30s - loss: 2.3476 - accuracy: 0.4858\n",
      "Epoch 00087: loss did not improve from 2.34459\n",
      " 21/128 [===>..........................] - ETA: 26s - loss: 2.3681 - accuracy: 0.4797\n",
      "Epoch 00087: loss did not improve from 2.34459\n",
      " 31/128 [======>.......................] - ETA: 24s - loss: 2.3508 - accuracy: 0.4774\n",
      "Epoch 00087: loss did not improve from 2.34459\n",
      " 41/128 [========>.....................] - ETA: 21s - loss: 2.3599 - accuracy: 0.4763\n",
      "Epoch 00087: loss did not improve from 2.34459\n",
      " 51/128 [==========>...................] - ETA: 18s - loss: 2.3882 - accuracy: 0.4719\n",
      "Epoch 00087: loss did not improve from 2.34459\n",
      " 61/128 [=============>................] - ETA: 16s - loss: 2.4026 - accuracy: 0.4701\n",
      "Epoch 00087: loss did not improve from 2.34459\n",
      " 71/128 [===============>..............] - ETA: 13s - loss: 2.4111 - accuracy: 0.4675\n",
      "Epoch 00087: loss did not improve from 2.34459\n",
      " 81/128 [=================>............] - ETA: 11s - loss: 2.4198 - accuracy: 0.4659\n",
      "Epoch 00087: loss did not improve from 2.34459\n",
      " 91/128 [====================>.........] - ETA: 9s - loss: 2.4359 - accuracy: 0.4632\n",
      "Epoch 00087: loss did not improve from 2.34459\n",
      "101/128 [======================>.......] - ETA: 6s - loss: 2.4437 - accuracy: 0.4619\n",
      "Epoch 00087: loss did not improve from 2.34459\n",
      "111/128 [=========================>....] - ETA: 4s - loss: 2.4414 - accuracy: 0.4626\n",
      "Epoch 00087: loss did not improve from 2.34459\n",
      "121/128 [===========================>..] - ETA: 1s - loss: 2.4511 - accuracy: 0.4611\n",
      "Epoch 00087: loss did not improve from 2.34459\n",
      "128/128 [==============================] - 31s 245ms/step - loss: 2.4531 - accuracy: 0.4607\n",
      "Epoch 88/100\n",
      "  3/128 [..............................] - ETA: 32s - loss: 2.3227 - accuracy: 0.4935\n",
      "Epoch 00088: loss improved from 2.34459 to 2.32457, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 13/128 [==>...........................] - ETA: 28s - loss: 2.3270 - accuracy: 0.4853\n",
      "Epoch 00088: loss improved from 2.32457 to 2.30985, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 23/128 [====>.........................] - ETA: 26s - loss: 2.3305 - accuracy: 0.4842\n",
      "Epoch 00088: loss did not improve from 2.30985\n",
      " 33/128 [======>.......................] - ETA: 23s - loss: 2.3243 - accuracy: 0.4837\n",
      "Epoch 00088: loss did not improve from 2.30985\n",
      " 43/128 [=========>....................] - ETA: 20s - loss: 2.3409 - accuracy: 0.4814\n",
      "Epoch 00088: loss did not improve from 2.30985\n",
      " 53/128 [===========>..................] - ETA: 18s - loss: 2.3393 - accuracy: 0.4819\n",
      "Epoch 00088: loss did not improve from 2.30985\n",
      " 63/128 [=============>................] - ETA: 15s - loss: 2.3459 - accuracy: 0.4784\n",
      "Epoch 00088: loss did not improve from 2.30985\n",
      " 73/128 [================>.............] - ETA: 13s - loss: 2.3615 - accuracy: 0.4729\n",
      "Epoch 00088: loss did not improve from 2.30985\n",
      " 83/128 [==================>...........] - ETA: 11s - loss: 2.3722 - accuracy: 0.4712\n",
      "Epoch 00088: loss did not improve from 2.30985\n",
      " 93/128 [====================>.........] - ETA: 8s - loss: 2.3727 - accuracy: 0.4708\n",
      "Epoch 00088: loss did not improve from 2.30985\n",
      "103/128 [=======================>......] - ETA: 6s - loss: 2.3879 - accuracy: 0.4682\n",
      "Epoch 00088: loss did not improve from 2.30985\n",
      "113/128 [=========================>....] - ETA: 3s - loss: 2.3981 - accuracy: 0.4665\n",
      "Epoch 00088: loss did not improve from 2.30985\n",
      "123/128 [===========================>..] - ETA: 1s - loss: 2.4081 - accuracy: 0.4651\n",
      "Epoch 00088: loss did not improve from 2.30985\n",
      "128/128 [==============================] - 32s 246ms/step - loss: 2.4120 - accuracy: 0.4648\n",
      "Epoch 89/100\n",
      "  5/128 [>.............................] - ETA: 27s - loss: 2.3554 - accuracy: 0.4711\n",
      "Epoch 00089: loss did not improve from 2.30985\n",
      " 15/128 [==>...........................] - ETA: 28s - loss: 2.3259 - accuracy: 0.4771\n",
      "Epoch 00089: loss did not improve from 2.30985\n",
      " 25/128 [====>.........................] - ETA: 24s - loss: 2.2963 - accuracy: 0.4855\n",
      "Epoch 00089: loss improved from 2.30985 to 2.29836, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 35/128 [=======>......................] - ETA: 23s - loss: 2.3144 - accuracy: 0.4829\n",
      "Epoch 00089: loss did not improve from 2.29836\n",
      " 45/128 [=========>....................] - ETA: 20s - loss: 2.3107 - accuracy: 0.4817\n",
      "Epoch 00089: loss did not improve from 2.29836\n",
      " 55/128 [===========>..................] - ETA: 17s - loss: 2.3261 - accuracy: 0.4798\n",
      "Epoch 00089: loss did not improve from 2.29836\n",
      " 65/128 [==============>...............] - ETA: 15s - loss: 2.3305 - accuracy: 0.4784\n",
      "Epoch 00089: loss did not improve from 2.29836\n",
      " 75/128 [================>.............] - ETA: 12s - loss: 2.3352 - accuracy: 0.4770\n",
      "Epoch 00089: loss did not improve from 2.29836\n",
      " 85/128 [==================>...........] - ETA: 10s - loss: 2.3457 - accuracy: 0.4735\n",
      "Epoch 00089: loss did not improve from 2.29836\n",
      " 95/128 [=====================>........] - ETA: 8s - loss: 2.3526 - accuracy: 0.4732\n",
      "Epoch 00089: loss did not improve from 2.29836\n",
      "105/128 [=======================>......] - ETA: 5s - loss: 2.3621 - accuracy: 0.4716\n",
      "Epoch 00089: loss did not improve from 2.29836\n",
      "115/128 [=========================>....] - ETA: 3s - loss: 2.3665 - accuracy: 0.4711\n",
      "Epoch 00089: loss did not improve from 2.29836\n",
      "125/128 [============================>.] - ETA: 0s - loss: 2.3757 - accuracy: 0.4701\n",
      "Epoch 00089: loss did not improve from 2.29836\n",
      "128/128 [==============================] - 31s 244ms/step - loss: 2.3789 - accuracy: 0.4694\n",
      "Epoch 90/100\n",
      "  7/128 [>.............................] - ETA: 31s - loss: 2.3236 - accuracy: 0.4900\n",
      "Epoch 00090: loss did not improve from 2.29836\n",
      " 17/128 [==>...........................] - ETA: 27s - loss: 2.3028 - accuracy: 0.4943\n",
      "Epoch 00090: loss improved from 2.29836 to 2.29135, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 27/128 [=====>........................] - ETA: 25s - loss: 2.2732 - accuracy: 0.4961\n",
      "Epoch 00090: loss improved from 2.29135 to 2.27420, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 37/128 [=======>......................] - ETA: 22s - loss: 2.2904 - accuracy: 0.4933\n",
      "Epoch 00090: loss did not improve from 2.27420\n",
      " 47/128 [==========>...................] - ETA: 20s - loss: 2.3037 - accuracy: 0.4899\n",
      "Epoch 00090: loss did not improve from 2.27420\n",
      " 57/128 [============>.................] - ETA: 17s - loss: 2.3080 - accuracy: 0.4886\n",
      "Epoch 00090: loss did not improve from 2.27420\n",
      " 67/128 [==============>...............] - ETA: 14s - loss: 2.3077 - accuracy: 0.4878\n",
      "Epoch 00090: loss did not improve from 2.27420\n",
      " 77/128 [=================>............] - ETA: 12s - loss: 2.3114 - accuracy: 0.4860\n",
      "Epoch 00090: loss did not improve from 2.27420\n",
      " 87/128 [===================>..........] - ETA: 10s - loss: 2.3079 - accuracy: 0.4868\n",
      "Epoch 00090: loss did not improve from 2.27420\n",
      " 97/128 [=====================>........] - ETA: 7s - loss: 2.3127 - accuracy: 0.4858\n",
      "Epoch 00090: loss did not improve from 2.27420\n",
      "107/128 [========================>.....] - ETA: 5s - loss: 2.3166 - accuracy: 0.4841\n",
      "Epoch 00090: loss did not improve from 2.27420\n",
      "117/128 [==========================>...] - ETA: 2s - loss: 2.3283 - accuracy: 0.4815\n",
      "Epoch 00090: loss did not improve from 2.27420\n",
      "127/128 [============================>.] - ETA: 0s - loss: 2.3325 - accuracy: 0.4805\n",
      "Epoch 00090: loss did not improve from 2.27420\n",
      "128/128 [==============================] - 31s 246ms/step - loss: 2.3328 - accuracy: 0.4804\n",
      "Epoch 91/100\n",
      "  9/128 [=>............................] - ETA: 27s - loss: 2.2722 - accuracy: 0.4996\n",
      "Epoch 00091: loss improved from 2.27420 to 2.26606, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 19/128 [===>..........................] - ETA: 26s - loss: 2.2325 - accuracy: 0.4963\n",
      "Epoch 00091: loss improved from 2.26606 to 2.23677, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 29/128 [=====>........................] - ETA: 24s - loss: 2.2434 - accuracy: 0.4923\n",
      "Epoch 00091: loss did not improve from 2.23677\n",
      " 39/128 [========>.....................] - ETA: 21s - loss: 2.2636 - accuracy: 0.4864\n",
      "Epoch 00091: loss did not improve from 2.23677\n",
      " 49/128 [==========>...................] - ETA: 19s - loss: 2.2615 - accuracy: 0.4857\n",
      "Epoch 00091: loss did not improve from 2.23677\n",
      " 59/128 [============>.................] - ETA: 16s - loss: 2.2761 - accuracy: 0.4844\n",
      "Epoch 00091: loss did not improve from 2.23677\n",
      " 69/128 [===============>..............] - ETA: 14s - loss: 2.2809 - accuracy: 0.4844\n",
      "Epoch 00091: loss did not improve from 2.23677\n",
      " 79/128 [=================>............] - ETA: 11s - loss: 2.2865 - accuracy: 0.4843\n",
      "Epoch 00091: loss did not improve from 2.23677\n",
      " 89/128 [===================>..........] - ETA: 9s - loss: 2.2922 - accuracy: 0.4836\n",
      "Epoch 00091: loss did not improve from 2.23677\n",
      " 99/128 [======================>.......] - ETA: 7s - loss: 2.2969 - accuracy: 0.4825\n",
      "Epoch 00091: loss did not improve from 2.23677\n",
      "109/128 [========================>.....] - ETA: 4s - loss: 2.3041 - accuracy: 0.4806\n",
      "Epoch 00091: loss did not improve from 2.23677\n",
      "119/128 [==========================>...] - ETA: 2s - loss: 2.3154 - accuracy: 0.4795\n",
      "Epoch 00091: loss did not improve from 2.23677\n",
      "128/128 [==============================] - 31s 245ms/step - loss: 2.3265 - accuracy: 0.4778\n",
      "Epoch 92/100\n",
      "  1/128 [..............................] - ETA: 28s - loss: 2.1584 - accuracy: 0.5273\n",
      "Epoch 00092: loss improved from 2.23677 to 1.99615, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 11/128 [=>............................] - ETA: 30s - loss: 2.1472 - accuracy: 0.5167\n",
      "Epoch 00092: loss did not improve from 1.99615\n",
      " 21/128 [===>..........................] - ETA: 26s - loss: 2.2038 - accuracy: 0.5006\n",
      "Epoch 00092: loss did not improve from 1.99615\n",
      " 31/128 [======>.......................] - ETA: 24s - loss: 2.2103 - accuracy: 0.5006\n",
      "Epoch 00092: loss did not improve from 1.99615\n",
      " 41/128 [========>.....................] - ETA: 21s - loss: 2.2232 - accuracy: 0.4958\n",
      "Epoch 00092: loss did not improve from 1.99615\n",
      " 51/128 [==========>...................] - ETA: 18s - loss: 2.2355 - accuracy: 0.4936\n",
      "Epoch 00092: loss did not improve from 1.99615\n",
      " 61/128 [=============>................] - ETA: 16s - loss: 2.2610 - accuracy: 0.4883\n",
      "Epoch 00092: loss did not improve from 1.99615\n",
      " 71/128 [===============>..............] - ETA: 13s - loss: 2.2666 - accuracy: 0.4879\n",
      "Epoch 00092: loss did not improve from 1.99615\n",
      " 81/128 [=================>............] - ETA: 11s - loss: 2.2716 - accuracy: 0.4887\n",
      "Epoch 00092: loss did not improve from 1.99615\n",
      " 91/128 [====================>.........] - ETA: 9s - loss: 2.2819 - accuracy: 0.4866\n",
      "Epoch 00092: loss did not improve from 1.99615\n",
      "101/128 [======================>.......] - ETA: 6s - loss: 2.2834 - accuracy: 0.4866\n",
      "Epoch 00092: loss did not improve from 1.99615\n",
      "111/128 [=========================>....] - ETA: 4s - loss: 2.2885 - accuracy: 0.4855\n",
      "Epoch 00092: loss did not improve from 1.99615\n",
      "121/128 [===========================>..] - ETA: 1s - loss: 2.2939 - accuracy: 0.4855\n",
      "Epoch 00092: loss did not improve from 1.99615\n",
      "128/128 [==============================] - 31s 245ms/step - loss: 2.2996 - accuracy: 0.4853\n",
      "Epoch 93/100\n",
      "  3/128 [..............................] - ETA: 32s - loss: 2.1542 - accuracy: 0.5195\n",
      "Epoch 00093: loss did not improve from 1.99615\n",
      " 13/128 [==>...........................] - ETA: 27s - loss: 2.1807 - accuracy: 0.5060\n",
      "Epoch 00093: loss did not improve from 1.99615\n",
      " 23/128 [====>.........................] - ETA: 25s - loss: 2.1787 - accuracy: 0.5087\n",
      "Epoch 00093: loss did not improve from 1.99615\n",
      " 33/128 [======>.......................] - ETA: 22s - loss: 2.1889 - accuracy: 0.5036\n",
      "Epoch 00093: loss did not improve from 1.99615\n",
      " 43/128 [=========>....................] - ETA: 20s - loss: 2.1888 - accuracy: 0.5024\n",
      "Epoch 00093: loss did not improve from 1.99615\n",
      " 53/128 [===========>..................] - ETA: 18s - loss: 2.2005 - accuracy: 0.4991\n",
      "Epoch 00093: loss did not improve from 1.99615\n",
      " 63/128 [=============>................] - ETA: 15s - loss: 2.2077 - accuracy: 0.4997\n",
      "Epoch 00093: loss did not improve from 1.99615\n",
      " 73/128 [================>.............] - ETA: 13s - loss: 2.2144 - accuracy: 0.5001\n",
      "Epoch 00093: loss did not improve from 1.99615\n",
      " 83/128 [==================>...........] - ETA: 10s - loss: 2.2273 - accuracy: 0.4971\n",
      "Epoch 00093: loss did not improve from 1.99615\n",
      " 93/128 [====================>.........] - ETA: 8s - loss: 2.2311 - accuracy: 0.4963\n",
      "Epoch 00093: loss did not improve from 1.99615\n",
      "103/128 [=======================>......] - ETA: 6s - loss: 2.2373 - accuracy: 0.4940\n",
      "Epoch 00093: loss did not improve from 1.99615\n",
      "113/128 [=========================>....] - ETA: 3s - loss: 2.2414 - accuracy: 0.4926\n",
      "Epoch 00093: loss did not improve from 1.99615\n",
      "123/128 [===========================>..] - ETA: 1s - loss: 2.2552 - accuracy: 0.4906\n",
      "Epoch 00093: loss did not improve from 1.99615\n",
      "128/128 [==============================] - 31s 244ms/step - loss: 2.2575 - accuracy: 0.4900\n",
      "Epoch 94/100\n",
      "  5/128 [>.............................] - ETA: 26s - loss: 2.0428 - accuracy: 0.5320\n",
      "Epoch 00094: loss did not improve from 1.99615\n",
      " 15/128 [==>...........................] - ETA: 26s - loss: 2.1045 - accuracy: 0.5208\n",
      "Epoch 00094: loss did not improve from 1.99615\n",
      " 25/128 [====>.........................] - ETA: 24s - loss: 2.1470 - accuracy: 0.5109\n",
      "Epoch 00094: loss did not improve from 1.99615\n",
      " 35/128 [=======>......................] - ETA: 22s - loss: 2.1561 - accuracy: 0.5092\n",
      "Epoch 00094: loss did not improve from 1.99615\n",
      " 45/128 [=========>....................] - ETA: 19s - loss: 2.1563 - accuracy: 0.5092\n",
      "Epoch 00094: loss did not improve from 1.99615\n",
      " 55/128 [===========>..................] - ETA: 17s - loss: 2.1649 - accuracy: 0.5074\n",
      "Epoch 00094: loss did not improve from 1.99615\n",
      " 65/128 [==============>...............] - ETA: 15s - loss: 2.1778 - accuracy: 0.5060\n",
      "Epoch 00094: loss did not improve from 1.99615\n",
      " 75/128 [================>.............] - ETA: 12s - loss: 2.1802 - accuracy: 0.5048\n",
      "Epoch 00094: loss did not improve from 1.99615\n",
      " 85/128 [==================>...........] - ETA: 10s - loss: 2.1860 - accuracy: 0.5045\n",
      "Epoch 00094: loss did not improve from 1.99615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 95/128 [=====================>........] - ETA: 7s - loss: 2.1867 - accuracy: 0.5037\n",
      "Epoch 00094: loss did not improve from 1.99615\n",
      "105/128 [=======================>......] - ETA: 5s - loss: 2.2055 - accuracy: 0.5002\n",
      "Epoch 00094: loss did not improve from 1.99615\n",
      "115/128 [=========================>....] - ETA: 3s - loss: 2.2193 - accuracy: 0.4968\n",
      "Epoch 00094: loss did not improve from 1.99615\n",
      "125/128 [============================>.] - ETA: 0s - loss: 2.2267 - accuracy: 0.4949\n",
      "Epoch 00094: loss did not improve from 1.99615\n",
      "128/128 [==============================] - 31s 244ms/step - loss: 2.2273 - accuracy: 0.4949\n",
      "Epoch 95/100\n",
      "  7/128 [>.............................] - ETA: 32s - loss: 2.1397 - accuracy: 0.5145\n",
      "Epoch 00095: loss did not improve from 1.99615\n",
      " 17/128 [==>...........................] - ETA: 27s - loss: 2.1178 - accuracy: 0.5209\n",
      "Epoch 00095: loss did not improve from 1.99615\n",
      " 27/128 [=====>........................] - ETA: 25s - loss: 2.1202 - accuracy: 0.5217\n",
      "Epoch 00095: loss did not improve from 1.99615\n",
      " 37/128 [=======>......................] - ETA: 22s - loss: 2.1225 - accuracy: 0.5177\n",
      "Epoch 00095: loss did not improve from 1.99615\n",
      " 47/128 [==========>...................] - ETA: 19s - loss: 2.1300 - accuracy: 0.5163\n",
      "Epoch 00095: loss did not improve from 1.99615\n",
      " 57/128 [============>.................] - ETA: 17s - loss: 2.1393 - accuracy: 0.5136\n",
      "Epoch 00095: loss did not improve from 1.99615\n",
      " 67/128 [==============>...............] - ETA: 14s - loss: 2.1594 - accuracy: 0.5075\n",
      "Epoch 00095: loss did not improve from 1.99615\n",
      " 77/128 [=================>............] - ETA: 12s - loss: 2.1676 - accuracy: 0.5050\n",
      "Epoch 00095: loss did not improve from 1.99615\n",
      " 87/128 [===================>..........] - ETA: 9s - loss: 2.1737 - accuracy: 0.5036 \n",
      "Epoch 00095: loss did not improve from 1.99615\n",
      " 97/128 [=====================>........] - ETA: 7s - loss: 2.1807 - accuracy: 0.5028\n",
      "Epoch 00095: loss did not improve from 1.99615\n",
      "107/128 [========================>.....] - ETA: 5s - loss: 2.1869 - accuracy: 0.5014\n",
      "Epoch 00095: loss did not improve from 1.99615\n",
      "117/128 [==========================>...] - ETA: 2s - loss: 2.1987 - accuracy: 0.5000\n",
      "Epoch 00095: loss did not improve from 1.99615\n",
      "127/128 [============================>.] - ETA: 0s - loss: 2.2057 - accuracy: 0.4985\n",
      "Epoch 00095: loss did not improve from 1.99615\n",
      "128/128 [==============================] - 31s 243ms/step - loss: 2.2060 - accuracy: 0.4985\n",
      "Epoch 96/100\n",
      "  9/128 [=>............................] - ETA: 29s - loss: 2.1814 - accuracy: 0.4970\n",
      "Epoch 00096: loss did not improve from 1.99615\n",
      " 19/128 [===>..........................] - ETA: 26s - loss: 2.1319 - accuracy: 0.5111\n",
      "Epoch 00096: loss did not improve from 1.99615\n",
      " 29/128 [=====>........................] - ETA: 24s - loss: 2.1557 - accuracy: 0.5092\n",
      "Epoch 00096: loss did not improve from 1.99615\n",
      " 39/128 [========>.....................] - ETA: 21s - loss: 2.1410 - accuracy: 0.5095\n",
      "Epoch 00096: loss did not improve from 1.99615\n",
      " 49/128 [==========>...................] - ETA: 19s - loss: 2.1413 - accuracy: 0.5098\n",
      "Epoch 00096: loss did not improve from 1.99615\n",
      " 59/128 [============>.................] - ETA: 16s - loss: 2.1531 - accuracy: 0.5079\n",
      "Epoch 00096: loss did not improve from 1.99615\n",
      " 69/128 [===============>..............] - ETA: 14s - loss: 2.1510 - accuracy: 0.5057\n",
      "Epoch 00096: loss did not improve from 1.99615\n",
      " 79/128 [=================>............] - ETA: 11s - loss: 2.1533 - accuracy: 0.5056\n",
      "Epoch 00096: loss did not improve from 1.99615\n",
      " 89/128 [===================>..........] - ETA: 9s - loss: 2.1562 - accuracy: 0.5056\n",
      "Epoch 00096: loss did not improve from 1.99615\n",
      " 99/128 [======================>.......] - ETA: 7s - loss: 2.1588 - accuracy: 0.5033\n",
      "Epoch 00096: loss did not improve from 1.99615\n",
      "109/128 [========================>.....] - ETA: 4s - loss: 2.1633 - accuracy: 0.5018\n",
      "Epoch 00096: loss did not improve from 1.99615\n",
      "119/128 [==========================>...] - ETA: 2s - loss: 2.1684 - accuracy: 0.5006\n",
      "Epoch 00096: loss did not improve from 1.99615\n",
      "128/128 [==============================] - 31s 244ms/step - loss: 2.1756 - accuracy: 0.4993\n",
      "Epoch 97/100\n",
      "  1/128 [..............................] - ETA: 30s - loss: 2.0779 - accuracy: 0.5312\n",
      "Epoch 00097: loss did not improve from 1.99615\n",
      " 11/128 [=>............................] - ETA: 28s - loss: 2.0544 - accuracy: 0.5362\n",
      "Epoch 00097: loss did not improve from 1.99615\n",
      " 21/128 [===>..........................] - ETA: 27s - loss: 2.0397 - accuracy: 0.5288\n",
      "Epoch 00097: loss did not improve from 1.99615\n",
      " 31/128 [======>.......................] - ETA: 23s - loss: 2.0577 - accuracy: 0.5281\n",
      "Epoch 00097: loss did not improve from 1.99615\n",
      " 41/128 [========>.....................] - ETA: 21s - loss: 2.0729 - accuracy: 0.5264\n",
      "Epoch 00097: loss did not improve from 1.99615\n",
      " 51/128 [==========>...................] - ETA: 18s - loss: 2.0677 - accuracy: 0.5258\n",
      "Epoch 00097: loss did not improve from 1.99615\n",
      " 61/128 [=============>................] - ETA: 16s - loss: 2.0797 - accuracy: 0.5237\n",
      "Epoch 00097: loss did not improve from 1.99615\n",
      " 71/128 [===============>..............] - ETA: 13s - loss: 2.1010 - accuracy: 0.5198\n",
      "Epoch 00097: loss did not improve from 1.99615\n",
      " 81/128 [=================>............] - ETA: 11s - loss: 2.1187 - accuracy: 0.5155\n",
      "Epoch 00097: loss did not improve from 1.99615\n",
      " 91/128 [====================>.........] - ETA: 8s - loss: 2.1184 - accuracy: 0.5150\n",
      "Epoch 00097: loss did not improve from 1.99615\n",
      "101/128 [======================>.......] - ETA: 6s - loss: 2.1338 - accuracy: 0.5109\n",
      "Epoch 00097: loss did not improve from 1.99615\n",
      "111/128 [=========================>....] - ETA: 4s - loss: 2.1343 - accuracy: 0.5104\n",
      "Epoch 00097: loss did not improve from 1.99615\n",
      "121/128 [===========================>..] - ETA: 1s - loss: 2.1433 - accuracy: 0.5084\n",
      "Epoch 00097: loss did not improve from 1.99615\n",
      "128/128 [==============================] - 31s 243ms/step - loss: 2.1467 - accuracy: 0.5075\n",
      "Epoch 98/100\n",
      "  3/128 [..............................] - ETA: 27s - loss: 2.0641 - accuracy: 0.5078\n",
      "Epoch 00098: loss did not improve from 1.99615\n",
      " 13/128 [==>...........................] - ETA: 30s - loss: 2.0354 - accuracy: 0.5279\n",
      "Epoch 00098: loss did not improve from 1.99615\n",
      " 23/128 [====>.........................] - ETA: 28s - loss: 2.0401 - accuracy: 0.5250\n",
      "Epoch 00098: loss did not improve from 1.99615\n",
      " 33/128 [======>.......................] - ETA: 24s - loss: 2.0591 - accuracy: 0.5218\n",
      "Epoch 00098: loss did not improve from 1.99615\n",
      " 43/128 [=========>....................] - ETA: 21s - loss: 2.0630 - accuracy: 0.5183\n",
      "Epoch 00098: loss did not improve from 1.99615\n",
      " 53/128 [===========>..................] - ETA: 18s - loss: 2.0607 - accuracy: 0.5198\n",
      "Epoch 00098: loss did not improve from 1.99615\n",
      " 63/128 [=============>................] - ETA: 16s - loss: 2.0633 - accuracy: 0.5213\n",
      "Epoch 00098: loss did not improve from 1.99615\n",
      " 73/128 [================>.............] - ETA: 13s - loss: 2.0707 - accuracy: 0.5200\n",
      "Epoch 00098: loss did not improve from 1.99615\n",
      " 83/128 [==================>...........] - ETA: 11s - loss: 2.0785 - accuracy: 0.5194\n",
      "Epoch 00098: loss did not improve from 1.99615\n",
      " 93/128 [====================>.........] - ETA: 8s - loss: 2.0885 - accuracy: 0.5171\n",
      "Epoch 00098: loss did not improve from 1.99615\n",
      "103/128 [=======================>......] - ETA: 6s - loss: 2.0948 - accuracy: 0.5150\n",
      "Epoch 00098: loss did not improve from 1.99615\n",
      "113/128 [=========================>....] - ETA: 3s - loss: 2.1025 - accuracy: 0.5128\n",
      "Epoch 00098: loss did not improve from 1.99615\n",
      "123/128 [===========================>..] - ETA: 1s - loss: 2.1112 - accuracy: 0.5117\n",
      "Epoch 00098: loss did not improve from 1.99615\n",
      "128/128 [==============================] - 31s 246ms/step - loss: 2.1094 - accuracy: 0.5122\n",
      "Epoch 99/100\n",
      "  5/128 [>.............................] - ETA: 27s - loss: 1.9541 - accuracy: 0.5516\n",
      "Epoch 00099: loss improved from 1.99615 to 1.97906, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 15/128 [==>...........................] - ETA: 29s - loss: 2.0073 - accuracy: 0.5380\n",
      "Epoch 00099: loss did not improve from 1.97906\n",
      " 25/128 [====>.........................] - ETA: 26s - loss: 2.0382 - accuracy: 0.5347\n",
      "Epoch 00099: loss did not improve from 1.97906\n",
      " 35/128 [=======>......................] - ETA: 23s - loss: 2.0254 - accuracy: 0.5334\n",
      "Epoch 00099: loss did not improve from 1.97906\n",
      " 45/128 [=========>....................] - ETA: 20s - loss: 2.0216 - accuracy: 0.5309\n",
      "Epoch 00099: loss did not improve from 1.97906\n",
      " 55/128 [===========>..................] - ETA: 18s - loss: 2.0305 - accuracy: 0.5283\n",
      "Epoch 00099: loss did not improve from 1.97906\n",
      " 65/128 [==============>...............] - ETA: 15s - loss: 2.0275 - accuracy: 0.5303\n",
      "Epoch 00099: loss did not improve from 1.97906\n",
      " 75/128 [================>.............] - ETA: 13s - loss: 2.0357 - accuracy: 0.5269\n",
      "Epoch 00099: loss did not improve from 1.97906\n",
      " 85/128 [==================>...........] - ETA: 10s - loss: 2.0429 - accuracy: 0.5245\n",
      "Epoch 00099: loss did not improve from 1.97906\n",
      " 95/128 [=====================>........] - ETA: 8s - loss: 2.0450 - accuracy: 0.5247\n",
      "Epoch 00099: loss did not improve from 1.97906\n",
      "105/128 [=======================>......] - ETA: 5s - loss: 2.0532 - accuracy: 0.5233\n",
      "Epoch 00099: loss did not improve from 1.97906\n",
      "115/128 [=========================>....] - ETA: 3s - loss: 2.0565 - accuracy: 0.5225\n",
      "Epoch 00099: loss did not improve from 1.97906\n",
      "125/128 [============================>.] - ETA: 0s - loss: 2.0627 - accuracy: 0.5204\n",
      "Epoch 00099: loss did not improve from 1.97906\n",
      "128/128 [==============================] - 31s 245ms/step - loss: 2.0657 - accuracy: 0.5200\n",
      "Epoch 100/100\n",
      "  7/128 [>.............................] - ETA: 27s - loss: 1.9367 - accuracy: 0.5346\n",
      "Epoch 00100: loss improved from 1.97906 to 1.92647, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 17/128 [==>...........................] - ETA: 28s - loss: 1.9240 - accuracy: 0.5443\n",
      "Epoch 00100: loss improved from 1.92647 to 1.91646, saving model to ./export/2023-10-02T110043/model.h5\n",
      " 27/128 [=====>........................] - ETA: 25s - loss: 1.9338 - accuracy: 0.5446\n",
      "Epoch 00100: loss did not improve from 1.91646\n",
      " 37/128 [=======>......................] - ETA: 23s - loss: 1.9473 - accuracy: 0.5408\n",
      "Epoch 00100: loss did not improve from 1.91646\n",
      " 47/128 [==========>...................] - ETA: 20s - loss: 1.9534 - accuracy: 0.5411\n",
      "Epoch 00100: loss did not improve from 1.91646\n",
      " 57/128 [============>.................] - ETA: 17s - loss: 1.9534 - accuracy: 0.5408\n",
      "Epoch 00100: loss did not improve from 1.91646\n",
      " 67/128 [==============>...............] - ETA: 15s - loss: 1.9606 - accuracy: 0.5398\n",
      "Epoch 00100: loss did not improve from 1.91646\n",
      " 77/128 [=================>............] - ETA: 12s - loss: 1.9796 - accuracy: 0.5350\n",
      "Epoch 00100: loss did not improve from 1.91646\n",
      " 87/128 [===================>..........] - ETA: 10s - loss: 1.9873 - accuracy: 0.5342\n",
      "Epoch 00100: loss did not improve from 1.91646\n",
      " 97/128 [=====================>........] - ETA: 7s - loss: 1.9955 - accuracy: 0.5326\n",
      "Epoch 00100: loss did not improve from 1.91646\n",
      "107/128 [========================>.....] - ETA: 5s - loss: 2.0120 - accuracy: 0.5302\n",
      "Epoch 00100: loss did not improve from 1.91646\n",
      "117/128 [==========================>...] - ETA: 2s - loss: 2.0211 - accuracy: 0.5292\n",
      "Epoch 00100: loss did not improve from 1.91646\n",
      "127/128 [============================>.] - ETA: 0s - loss: 2.0294 - accuracy: 0.5266\n",
      "Epoch 00100: loss did not improve from 1.91646\n",
      "128/128 [==============================] - 31s 245ms/step - loss: 2.0305 - accuracy: 0.5264\n"
     ]
    }
   ],
   "source": [
    "!cd lyrics-generator && python3 -m lyrics.train --songdata-file ../data/cleaned_poems_of_mandelshtamp.csv --artists '*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54278595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-02 12:34:16.472863: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-10-02 12:34:16.472889: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-10-02 12:34:18.169542: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_COMPAT_NOT_SUPPORTED_ON_DEVICE: forward compatibility was attempted on non supported HW\n",
      "2023-10-02 12:34:18.169606: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: jollyreap-B450-AORUS-ELITE\n",
      "2023-10-02 12:34:18.169613: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: jollyreap-B450-AORUS-ELITE\n",
      "2023-10-02 12:34:18.169735: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 535.113.1\n",
      "2023-10-02 12:34:18.169760: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 535.104.5\n",
      "2023-10-02 12:34:18.169766: E tensorflow/stream_executor/cuda/cuda_diagnostics.cc:313] kernel version 535.104.5 does not match DSO version 535.113.1 -- cannot find working devices in this configuration\n",
      "2023-10-02 12:34:18.170185: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Generating lyrics from \"Я вернулся в мой город, знакомый до слез\"...\n",
      "Using integer sequences\n",
      "я вернулся в мой город знакомый до слез \n",
      " хвостик время вернусь \n",
      " полночных до ним ворующий \n",
      " и перед отец к воде \n",
      " там глаз ялики и пламень \n",
      " когда с наступающей жизни \n",
      " толпы обуза тимпаном \n",
      " будут где скользнуламелькнула бумажек в светлой \n",
      " я помню луч глубже \n",
      " но же бы смертью отвар \n",
      " как будто бы корой и тебя не быть каждый конца \n",
      " пусть смотри твоя по мозаичный осла \n",
      " задонском как в кухне другое\n",
      "\n",
      "Random seed (for reproducibility): 2015025205\n"
     ]
    }
   ],
   "source": [
    "!cd lyrics-generator && python3 -m cli lyrics export/2023-10-02T110043/model.h5 export/2023-10-02T110043/tokenizer.pickle --text 'Я вернулся в мой город, знакомый до слез' --length 80"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
